{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "timeseries_stocks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameyas1/Stock_prediction/blob/master/timeseries_stocks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIIr-whIial_",
        "colab_type": "code",
        "outputId": "5e2c72a3-7a1b-494f-c2c0-2a433aea1bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "# Install yfinance package.\n",
        "!pip install yfinance "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/53/0e/40387099824c98be22cd7e33a620e9d38b61998b031f0b33f0b9959717d2/yfinance-0.1.45.tar.gz\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.24.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.16.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from yfinance) (2.21.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.24->yfinance) (1.12.0)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.45-cp36-none-any.whl size=14652 sha256=14324d229dae09fc1eef0d5c9760460357fe84a2cc4543c79ff03bcafe4cd4b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/d1/df/aa9a7744a4ac353cc9a1f2c3aaea7c1f457fc49de4286f2d88\n",
            "Successfully built yfinance\n",
            "Installing collected packages: yfinance\n",
            "Successfully installed yfinance-0.1.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JBvEhqCXTPo",
        "colab_type": "code",
        "outputId": "7be5a68b-bd2f-4833-dafb-a987efdcd64e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0b1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0b1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/6c/2c9a5c4d095c63c2fb37d20def0e4f92685f7aee9243d6aae25862694fd1/tensorflow-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (87.9MB)\n",
            "\u001b[K     |████████████████████████████████| 87.9MB 387kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (0.1.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (0.8.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (0.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (1.16.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (0.33.6)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow==2.0.0b1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (3.7.1)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow==2.0.0b1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (0.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0b1) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0b1) (41.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0b1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0b1) (0.15.5)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.14.0\n",
            "    Uninstalling tensorflow-1.14.0:\n",
            "      Successfully uninstalled tensorflow-1.14.0\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWE7ZCncWvan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Import yfinance\n",
        "import yfinance as yf \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import math\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAQKIcG2iiyz",
        "colab_type": "code",
        "outputId": "eb78e59a-0614-44e6-aa32-6b970747f4d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = yf.download('ICICIBANK.NS','2006-01-01','2019-08-30')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYtLYSQli4vQ",
        "colab_type": "code",
        "outputId": "aead39d3-1124-4c6c-d50c-787dfffaad1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2006-01-02</th>\n",
              "      <td>106.86</td>\n",
              "      <td>110.89</td>\n",
              "      <td>106.86</td>\n",
              "      <td>108.54</td>\n",
              "      <td>40.92</td>\n",
              "      <td>56324939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-01-03</th>\n",
              "      <td>108.54</td>\n",
              "      <td>110.64</td>\n",
              "      <td>104.47</td>\n",
              "      <td>110.27</td>\n",
              "      <td>41.58</td>\n",
              "      <td>25631986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-01-04</th>\n",
              "      <td>111.09</td>\n",
              "      <td>112.91</td>\n",
              "      <td>110.54</td>\n",
              "      <td>111.58</td>\n",
              "      <td>42.07</td>\n",
              "      <td>28841324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-01-05</th>\n",
              "      <td>112.35</td>\n",
              "      <td>112.35</td>\n",
              "      <td>108.09</td>\n",
              "      <td>109.92</td>\n",
              "      <td>41.44</td>\n",
              "      <td>12662964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-01-06</th>\n",
              "      <td>110.14</td>\n",
              "      <td>110.86</td>\n",
              "      <td>108.12</td>\n",
              "      <td>109.12</td>\n",
              "      <td>41.14</td>\n",
              "      <td>3684637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Open    High     Low   Close  Adj Close    Volume\n",
              "Date                                                           \n",
              "2006-01-02  106.86  110.89  106.86  108.54      40.92  56324939\n",
              "2006-01-03  108.54  110.64  104.47  110.27      41.58  25631986\n",
              "2006-01-04  111.09  112.91  110.54  111.58      42.07  28841324\n",
              "2006-01-05  112.35  112.35  108.09  109.92      41.44  12662964\n",
              "2006-01-06  110.14  110.86  108.12  109.12      41.14   3684637"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhI5gf9JjBP-",
        "colab_type": "code",
        "outputId": "e9732a33-0e3e-4c16-a52f-3eb49a8f5cd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "data.Close.plot()\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/2MUW3Ni1AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk10GAtajkph",
        "colab_type": "code",
        "outputId": "6992d0c3-c0ba-404c-ebc2-257e380760e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "def roundup(x):\n",
        "    return int(math.ceil(x / 100.0)) * 100\n",
        "  \n",
        "\n",
        "print(min(data.Close))  \n",
        "print(max(data.Close))\n",
        "roundup(max(data.Close))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47.81\n",
            "440.95\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niQj_oWjjwRI",
        "colab_type": "code",
        "outputId": "aa301d65-f78f-4009-f529-0db0de29defa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data['Close'].isnull().sum(axis = 0)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOyUq7yvkKaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to make Date index column into a normal column\n",
        "# data.reset_index(level=0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ4Da7O7mvSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data[\"Date\"] = pd.to_datetime(data[\"Date\"]).dt.strftime(\"%Y%m%d\").astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2Cty5F8m8kN",
        "colab_type": "code",
        "outputId": "244a3c21-4780-4c74-ffdc-530685117f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "data.tail()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-08-26</th>\n",
              "      <td>407.0</td>\n",
              "      <td>414.00</td>\n",
              "      <td>392.85</td>\n",
              "      <td>411.65</td>\n",
              "      <td>411.65</td>\n",
              "      <td>26701988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-27</th>\n",
              "      <td>412.8</td>\n",
              "      <td>420.50</td>\n",
              "      <td>411.25</td>\n",
              "      <td>418.60</td>\n",
              "      <td>418.60</td>\n",
              "      <td>28793372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-28</th>\n",
              "      <td>418.0</td>\n",
              "      <td>418.25</td>\n",
              "      <td>409.70</td>\n",
              "      <td>412.95</td>\n",
              "      <td>412.95</td>\n",
              "      <td>12154347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-29</th>\n",
              "      <td>409.9</td>\n",
              "      <td>410.80</td>\n",
              "      <td>399.35</td>\n",
              "      <td>404.40</td>\n",
              "      <td>404.40</td>\n",
              "      <td>30331105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-30</th>\n",
              "      <td>406.5</td>\n",
              "      <td>412.85</td>\n",
              "      <td>402.65</td>\n",
              "      <td>409.65</td>\n",
              "      <td>409.65</td>\n",
              "      <td>18314194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Open    High     Low   Close  Adj Close    Volume\n",
              "Date                                                          \n",
              "2019-08-26  407.0  414.00  392.85  411.65     411.65  26701988\n",
              "2019-08-27  412.8  420.50  411.25  418.60     418.60  28793372\n",
              "2019-08-28  418.0  418.25  409.70  412.95     412.95  12154347\n",
              "2019-08-29  409.9  410.80  399.35  404.40     404.40  30331105\n",
              "2019-08-30  406.5  412.85  402.65  409.65     409.65  18314194"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjG2krO5nGZA",
        "colab_type": "code",
        "outputId": "912728d8-aead-4800-9f34-8528c0ee8e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3365"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj5XApiTkXYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data['Date'].isnull().sum(axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWrdsmw5mbRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "series = data.Close.values.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "405UVjwdQg4A",
        "colab_type": "code",
        "outputId": "23b6e89c-a30e-4af2-fd42-b5419447d275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(series)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3365"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOWkQ-Samp36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "timestep = [i for i in range(len(series))]\n",
        "timestep = np.array(timestep)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y1I_E4qQsfQ",
        "colab_type": "code",
        "outputId": "31575e9b-616d-4e7c-c22a-ec9b01c86696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "timestep"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    1,    2, ..., 3362, 3363, 3364])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOQY-n7BnQR7",
        "colab_type": "code",
        "outputId": "3bd65de7-a55f-4e49-df7b-cb089eff2fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ro=float(roundup(max(series)))\n",
        "print(ro)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jIKaa_bnzUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
        "    plt.plot(time[start:end], series[start:end], format)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.grid(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkbghSZGn18t",
        "colab_type": "code",
        "outputId": "0a2b912e-54c8-4322-eacc-91f928b8c76b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(timestep, series)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAF3CAYAAAAYbBfgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/j+ck/KsjW/6MwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pkuDLhIn5if",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.figure(figsize=(10, 6))\n",
        "# data.Close.plot()\n",
        "# plt.plot(data.index, data.Close)\n",
        "# plt.grid(True)\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr9h0LiLoMSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split_time = 3000\n",
        "time_train = timestep[:split_time]\n",
        "x_train = series[:split_time]\n",
        "time_valid = timestep[split_time:]\n",
        "x_valid = series[split_time:]\n",
        "\n",
        "window_size = 30\n",
        "batch_size = 100\n",
        "shuffle_buffer_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reTTHr5AqgIM",
        "colab_type": "code",
        "outputId": "fcfc48e2-73e7-4840-e6b1-90ad3bd5ce04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time_train,x_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAF3CAYAAADgjOwXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIV+3QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXd9NpQ8rXzd",
        "colab_type": "code",
        "outputId": "946a3752-3ae0-49ca-e0b1-160fff04302e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time_valid,x_valid)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAF3CAYAAAARh7eaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTQghhBCiwEiAJoQQQghRYP4/OBMTMCjk8p4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur6dmLACZDJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "    series = tf.expand_dims(series, axis=-1)\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
        "    ds = ds.shuffle(shuffle_buffer)\n",
        "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
        "    return ds.batch(batch_size).prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3nSl3ffZIe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_forecast(model, series, window_size):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
        "    ds = ds.batch(32).prefetch(1)\n",
        "    forecast = model.predict(ds)\n",
        "    return forecast"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7iH-AZLZMG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath=\"cp/weights-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "# callbacks_list = [checkpoint]\n",
        "!mkdir cp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xla64S0oZcPf",
        "colab_type": "code",
        "outputId": "a2b86b65-2233-4e15-b126-907d7d75d812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)\n",
        "window_size = 30\n",
        "batch_size = 100\n",
        "train_set = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "print(train_set)\n",
        "print(x_train.shape)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv1D(filters=60, kernel_size=6,\n",
        "                      strides=1, padding=\"causal\",\n",
        "                      activation=\"relu\",\n",
        "                      input_shape=[None, 1]),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(60, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(60, return_sequences=True)),\n",
        "  tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * ro)\n",
        "])\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
        "optimizer = tf.keras.optimizers.Adam(lr=1e-8)\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0901 13:49:59.986363 140282053453696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ((None, None, 1), (None, None, 1)), types: (tf.float32, tf.float32)>\n",
            "(3000,)\n",
            "Epoch 1/100\n",
            "30/30 [==============================] - 9s 285ms/step - loss: 238.7681 - mae: 238.2303\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 5s 154ms/step - loss: 238.6939 - mae: 238.1897\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 238.6473 - mae: 238.1432\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 5s 157ms/step - loss: 238.5946 - mae: 238.0907\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 238.5374 - mae: 238.0336\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 238.4751 - mae: 237.9715\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 5s 153ms/step - loss: 238.4043 - mae: 237.9007\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 238.3234 - mae: 237.8201\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 5s 153ms/step - loss: 238.2324 - mae: 237.7292\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 238.1291 - mae: 237.6261\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 5s 154ms/step - loss: 238.0137 - mae: 237.5109\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 237.8843 - mae: 237.3818\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 5s 159ms/step - loss: 237.7377 - mae: 237.2354\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 237.5720 - mae: 237.0701\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 5s 157ms/step - loss: 237.3853 - mae: 236.8838\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 5s 154ms/step - loss: 237.1736 - mae: 236.6726\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 236.9341 - mae: 236.4335\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 236.6627 - mae: 236.1628\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 5s 154ms/step - loss: 236.3547 - mae: 235.8555\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 236.0051 - mae: 235.5066\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 235.6073 - mae: 235.1097\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 235.1533 - mae: 234.6568\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 5s 157ms/step - loss: 234.6341 - mae: 234.1388\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 5s 153ms/step - loss: 234.0383 - mae: 233.5443\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 233.3512 - mae: 232.8589\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 232.5544 - mae: 232.0638\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 5s 162ms/step - loss: 231.6230 - mae: 231.1347\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 5s 164ms/step - loss: 230.5247 - mae: 230.0390\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 5s 154ms/step - loss: 229.2203 - mae: 228.7376\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 227.6688 - mae: 227.1896\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 5s 158ms/step - loss: 225.8180 - mae: 225.3427\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 5s 157ms/step - loss: 223.6009 - mae: 223.1305\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 220.9433 - mae: 220.4784\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 5s 157ms/step - loss: 217.7606 - mae: 217.3020\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 213.9540 - mae: 213.5021\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 209.4481 - mae: 209.0040\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 5s 154ms/step - loss: 204.1024 - mae: 203.6681\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 5s 157ms/step - loss: 197.7107 - mae: 197.2885\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 5s 158ms/step - loss: 189.8959 - mae: 189.4901\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 5s 157ms/step - loss: 180.3313 - mae: 179.9501\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 5s 160ms/step - loss: 168.8738 - mae: 168.5254\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 5s 159ms/step - loss: 156.0129 - mae: 155.6934\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 142.7535 - mae: 142.4443\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 5s 154ms/step - loss: 129.5861 - mae: 129.2740\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 5s 154ms/step - loss: 116.5109 - mae: 116.1924\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 103.4450 - mae: 103.1245\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 5s 160ms/step - loss: 90.3697 - mae: 90.0552\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 5s 158ms/step - loss: 77.7105 - mae: 77.4108\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 5s 158ms/step - loss: 66.3473 - mae: 66.0728\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 58.0363 - mae: 57.8026\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 5s 157ms/step - loss: 53.1082 - mae: 52.9251\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 5s 157ms/step - loss: 50.1138 - mae: 49.9791\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 48.0296 - mae: 47.9365\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 5s 157ms/step - loss: 46.2183 - mae: 46.1586\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 44.4392 - mae: 44.4064\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 42.5014 - mae: 42.4897\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 40.2338 - mae: 40.2410\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 37.5074 - mae: 37.5343\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 34.4198 - mae: 34.4734\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 31.2360 - mae: 31.3273\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 5s 157ms/step - loss: 28.2885 - mae: 28.4272\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 25.8059 - mae: 25.9905\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 23.3413 - mae: 23.5764\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 5s 158ms/step - loss: 21.0596 - mae: 21.3398\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 5s 159ms/step - loss: 18.8984 - mae: 19.2064\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 16.7783 - mae: 17.0956\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 14.9130 - mae: 15.2427\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 5s 154ms/step - loss: 13.5008 - mae: 13.8481\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 12.1887 - mae: 12.5391\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 10.8738 - mae: 11.2115\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 5s 154ms/step - loss: 9.5359 - mae: 9.8760\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 8.5403 - mae: 8.8987\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 8.1493 - mae: 8.5309\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 5s 157ms/step - loss: 7.5900 - mae: 7.9822\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 5s 154ms/step - loss: 8.0422 - mae: 8.4437\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 5s 154ms/step - loss: 7.3256 - mae: 7.7437\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 5s 154ms/step - loss: 7.2055 - mae: 7.6337\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 5s 157ms/step - loss: 10.7793 - mae: 11.1938\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 5s 154ms/step - loss: 9.0359 - mae: 9.4904\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 5s 158ms/step - loss: 11.5476 - mae: 11.9985\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 7.8710 - mae: 8.3169\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 5s 158ms/step - loss: 6.5886 - mae: 7.0382\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 5s 158ms/step - loss: 10.9154 - mae: 11.4048\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 14.2356 - mae: 14.7521\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 14.5726 - mae: 15.0756\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 5s 158ms/step - loss: 10.6047 - mae: 11.0895\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 8.1648 - mae: 8.5945\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 19.1431 - mae: 19.6237\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 28.4798 - mae: 28.7450\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 5s 154ms/step - loss: 14.8879 - mae: 15.1179\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 17.8964 - mae: 18.0889\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 5s 155ms/step - loss: 20.8904 - mae: 21.0320\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 5s 159ms/step - loss: 12.2836 - mae: 12.6968\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 24.1139 - mae: 24.6309\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 40.4372 - mae: 40.9215\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 5s 156ms/step - loss: 28.7592 - mae: 29.0528\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 5s 157ms/step - loss: 26.1600 - mae: 26.4784\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 5s 157ms/step - loss: 25.0662 - mae: 25.4324\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 5s 159ms/step - loss: 24.6227 - mae: 24.8406\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 5s 157ms/step - loss: 21.6849 - mae: 21.6422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9FPYq0vZzZ2",
        "colab_type": "code",
        "outputId": "7b168133-75ce-4b0b-d6f9-761d43f681ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f95b6b95e48>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnIJeRCTK/X/i+a5BgE+9GwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19piKFRnZ9n5",
        "colab_type": "code",
        "outputId": "a75afeaf-0baa-4dd8-808b-f099c30c6751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)\n",
        "train_set = windowed_dataset(x_train, window_size=30, batch_size=100, shuffle_buffer=shuffle_buffer_size)\n",
        "test_set = windowed_dataset(x_valid, window_size=30, batch_size=32, shuffle_buffer=shuffle_buffer_size)\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv1D(filters=60, kernel_size=5,\n",
        "                      strides=1, padding=\"causal\",\n",
        "                      activation=\"relu\",\n",
        "                      input_shape=[None, 1]),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(60, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(60, return_sequences=True)),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * ro)\n",
        "])\n",
        "\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr=4e-5)\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(train_set,epochs=1000,callbacks=[checkpoint], validation_data=test_set)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "     30/Unknown - 9s 312ms/step - loss: 158.9253 - mae: 159.4398\n",
            "Epoch 00001: val_loss improved from inf to 159.08302, saving model to cp/weights-01-159.08.hdf5\n",
            "30/30 [==============================] - 11s 368ms/step - loss: 158.9253 - mae: 159.4398 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
            "Epoch 2/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 114.0297 - mae: 114.5288\n",
            "Epoch 00002: val_loss did not improve from 159.08302\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 115.2103 - mae: 115.3715 - val_loss: 178.1680 - val_mae: 176.7387\n",
            "Epoch 3/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 95.9733 - mae: 96.4722\n",
            "Epoch 00003: val_loss improved from 159.08302 to 155.96355, saving model to cp/weights-03-155.96.hdf5\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 97.2202 - mae: 97.3623 - val_loss: 155.9635 - val_mae: 154.5249\n",
            "Epoch 4/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 86.0934 - mae: 86.5922\n",
            "Epoch 00004: val_loss improved from 155.96355 to 143.55729, saving model to cp/weights-04-143.56.hdf5\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 87.3028 - mae: 87.4555 - val_loss: 143.5573 - val_mae: 142.1949\n",
            "Epoch 5/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 77.9343 - mae: 78.4330\n",
            "Epoch 00005: val_loss improved from 143.55729 to 131.02855, saving model to cp/weights-05-131.03.hdf5\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 79.1513 - mae: 79.3017 - val_loss: 131.0286 - val_mae: 129.7504\n",
            "Epoch 6/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 72.5815 - mae: 73.0800\n",
            "Epoch 00006: val_loss improved from 131.02855 to 125.43143, saving model to cp/weights-06-125.43.hdf5\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 73.7387 - mae: 73.9061 - val_loss: 125.4314 - val_mae: 124.1554\n",
            "Epoch 7/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 68.6284 - mae: 69.1270\n",
            "Epoch 00007: val_loss improved from 125.43143 to 119.21478, saving model to cp/weights-07-119.21.hdf5\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 69.6387 - mae: 69.8482 - val_loss: 119.2148 - val_mae: 117.9792\n",
            "Epoch 8/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 65.1388 - mae: 65.6371\n",
            "Epoch 00008: val_loss improved from 119.21478 to 113.42788, saving model to cp/weights-08-113.43.hdf5\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 66.2592 - mae: 66.4369 - val_loss: 113.4279 - val_mae: 112.2369\n",
            "Epoch 9/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 62.5511 - mae: 63.0492\n",
            "Epoch 00009: val_loss improved from 113.42788 to 108.46442, saving model to cp/weights-09-108.46.hdf5\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 63.6330 - mae: 63.8215 - val_loss: 108.4644 - val_mae: 107.3100\n",
            "Epoch 10/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 59.8286 - mae: 60.3267\n",
            "Epoch 00010: val_loss improved from 108.46442 to 100.73010, saving model to cp/weights-10-100.73.hdf5\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 60.8863 - mae: 61.0817 - val_loss: 100.7301 - val_mae: 99.5925\n",
            "Epoch 11/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 58.0783 - mae: 58.5765\n",
            "Epoch 00011: val_loss improved from 100.73010 to 96.00913, saving model to cp/weights-11-96.01.hdf5\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 59.1509 - mae: 59.3421 - val_loss: 96.0091 - val_mae: 94.9299\n",
            "Epoch 12/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 56.4367 - mae: 56.9347\n",
            "Epoch 00012: val_loss improved from 96.00913 to 95.78242, saving model to cp/weights-12-95.78.hdf5\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 57.4556 - mae: 57.6620 - val_loss: 95.7824 - val_mae: 94.7504\n",
            "Epoch 13/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 55.2800 - mae: 55.7781\n",
            "Epoch 00013: val_loss improved from 95.78242 to 94.43473, saving model to cp/weights-13-94.43.hdf5\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 56.3074 - mae: 56.5114 - val_loss: 94.4347 - val_mae: 93.4422\n",
            "Epoch 14/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 53.9608 - mae: 54.4587\n",
            "Epoch 00014: val_loss improved from 94.43473 to 91.96222, saving model to cp/weights-14-91.96.hdf5\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 54.9885 - mae: 55.1923 - val_loss: 91.9622 - val_mae: 91.0082\n",
            "Epoch 15/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 52.7446 - mae: 53.2424\n",
            "Epoch 00015: val_loss improved from 91.96222 to 90.04116, saving model to cp/weights-15-90.04.hdf5\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 53.8065 - mae: 54.0004 - val_loss: 90.0412 - val_mae: 89.1151\n",
            "Epoch 16/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 51.7216 - mae: 52.2193\n",
            "Epoch 00016: val_loss improved from 90.04116 to 87.58337, saving model to cp/weights-16-87.58.hdf5\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 52.6787 - mae: 52.9025 - val_loss: 87.5834 - val_mae: 86.6908\n",
            "Epoch 17/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 51.2221 - mae: 51.7197\n",
            "Epoch 00017: val_loss improved from 87.58337 to 86.13845, saving model to cp/weights-17-86.14.hdf5\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 52.2364 - mae: 52.4438 - val_loss: 86.1385 - val_mae: 85.2586\n",
            "Epoch 18/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 50.3833 - mae: 50.8810\n",
            "Epoch 00018: val_loss improved from 86.13845 to 85.58985, saving model to cp/weights-18-85.59.hdf5\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 51.3467 - mae: 51.5687 - val_loss: 85.5898 - val_mae: 84.7448\n",
            "Epoch 19/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 49.9001 - mae: 50.3978\n",
            "Epoch 00019: val_loss improved from 85.58985 to 83.42792, saving model to cp/weights-19-83.43.hdf5\n",
            "30/30 [==============================] - 5s 166ms/step - loss: 50.8889 - mae: 51.1037 - val_loss: 83.4279 - val_mae: 82.6065\n",
            "Epoch 20/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 49.5078 - mae: 50.0055\n",
            "Epoch 00020: val_loss did not improve from 83.42792\n",
            "30/30 [==============================] - 5s 166ms/step - loss: 50.4305 - mae: 50.6641 - val_loss: 86.4467 - val_mae: 85.6367\n",
            "Epoch 21/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 48.6454 - mae: 49.1427\n",
            "Epoch 00021: val_loss did not improve from 83.42792\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 49.5673 - mae: 49.8008 - val_loss: 84.7949 - val_mae: 84.0272\n",
            "Epoch 22/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 48.1992 - mae: 48.6966\n",
            "Epoch 00022: val_loss did not improve from 83.42792\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 49.1854 - mae: 49.4006 - val_loss: 85.0175 - val_mae: 84.2429\n",
            "Epoch 23/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 47.8047 - mae: 48.3021\n",
            "Epoch 00023: val_loss improved from 83.42792 to 83.22056, saving model to cp/weights-23-83.22.hdf5\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 48.7318 - mae: 48.9639 - val_loss: 83.2206 - val_mae: 82.4671\n",
            "Epoch 24/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 47.2063 - mae: 47.7038\n",
            "Epoch 00024: val_loss improved from 83.22056 to 82.43099, saving model to cp/weights-24-82.43.hdf5\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 48.1711 - mae: 48.3925 - val_loss: 82.4310 - val_mae: 81.6983\n",
            "Epoch 25/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 46.5106 - mae: 47.0079\n",
            "Epoch 00025: val_loss did not improve from 82.43099\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 47.4660 - mae: 47.6899 - val_loss: 83.1928 - val_mae: 82.4917\n",
            "Epoch 26/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 46.3745 - mae: 46.8719\n",
            "Epoch 00026: val_loss improved from 82.43099 to 82.04090, saving model to cp/weights-26-82.04.hdf5\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 47.2887 - mae: 47.5245 - val_loss: 82.0409 - val_mae: 81.3602\n",
            "Epoch 27/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 46.0503 - mae: 46.5476\n",
            "Epoch 00027: val_loss did not improve from 82.04090\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 46.9915 - mae: 47.2196 - val_loss: 82.7869 - val_mae: 82.1007\n",
            "Epoch 28/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 45.3877 - mae: 45.8850\n",
            "Epoch 00028: val_loss improved from 82.04090 to 80.91289, saving model to cp/weights-28-80.91.hdf5\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 46.2422 - mae: 46.4949 - val_loss: 80.9129 - val_mae: 80.2744\n",
            "Epoch 29/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 45.0994 - mae: 45.5965\n",
            "Epoch 00029: val_loss improved from 80.91289 to 79.59624, saving model to cp/weights-29-79.60.hdf5\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 45.9816 - mae: 46.2263 - val_loss: 79.5962 - val_mae: 78.9497\n",
            "Epoch 30/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 44.5280 - mae: 45.0252\n",
            "Epoch 00030: val_loss did not improve from 79.59624\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 45.3884 - mae: 45.6393 - val_loss: 80.9920 - val_mae: 80.3736\n",
            "Epoch 31/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 44.1557 - mae: 44.6529\n",
            "Epoch 00031: val_loss improved from 79.59624 to 76.68968, saving model to cp/weights-31-76.69.hdf5\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 45.0644 - mae: 45.3016 - val_loss: 76.6897 - val_mae: 76.1020\n",
            "Epoch 32/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 43.5849 - mae: 44.0818\n",
            "Epoch 00032: val_loss did not improve from 76.68968\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 44.5122 - mae: 44.7438 - val_loss: 78.4085 - val_mae: 77.8317\n",
            "Epoch 33/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 43.2736 - mae: 43.7708\n",
            "Epoch 00033: val_loss improved from 76.68968 to 75.17884, saving model to cp/weights-33-75.18.hdf5\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 44.1304 - mae: 44.3824 - val_loss: 75.1788 - val_mae: 74.6228\n",
            "Epoch 34/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 42.9373 - mae: 43.4345\n",
            "Epoch 00034: val_loss did not improve from 75.17884\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 43.8247 - mae: 44.0680 - val_loss: 78.7703 - val_mae: 78.2438\n",
            "Epoch 35/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 42.6081 - mae: 43.1051\n",
            "Epoch 00035: val_loss improved from 75.17884 to 74.49160, saving model to cp/weights-35-74.49.hdf5\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 43.5132 - mae: 43.7513 - val_loss: 74.4916 - val_mae: 73.9488\n",
            "Epoch 36/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 42.3677 - mae: 42.8647\n",
            "Epoch 00036: val_loss did not improve from 74.49160\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 43.1888 - mae: 43.4509 - val_loss: 76.7777 - val_mae: 76.2837\n",
            "Epoch 37/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 42.0006 - mae: 42.4977\n",
            "Epoch 00037: val_loss improved from 74.49160 to 70.68408, saving model to cp/weights-37-70.68.hdf5\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 42.8845 - mae: 43.1287 - val_loss: 70.6841 - val_mae: 70.1732\n",
            "Epoch 38/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 41.6598 - mae: 42.1566\n",
            "Epoch 00038: val_loss did not improve from 70.68408\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 42.5124 - mae: 42.7653 - val_loss: 76.5735 - val_mae: 76.0788\n",
            "Epoch 39/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 41.2903 - mae: 41.7874\n",
            "Epoch 00039: val_loss did not improve from 70.68408\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 42.2967 - mae: 42.5058 - val_loss: 73.9381 - val_mae: 73.4686\n",
            "Epoch 40/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 40.8910 - mae: 41.3880\n",
            "Epoch 00040: val_loss improved from 70.68408 to 68.73358, saving model to cp/weights-40-68.73.hdf5\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 41.7880 - mae: 42.0283 - val_loss: 68.7336 - val_mae: 68.2745\n",
            "Epoch 41/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 40.5983 - mae: 41.0953\n",
            "Epoch 00041: val_loss did not improve from 68.73358\n",
            "30/30 [==============================] - 5s 166ms/step - loss: 41.4687 - mae: 41.7166 - val_loss: 73.2826 - val_mae: 72.8490\n",
            "Epoch 42/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 40.4118 - mae: 40.9086\n",
            "Epoch 00042: val_loss did not improve from 68.73358\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 41.3215 - mae: 41.5580 - val_loss: 71.1626 - val_mae: 70.7371\n",
            "Epoch 43/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 40.1533 - mae: 40.6501\n",
            "Epoch 00043: val_loss improved from 68.73358 to 66.99402, saving model to cp/weights-43-66.99.hdf5\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 41.0156 - mae: 41.2656 - val_loss: 66.9940 - val_mae: 66.5624\n",
            "Epoch 44/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 40.0923 - mae: 40.5891\n",
            "Epoch 00044: val_loss did not improve from 66.99402\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 40.9698 - mae: 41.2155 - val_loss: 69.3812 - val_mae: 69.0054\n",
            "Epoch 45/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 39.4324 - mae: 39.9291\n",
            "Epoch 00045: val_loss did not improve from 66.99402\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 40.2912 - mae: 40.5422 - val_loss: 69.4131 - val_mae: 69.0297\n",
            "Epoch 46/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 39.2711 - mae: 39.7678\n",
            "Epoch 00046: val_loss did not improve from 66.99402\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 40.1500 - mae: 40.3952 - val_loss: 71.5698 - val_mae: 71.2206\n",
            "Epoch 47/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 39.0131 - mae: 39.5097\n",
            "Epoch 00047: val_loss did not improve from 66.99402\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 39.8932 - mae: 40.1379 - val_loss: 68.5707 - val_mae: 68.2312\n",
            "Epoch 48/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 38.9070 - mae: 39.4037\n",
            "Epoch 00048: val_loss did not improve from 66.99402\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 39.7879 - mae: 40.0326 - val_loss: 70.2224 - val_mae: 69.8870\n",
            "Epoch 49/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 38.6256 - mae: 39.1221\n",
            "Epoch 00049: val_loss did not improve from 66.99402\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 39.4859 - mae: 39.7363 - val_loss: 67.0844 - val_mae: 66.7401\n",
            "Epoch 50/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 38.0278 - mae: 38.5242\n",
            "Epoch 00050: val_loss did not improve from 66.99402\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 38.8928 - mae: 39.1418 - val_loss: 68.8309 - val_mae: 68.4957\n",
            "Epoch 51/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 38.1653 - mae: 38.6618\n",
            "Epoch 00051: val_loss did not improve from 66.99402\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 38.9369 - mae: 39.2126 - val_loss: 68.8180 - val_mae: 68.4835\n",
            "Epoch 52/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 37.7542 - mae: 38.2506\n",
            "Epoch 00052: val_loss did not improve from 66.99402\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 38.5573 - mae: 38.8239 - val_loss: 72.5164 - val_mae: 72.1994\n",
            "Epoch 53/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 37.6906 - mae: 38.1872\n",
            "Epoch 00053: val_loss improved from 66.99402 to 65.91949, saving model to cp/weights-53-65.92.hdf5\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 38.5081 - mae: 38.7708 - val_loss: 65.9195 - val_mae: 65.6236\n",
            "Epoch 54/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 37.1717 - mae: 37.6683\n",
            "Epoch 00054: val_loss improved from 65.91949 to 65.38023, saving model to cp/weights-54-65.38.hdf5\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 38.0524 - mae: 38.2970 - val_loss: 65.3802 - val_mae: 65.0797\n",
            "Epoch 55/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 36.8933 - mae: 37.3897\n",
            "Epoch 00055: val_loss did not improve from 65.38023\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 37.6943 - mae: 37.9615 - val_loss: 66.6009 - val_mae: 66.3170\n",
            "Epoch 56/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 36.8722 - mae: 37.3684\n",
            "Epoch 00056: val_loss did not improve from 65.38023\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 37.6712 - mae: 37.9388 - val_loss: 66.2797 - val_mae: 66.0015\n",
            "Epoch 57/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 36.6378 - mae: 37.1342\n",
            "Epoch 00057: val_loss did not improve from 65.38023\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 37.5224 - mae: 37.7656 - val_loss: 66.0256 - val_mae: 65.7591\n",
            "Epoch 58/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 36.5918 - mae: 37.0880\n",
            "Epoch 00058: val_loss did not improve from 65.38023\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 37.4143 - mae: 37.6751 - val_loss: 66.3167 - val_mae: 66.0555\n",
            "Epoch 59/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 36.3797 - mae: 36.8761\n",
            "Epoch 00059: val_loss improved from 65.38023 to 65.24300, saving model to cp/weights-59-65.24.hdf5\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 37.1727 - mae: 37.4421 - val_loss: 65.2430 - val_mae: 64.9913\n",
            "Epoch 60/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 36.1595 - mae: 36.6559\n",
            "Epoch 00060: val_loss improved from 65.24300 to 64.59462, saving model to cp/weights-60-64.59.hdf5\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 37.0424 - mae: 37.2862 - val_loss: 64.5946 - val_mae: 64.3481\n",
            "Epoch 61/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 35.7776 - mae: 36.2737\n",
            "Epoch 00061: val_loss improved from 64.59462 to 62.15728, saving model to cp/weights-61-62.16.hdf5\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 36.6594 - mae: 36.9032 - val_loss: 62.1573 - val_mae: 61.9321\n",
            "Epoch 62/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 35.4736 - mae: 35.9699\n",
            "Epoch 00062: val_loss improved from 62.15728 to 61.72317, saving model to cp/weights-62-61.72.hdf5\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 36.2313 - mae: 36.5108 - val_loss: 61.7232 - val_mae: 61.4902\n",
            "Epoch 63/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 35.1326 - mae: 35.6288\n",
            "Epoch 00063: val_loss improved from 61.72317 to 61.28882, saving model to cp/weights-63-61.29.hdf5\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 35.9757 - mae: 36.2307 - val_loss: 61.2888 - val_mae: 61.0782\n",
            "Epoch 64/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 35.1395 - mae: 35.6359\n",
            "Epoch 00064: val_loss did not improve from 61.28882\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 36.0135 - mae: 36.2598 - val_loss: 61.6203 - val_mae: 61.4119\n",
            "Epoch 65/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 34.8808 - mae: 35.3768\n",
            "Epoch 00065: val_loss did not improve from 61.28882\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 35.6852 - mae: 35.9511 - val_loss: 64.0779 - val_mae: 63.8589\n",
            "Epoch 66/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 34.7749 - mae: 35.2711\n",
            "Epoch 00066: val_loss improved from 61.28882 to 60.76210, saving model to cp/weights-66-60.76.hdf5\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 35.6016 - mae: 35.8612 - val_loss: 60.7621 - val_mae: 60.5594\n",
            "Epoch 67/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 34.4037 - mae: 34.8999\n",
            "Epoch 00067: val_loss improved from 60.76210 to 59.57389, saving model to cp/weights-67-59.57.hdf5\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 35.2391 - mae: 35.4962 - val_loss: 59.5739 - val_mae: 59.3845\n",
            "Epoch 68/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 34.1696 - mae: 34.6656\n",
            "Epoch 00068: val_loss improved from 59.57389 to 59.50669, saving model to cp/weights-68-59.51.hdf5\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 34.9901 - mae: 35.2514 - val_loss: 59.5067 - val_mae: 59.3202\n",
            "Epoch 69/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 34.1340 - mae: 34.6300\n",
            "Epoch 00069: val_loss did not improve from 59.50669\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 34.9704 - mae: 35.2270 - val_loss: 63.7309 - val_mae: 63.5607\n",
            "Epoch 70/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 34.0370 - mae: 34.5331\n",
            "Epoch 00070: val_loss did not improve from 59.50669\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 34.8785 - mae: 35.1338 - val_loss: 62.9755 - val_mae: 62.7896\n",
            "Epoch 71/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 33.9569 - mae: 34.4529\n",
            "Epoch 00071: val_loss did not improve from 59.50669\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 34.7764 - mae: 35.0379 - val_loss: 62.8927 - val_mae: 62.7023\n",
            "Epoch 72/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 33.5422 - mae: 34.0383\n",
            "Epoch 00072: val_loss did not improve from 59.50669\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 34.3430 - mae: 34.6099 - val_loss: 60.1055 - val_mae: 59.9317\n",
            "Epoch 73/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 33.2694 - mae: 33.7653\n",
            "Epoch 00073: val_loss did not improve from 59.50669\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 34.0916 - mae: 34.3523 - val_loss: 65.2400 - val_mae: 65.0709\n",
            "Epoch 74/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 33.3841 - mae: 33.8798\n",
            "Epoch 00074: val_loss did not improve from 59.50669\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 34.1967 - mae: 34.4599 - val_loss: 61.2188 - val_mae: 61.0382\n",
            "Epoch 75/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 33.0978 - mae: 33.5939\n",
            "Epoch 00075: val_loss did not improve from 59.50669\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 33.8764 - mae: 34.1498 - val_loss: 60.7831 - val_mae: 60.6116\n",
            "Epoch 76/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 32.9293 - mae: 33.4252\n",
            "Epoch 00076: val_loss did not improve from 59.50669\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 33.7482 - mae: 34.0098 - val_loss: 61.7638 - val_mae: 61.5894\n",
            "Epoch 77/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 32.8165 - mae: 33.3124\n",
            "Epoch 00077: val_loss did not improve from 59.50669\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 33.6634 - mae: 33.9170 - val_loss: 61.0802 - val_mae: 60.9200\n",
            "Epoch 78/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 32.7187 - mae: 33.2146\n",
            "Epoch 00078: val_loss did not improve from 59.50669\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 33.5808 - mae: 33.8301 - val_loss: 60.0692 - val_mae: 59.9289\n",
            "Epoch 79/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 32.4359 - mae: 32.9319\n",
            "Epoch 00079: val_loss did not improve from 59.50669\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 33.3158 - mae: 33.5600 - val_loss: 60.6695 - val_mae: 60.5143\n",
            "Epoch 80/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 32.3485 - mae: 32.8444\n",
            "Epoch 00080: val_loss did not improve from 59.50669\n",
            "30/30 [==============================] - 5s 166ms/step - loss: 33.1697 - mae: 33.4306 - val_loss: 62.9233 - val_mae: 62.7493\n",
            "Epoch 81/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 32.1502 - mae: 32.6460\n",
            "Epoch 00081: val_loss improved from 59.50669 to 57.34801, saving model to cp/weights-81-57.35.hdf5\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 32.9549 - mae: 33.2205 - val_loss: 57.3480 - val_mae: 57.1774\n",
            "Epoch 82/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 32.0295 - mae: 32.5252\n",
            "Epoch 00082: val_loss did not improve from 57.34801\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 32.8228 - mae: 33.0915 - val_loss: 59.7610 - val_mae: 59.5836\n",
            "Epoch 83/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 31.8153 - mae: 32.3111\n",
            "Epoch 00083: val_loss improved from 57.34801 to 54.18125, saving model to cp/weights-83-54.18.hdf5\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 32.6725 - mae: 32.9231 - val_loss: 54.1812 - val_mae: 54.0349\n",
            "Epoch 84/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 31.6266 - mae: 32.1223\n",
            "Epoch 00084: val_loss did not improve from 54.18125\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 32.4303 - mae: 32.6960 - val_loss: 60.8899 - val_mae: 60.7345\n",
            "Epoch 85/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 31.4766 - mae: 31.9723\n",
            "Epoch 00085: val_loss did not improve from 54.18125\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 32.2928 - mae: 32.5550 - val_loss: 59.1957 - val_mae: 59.0255\n",
            "Epoch 86/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 31.1620 - mae: 31.6576\n",
            "Epoch 00086: val_loss did not improve from 54.18125\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 31.9284 - mae: 32.2047 - val_loss: 58.1998 - val_mae: 58.0599\n",
            "Epoch 87/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 31.2415 - mae: 31.7373\n",
            "Epoch 00087: val_loss did not improve from 54.18125\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 32.0040 - mae: 32.2817 - val_loss: 60.5571 - val_mae: 60.4161\n",
            "Epoch 88/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 31.2413 - mae: 31.7368\n",
            "Epoch 00088: val_loss did not improve from 54.18125\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 31.9751 - mae: 32.2607 - val_loss: 58.0874 - val_mae: 57.9287\n",
            "Epoch 89/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 30.9237 - mae: 31.4193\n",
            "Epoch 00089: val_loss did not improve from 54.18125\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 31.7710 - mae: 32.0242 - val_loss: 61.6953 - val_mae: 61.5211\n",
            "Epoch 90/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 30.8635 - mae: 31.3592\n",
            "Epoch 00090: val_loss did not improve from 54.18125\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 31.6426 - mae: 31.9153 - val_loss: 58.6042 - val_mae: 58.3944\n",
            "Epoch 91/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 30.4850 - mae: 30.9805\n",
            "Epoch 00091: val_loss did not improve from 54.18125\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 31.2352 - mae: 31.5160 - val_loss: 59.1422 - val_mae: 58.9838\n",
            "Epoch 92/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 30.3773 - mae: 30.8730\n",
            "Epoch 00092: val_loss did not improve from 54.18125\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 31.1307 - mae: 31.4108 - val_loss: 60.4599 - val_mae: 60.2715\n",
            "Epoch 93/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 30.1993 - mae: 30.6949\n",
            "Epoch 00093: val_loss did not improve from 54.18125\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 31.0480 - mae: 31.3008 - val_loss: 55.9137 - val_mae: 55.7228\n",
            "Epoch 94/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 29.9202 - mae: 30.4158\n",
            "Epoch 00094: val_loss did not improve from 54.18125\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 30.7170 - mae: 30.9846 - val_loss: 57.2531 - val_mae: 57.0829\n",
            "Epoch 95/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 29.9514 - mae: 30.4467\n",
            "Epoch 00095: val_loss did not improve from 54.18125\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 30.7973 - mae: 31.0506 - val_loss: 58.0529 - val_mae: 57.8914\n",
            "Epoch 96/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 29.8491 - mae: 30.3446\n",
            "Epoch 00096: val_loss did not improve from 54.18125\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 30.5677 - mae: 30.8577 - val_loss: 55.8318 - val_mae: 55.6811\n",
            "Epoch 97/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 29.6539 - mae: 30.1490\n",
            "Epoch 00097: val_loss improved from 54.18125 to 52.66939, saving model to cp/weights-97-52.67.hdf5\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 30.4729 - mae: 30.7338 - val_loss: 52.6694 - val_mae: 52.5182\n",
            "Epoch 98/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 29.4176 - mae: 29.9131\n",
            "Epoch 00098: val_loss did not improve from 52.66939\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 30.2319 - mae: 30.4944 - val_loss: 54.7632 - val_mae: 54.5706\n",
            "Epoch 99/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 29.5051 - mae: 30.0002\n",
            "Epoch 00099: val_loss did not improve from 52.66939\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 30.2394 - mae: 30.5244 - val_loss: 56.4286 - val_mae: 56.2620\n",
            "Epoch 100/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 29.4199 - mae: 29.9152\n",
            "Epoch 00100: val_loss did not improve from 52.66939\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 30.2040 - mae: 30.4750 - val_loss: 56.9748 - val_mae: 56.8089\n",
            "Epoch 101/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 29.1949 - mae: 29.6902\n",
            "Epoch 00101: val_loss did not improve from 52.66939\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 29.9773 - mae: 30.2487 - val_loss: 54.3042 - val_mae: 54.1506\n",
            "Epoch 102/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 29.0750 - mae: 29.5704\n",
            "Epoch 00102: val_loss did not improve from 52.66939\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 29.8992 - mae: 30.1587 - val_loss: 55.8028 - val_mae: 55.6522\n",
            "Epoch 103/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 28.9542 - mae: 29.4498\n",
            "Epoch 00103: val_loss did not improve from 52.66939\n",
            "30/30 [==============================] - 5s 166ms/step - loss: 29.7245 - mae: 29.9996 - val_loss: 57.5454 - val_mae: 57.3671\n",
            "Epoch 104/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 28.6716 - mae: 29.1669\n",
            "Epoch 00104: val_loss did not improve from 52.66939\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 29.4361 - mae: 29.7126 - val_loss: 54.3354 - val_mae: 54.1597\n",
            "Epoch 105/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 28.4221 - mae: 28.9174\n",
            "Epoch 00105: val_loss did not improve from 52.66939\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 29.2148 - mae: 29.4833 - val_loss: 58.5698 - val_mae: 58.4318\n",
            "Epoch 106/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 28.6622 - mae: 29.1574\n",
            "Epoch 00106: val_loss did not improve from 52.66939\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 29.3984 - mae: 29.6830 - val_loss: 56.6826 - val_mae: 56.5269\n",
            "Epoch 107/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 28.5453 - mae: 29.0406\n",
            "Epoch 00107: val_loss did not improve from 52.66939\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 29.3070 - mae: 29.5843 - val_loss: 56.7870 - val_mae: 56.5995\n",
            "Epoch 108/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 28.1899 - mae: 28.6852\n",
            "Epoch 00108: val_loss did not improve from 52.66939\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 28.9498 - mae: 29.2276 - val_loss: 54.1588 - val_mae: 53.9253\n",
            "Epoch 109/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 28.0343 - mae: 28.5295\n",
            "Epoch 00109: val_loss did not improve from 52.66939\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 28.7350 - mae: 29.0297 - val_loss: 54.1760 - val_mae: 53.9633\n",
            "Epoch 110/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 27.7259 - mae: 28.2206\n",
            "Epoch 00110: val_loss improved from 52.66939 to 51.40540, saving model to cp/weights-110-51.41.hdf5\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 28.5480 - mae: 28.8075 - val_loss: 51.4054 - val_mae: 51.1911\n",
            "Epoch 111/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 27.5226 - mae: 28.0176\n",
            "Epoch 00111: val_loss did not improve from 51.40540\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 28.3185 - mae: 28.5858 - val_loss: 52.3407 - val_mae: 52.1407\n",
            "Epoch 112/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 27.4581 - mae: 27.9528\n",
            "Epoch 00112: val_loss did not improve from 51.40540\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 28.2433 - mae: 28.5133 - val_loss: 58.5898 - val_mae: 58.4058\n",
            "Epoch 113/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 27.5086 - mae: 28.0037\n",
            "Epoch 00113: val_loss did not improve from 51.40540\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 28.2729 - mae: 28.5493 - val_loss: 56.3483 - val_mae: 56.1875\n",
            "Epoch 114/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 27.3614 - mae: 27.8563\n",
            "Epoch 00114: val_loss did not improve from 51.40540\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 28.1650 - mae: 28.4300 - val_loss: 53.5673 - val_mae: 53.4239\n",
            "Epoch 115/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 27.1128 - mae: 27.6079\n",
            "Epoch 00115: val_loss did not improve from 51.40540\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 27.9076 - mae: 28.1753 - val_loss: 52.5569 - val_mae: 52.4238\n",
            "Epoch 116/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 27.1012 - mae: 27.5960\n",
            "Epoch 00116: val_loss did not improve from 51.40540\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 27.8064 - mae: 28.0995 - val_loss: 55.3251 - val_mae: 55.1803\n",
            "Epoch 117/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 26.9313 - mae: 27.4260\n",
            "Epoch 00117: val_loss did not improve from 51.40540\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 27.6876 - mae: 27.9659 - val_loss: 54.2344 - val_mae: 54.0937\n",
            "Epoch 118/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 26.8505 - mae: 27.3454\n",
            "Epoch 00118: val_loss did not improve from 51.40540\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 27.6450 - mae: 27.9126 - val_loss: 51.6374 - val_mae: 51.5321\n",
            "Epoch 119/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 26.6936 - mae: 27.1886\n",
            "Epoch 00119: val_loss did not improve from 51.40540\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 27.4912 - mae: 27.7579 - val_loss: 53.5463 - val_mae: 53.4170\n",
            "Epoch 120/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 26.6572 - mae: 27.1519\n",
            "Epoch 00120: val_loss did not improve from 51.40540\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 27.3901 - mae: 27.6751 - val_loss: 52.7857 - val_mae: 52.6410\n",
            "Epoch 121/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 26.4655 - mae: 26.9601\n",
            "Epoch 00121: val_loss did not improve from 51.40540\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 27.2309 - mae: 27.5065 - val_loss: 53.0352 - val_mae: 52.9078\n",
            "Epoch 122/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 26.3182 - mae: 26.8129\n",
            "Epoch 00122: val_loss did not improve from 51.40540\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 27.0606 - mae: 27.3430 - val_loss: 54.6802 - val_mae: 54.5771\n",
            "Epoch 123/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 26.3404 - mae: 26.8351\n",
            "Epoch 00123: val_loss did not improve from 51.40540\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 27.1509 - mae: 27.4138 - val_loss: 53.3977 - val_mae: 53.2588\n",
            "Epoch 124/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 26.1103 - mae: 26.6052\n",
            "Epoch 00124: val_loss did not improve from 51.40540\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 26.8641 - mae: 27.1433 - val_loss: 53.7363 - val_mae: 53.5822\n",
            "Epoch 125/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 25.7869 - mae: 26.2814\n",
            "Epoch 00125: val_loss did not improve from 51.40540\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 26.5079 - mae: 26.7961 - val_loss: 54.9190 - val_mae: 54.7954\n",
            "Epoch 126/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 25.8270 - mae: 26.3217\n",
            "Epoch 00126: val_loss improved from 51.40540 to 50.81170, saving model to cp/weights-126-50.81.hdf5\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 26.6226 - mae: 26.8897 - val_loss: 50.8117 - val_mae: 50.6736\n",
            "Epoch 127/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 25.7277 - mae: 26.2222\n",
            "Epoch 00127: val_loss improved from 50.81170 to 50.47698, saving model to cp/weights-127-50.48.hdf5\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 26.4887 - mae: 26.7655 - val_loss: 50.4770 - val_mae: 50.3355\n",
            "Epoch 128/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 25.3590 - mae: 25.8534\n",
            "Epoch 00128: val_loss did not improve from 50.47698\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 26.1165 - mae: 26.3942 - val_loss: 53.2674 - val_mae: 53.1094\n",
            "Epoch 129/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 25.4768 - mae: 25.9712\n",
            "Epoch 00129: val_loss did not improve from 50.47698\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 26.2644 - mae: 26.5334 - val_loss: 53.6090 - val_mae: 53.4548\n",
            "Epoch 130/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 25.3348 - mae: 25.8290\n",
            "Epoch 00130: val_loss did not improve from 50.47698\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 26.0985 - mae: 26.3742 - val_loss: 51.1665 - val_mae: 51.0158\n",
            "Epoch 131/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 25.3612 - mae: 25.8555\n",
            "Epoch 00131: val_loss improved from 50.47698 to 49.50316, saving model to cp/weights-131-49.50.hdf5\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 26.1063 - mae: 26.3874 - val_loss: 49.5032 - val_mae: 49.3617\n",
            "Epoch 132/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 25.0336 - mae: 25.5278\n",
            "Epoch 00132: val_loss improved from 49.50316 to 48.92796, saving model to cp/weights-132-48.93.hdf5\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 25.7739 - mae: 26.0563 - val_loss: 48.9280 - val_mae: 48.7764\n",
            "Epoch 133/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 24.8556 - mae: 25.3497\n",
            "Epoch 00133: val_loss did not improve from 48.92796\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 25.5790 - mae: 25.8662 - val_loss: 51.7179 - val_mae: 51.5390\n",
            "Epoch 134/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 25.0071 - mae: 25.5017\n",
            "Epoch 00134: val_loss did not improve from 48.92796\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 25.7586 - mae: 26.0381 - val_loss: 51.8095 - val_mae: 51.6687\n",
            "Epoch 135/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 24.7254 - mae: 25.2197\n",
            "Epoch 00135: val_loss improved from 48.92796 to 48.48290, saving model to cp/weights-135-48.48.hdf5\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 25.4758 - mae: 25.7554 - val_loss: 48.4829 - val_mae: 48.3797\n",
            "Epoch 136/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 24.6657 - mae: 25.1599\n",
            "Epoch 00136: val_loss did not improve from 48.48290\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 25.4001 - mae: 25.6842 - val_loss: 54.5956 - val_mae: 54.4457\n",
            "Epoch 137/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 24.5933 - mae: 25.0878\n",
            "Epoch 00137: val_loss did not improve from 48.48290\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 25.3856 - mae: 25.6534 - val_loss: 49.1146 - val_mae: 48.9795\n",
            "Epoch 138/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 24.5276 - mae: 25.0219\n",
            "Epoch 00138: val_loss did not improve from 48.48290\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 25.2739 - mae: 25.5547 - val_loss: 50.7710 - val_mae: 50.6165\n",
            "Epoch 139/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 24.3147 - mae: 24.8090\n",
            "Epoch 00139: val_loss did not improve from 48.48290\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 25.1112 - mae: 25.3776 - val_loss: 54.5610 - val_mae: 54.3775\n",
            "Epoch 140/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 24.1678 - mae: 24.6619\n",
            "Epoch 00140: val_loss did not improve from 48.48290\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 24.9480 - mae: 25.2189 - val_loss: 54.5936 - val_mae: 54.4501\n",
            "Epoch 141/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 24.2292 - mae: 24.7235\n",
            "Epoch 00141: val_loss did not improve from 48.48290\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 24.9376 - mae: 25.2292 - val_loss: 52.2689 - val_mae: 52.1110\n",
            "Epoch 142/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 24.1072 - mae: 24.6014\n",
            "Epoch 00142: val_loss did not improve from 48.48290\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 24.9218 - mae: 25.1829 - val_loss: 52.6348 - val_mae: 52.4924\n",
            "Epoch 143/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 23.9954 - mae: 24.4896\n",
            "Epoch 00143: val_loss did not improve from 48.48290\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 24.7227 - mae: 25.0088 - val_loss: 51.4305 - val_mae: 51.2977\n",
            "Epoch 144/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 23.9469 - mae: 24.4411\n",
            "Epoch 00144: val_loss did not improve from 48.48290\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 24.7724 - mae: 25.0305 - val_loss: 50.2006 - val_mae: 50.0693\n",
            "Epoch 145/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 23.8333 - mae: 24.3275\n",
            "Epoch 00145: val_loss did not improve from 48.48290\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 24.5575 - mae: 24.8446 - val_loss: 51.3219 - val_mae: 51.1642\n",
            "Epoch 146/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 23.8005 - mae: 24.2946\n",
            "Epoch 00146: val_loss did not improve from 48.48290\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 24.5716 - mae: 24.8451 - val_loss: 50.7846 - val_mae: 50.6108\n",
            "Epoch 147/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 23.5123 - mae: 24.0062\n",
            "Epoch 00147: val_loss did not improve from 48.48290\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 24.2911 - mae: 24.5622 - val_loss: 50.4874 - val_mae: 50.3363\n",
            "Epoch 148/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 23.5448 - mae: 24.0389\n",
            "Epoch 00148: val_loss improved from 48.48290 to 46.40467, saving model to cp/weights-148-46.40.hdf5\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 24.2600 - mae: 24.5494 - val_loss: 46.4047 - val_mae: 46.2323\n",
            "Epoch 149/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 23.3314 - mae: 23.8251\n",
            "Epoch 00149: val_loss did not improve from 46.40467\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 24.0137 - mae: 24.3123 - val_loss: 47.3117 - val_mae: 47.1674\n",
            "Epoch 150/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 23.3068 - mae: 23.8007\n",
            "Epoch 00150: val_loss did not improve from 46.40467\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 24.1018 - mae: 24.3683 - val_loss: 49.0735 - val_mae: 48.8660\n",
            "Epoch 151/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 23.1600 - mae: 23.6537\n",
            "Epoch 00151: val_loss improved from 46.40467 to 43.78492, saving model to cp/weights-151-43.78.hdf5\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 23.9250 - mae: 24.1999 - val_loss: 43.7849 - val_mae: 43.6053\n",
            "Epoch 152/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 23.3242 - mae: 23.8185\n",
            "Epoch 00152: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 24.0737 - mae: 24.3536 - val_loss: 50.3728 - val_mae: 50.2491\n",
            "Epoch 153/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 23.2720 - mae: 23.7663\n",
            "Epoch 00153: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 23.9672 - mae: 24.2626 - val_loss: 48.0664 - val_mae: 47.8590\n",
            "Epoch 154/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 23.0164 - mae: 23.5102\n",
            "Epoch 00154: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 23.7520 - mae: 24.0354 - val_loss: 48.0415 - val_mae: 47.8461\n",
            "Epoch 155/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 22.7025 - mae: 23.1960\n",
            "Epoch 00155: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 23.3900 - mae: 23.6869 - val_loss: 48.6512 - val_mae: 48.4585\n",
            "Epoch 156/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 22.5394 - mae: 23.0329\n",
            "Epoch 00156: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 23.2781 - mae: 23.5602 - val_loss: 49.4343 - val_mae: 49.2465\n",
            "Epoch 157/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 22.3929 - mae: 22.8863\n",
            "Epoch 00157: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 23.1313 - mae: 23.4135 - val_loss: 45.4537 - val_mae: 45.2967\n",
            "Epoch 158/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 22.1935 - mae: 22.6870\n",
            "Epoch 00158: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 22.9367 - mae: 23.2176 - val_loss: 47.3766 - val_mae: 47.2217\n",
            "Epoch 159/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 22.2128 - mae: 22.7064\n",
            "Epoch 00159: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 22.9756 - mae: 23.2510 - val_loss: 48.0037 - val_mae: 47.8589\n",
            "Epoch 160/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 22.3858 - mae: 22.8791\n",
            "Epoch 00160: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 23.1231 - mae: 23.4056 - val_loss: 45.9433 - val_mae: 45.7984\n",
            "Epoch 161/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 22.0345 - mae: 22.5278\n",
            "Epoch 00161: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 22.7597 - mae: 23.0456 - val_loss: 49.0218 - val_mae: 48.8591\n",
            "Epoch 162/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 22.0936 - mae: 22.5869\n",
            "Epoch 00162: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 22.8570 - mae: 23.1319 - val_loss: 48.4687 - val_mae: 48.2974\n",
            "Epoch 163/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 22.0253 - mae: 22.5186\n",
            "Epoch 00163: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 22.7696 - mae: 23.0500 - val_loss: 47.5109 - val_mae: 47.3714\n",
            "Epoch 164/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 21.7496 - mae: 22.2428\n",
            "Epoch 00164: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 22.5164 - mae: 22.7903 - val_loss: 51.1709 - val_mae: 51.0364\n",
            "Epoch 165/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 22.0024 - mae: 22.4962\n",
            "Epoch 00165: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 22.6934 - mae: 22.9895 - val_loss: 47.5284 - val_mae: 47.3820\n",
            "Epoch 166/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 21.8364 - mae: 22.3300\n",
            "Epoch 00166: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 22.5596 - mae: 22.8463 - val_loss: 48.1190 - val_mae: 47.9572\n",
            "Epoch 167/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 21.9323 - mae: 22.4259\n",
            "Epoch 00167: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 22.6550 - mae: 22.9418 - val_loss: 44.6480 - val_mae: 44.5046\n",
            "Epoch 168/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 21.5129 - mae: 22.0059\n",
            "Epoch 00168: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 22.3013 - mae: 22.5688 - val_loss: 46.4780 - val_mae: 46.3280\n",
            "Epoch 169/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 21.3961 - mae: 21.8894\n",
            "Epoch 00169: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 22.0890 - mae: 22.3840 - val_loss: 48.9081 - val_mae: 48.7711\n",
            "Epoch 170/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 21.4476 - mae: 21.9410\n",
            "Epoch 00170: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 22.1839 - mae: 22.4666 - val_loss: 45.9763 - val_mae: 45.8537\n",
            "Epoch 171/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 21.3865 - mae: 21.8799\n",
            "Epoch 00171: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 22.1342 - mae: 22.4137 - val_loss: 48.6919 - val_mae: 48.5777\n",
            "Epoch 172/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 21.3268 - mae: 21.8201\n",
            "Epoch 00172: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 22.0385 - mae: 22.3283 - val_loss: 48.3128 - val_mae: 48.1713\n",
            "Epoch 173/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 21.1231 - mae: 21.6165\n",
            "Epoch 00173: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 21.8617 - mae: 22.1438 - val_loss: 46.8760 - val_mae: 46.7134\n",
            "Epoch 174/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 21.0041 - mae: 21.4972\n",
            "Epoch 00174: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 21.7473 - mae: 22.0278 - val_loss: 44.8700 - val_mae: 44.7172\n",
            "Epoch 175/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 20.8718 - mae: 21.3645\n",
            "Epoch 00175: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 21.6330 - mae: 21.9079 - val_loss: 45.0242 - val_mae: 44.8404\n",
            "Epoch 176/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 20.8874 - mae: 21.3802\n",
            "Epoch 00176: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 21.6685 - mae: 21.9379 - val_loss: 46.0166 - val_mae: 45.8389\n",
            "Epoch 177/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 20.8474 - mae: 21.3404\n",
            "Epoch 00177: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 21.5467 - mae: 21.8397 - val_loss: 47.4014 - val_mae: 47.2280\n",
            "Epoch 178/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 20.7288 - mae: 21.2216\n",
            "Epoch 00178: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 21.4991 - mae: 21.7715 - val_loss: 43.8683 - val_mae: 43.7020\n",
            "Epoch 179/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 20.6936 - mae: 21.1866\n",
            "Epoch 00179: val_loss did not improve from 43.78492\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 21.4006 - mae: 21.6914 - val_loss: 47.6225 - val_mae: 47.4751\n",
            "Epoch 180/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 20.6227 - mae: 21.1159\n",
            "Epoch 00180: val_loss improved from 43.78492 to 43.71202, saving model to cp/weights-180-43.71.hdf5\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 21.3476 - mae: 21.6334 - val_loss: 43.7120 - val_mae: 43.5586\n",
            "Epoch 181/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 20.4846 - mae: 20.9775\n",
            "Epoch 00181: val_loss did not improve from 43.71202\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 21.1921 - mae: 21.4826 - val_loss: 47.1811 - val_mae: 47.0206\n",
            "Epoch 182/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 20.4821 - mae: 20.9748\n",
            "Epoch 00182: val_loss improved from 43.71202 to 39.55149, saving model to cp/weights-182-39.55.hdf5\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 21.1970 - mae: 21.4852 - val_loss: 39.5515 - val_mae: 39.4200\n",
            "Epoch 183/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 20.2945 - mae: 20.7873\n",
            "Epoch 00183: val_loss did not improve from 39.55149\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 20.9995 - mae: 21.2907 - val_loss: 43.0149 - val_mae: 42.8607\n",
            "Epoch 184/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 20.2555 - mae: 20.7480\n",
            "Epoch 00184: val_loss did not improve from 39.55149\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 20.9359 - mae: 21.2338 - val_loss: 45.4183 - val_mae: 45.2411\n",
            "Epoch 185/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 20.0770 - mae: 20.5695\n",
            "Epoch 00185: val_loss did not improve from 39.55149\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 20.7942 - mae: 21.0815 - val_loss: 40.1336 - val_mae: 39.9889\n",
            "Epoch 186/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 20.0904 - mae: 20.5831\n",
            "Epoch 00186: val_loss did not improve from 39.55149\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 20.8264 - mae: 21.1086 - val_loss: 46.0663 - val_mae: 45.8890\n",
            "Epoch 187/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 19.9164 - mae: 20.4090\n",
            "Epoch 00187: val_loss did not improve from 39.55149\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 20.6398 - mae: 20.9255 - val_loss: 43.8504 - val_mae: 43.6975\n",
            "Epoch 188/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 19.9656 - mae: 20.4582\n",
            "Epoch 00188: val_loss did not improve from 39.55149\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 20.6089 - mae: 20.9175 - val_loss: 40.0287 - val_mae: 39.8897\n",
            "Epoch 189/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 19.8621 - mae: 20.3543\n",
            "Epoch 00189: val_loss did not improve from 39.55149\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 20.5784 - mae: 20.8658 - val_loss: 45.1495 - val_mae: 44.9799\n",
            "Epoch 190/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 19.7868 - mae: 20.2792\n",
            "Epoch 00190: val_loss did not improve from 39.55149\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 20.5149 - mae: 20.7991 - val_loss: 40.6791 - val_mae: 40.5382\n",
            "Epoch 191/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 19.6478 - mae: 20.1400\n",
            "Epoch 00191: val_loss did not improve from 39.55149\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 20.3701 - mae: 20.6558 - val_loss: 40.4257 - val_mae: 40.2838\n",
            "Epoch 192/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 19.5414 - mae: 20.0333\n",
            "Epoch 00192: val_loss did not improve from 39.55149\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 20.2478 - mae: 20.5377 - val_loss: 39.6117 - val_mae: 39.4452\n",
            "Epoch 193/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 19.5474 - mae: 20.0401\n",
            "Epoch 00193: val_loss did not improve from 39.55149\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 20.2677 - mae: 20.5544 - val_loss: 44.3242 - val_mae: 44.1583\n",
            "Epoch 194/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 19.5280 - mae: 20.0204\n",
            "Epoch 00194: val_loss improved from 39.55149 to 38.05271, saving model to cp/weights-194-38.05.hdf5\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 20.2749 - mae: 20.5537 - val_loss: 38.0527 - val_mae: 37.9384\n",
            "Epoch 195/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 19.4656 - mae: 19.9579\n",
            "Epoch 00195: val_loss did not improve from 38.05271\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 20.1748 - mae: 20.4642 - val_loss: 42.3065 - val_mae: 42.1745\n",
            "Epoch 196/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 19.2900 - mae: 19.7818\n",
            "Epoch 00196: val_loss improved from 38.05271 to 38.00764, saving model to cp/weights-196-38.01.hdf5\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 19.9961 - mae: 20.2859 - val_loss: 38.0076 - val_mae: 37.8856\n",
            "Epoch 197/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 19.3112 - mae: 19.8036\n",
            "Epoch 00197: val_loss did not improve from 38.00764\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 20.0379 - mae: 20.3225 - val_loss: 39.9265 - val_mae: 39.7906\n",
            "Epoch 198/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 19.1834 - mae: 19.6755\n",
            "Epoch 00198: val_loss did not improve from 38.00764\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 19.8986 - mae: 20.1862 - val_loss: 38.2081 - val_mae: 38.0747\n",
            "Epoch 199/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 19.1233 - mae: 19.6157\n",
            "Epoch 00199: val_loss did not improve from 38.00764\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 19.8281 - mae: 20.1189 - val_loss: 43.0421 - val_mae: 42.9028\n",
            "Epoch 200/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 19.2432 - mae: 19.7357\n",
            "Epoch 00200: val_loss improved from 38.00764 to 36.37829, saving model to cp/weights-200-36.38.hdf5\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 19.8925 - mae: 20.1992 - val_loss: 36.3783 - val_mae: 36.2603\n",
            "Epoch 201/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.9700 - mae: 19.4625\n",
            "Epoch 00201: val_loss did not improve from 36.37829\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 19.6895 - mae: 19.9762 - val_loss: 40.5957 - val_mae: 40.4430\n",
            "Epoch 202/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.8762 - mae: 19.3682\n",
            "Epoch 00202: val_loss improved from 36.37829 to 35.68072, saving model to cp/weights-202-35.68.hdf5\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 19.5882 - mae: 19.8765 - val_loss: 35.6807 - val_mae: 35.5168\n",
            "Epoch 203/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.9246 - mae: 19.4172\n",
            "Epoch 00203: val_loss did not improve from 35.68072\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 19.5956 - mae: 19.8963 - val_loss: 41.0418 - val_mae: 40.8667\n",
            "Epoch 204/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.9420 - mae: 19.4343\n",
            "Epoch 00204: val_loss improved from 35.68072 to 34.55913, saving model to cp/weights-204-34.56.hdf5\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 19.6720 - mae: 19.9554 - val_loss: 34.5591 - val_mae: 34.4269\n",
            "Epoch 205/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.8416 - mae: 19.3340\n",
            "Epoch 00205: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 19.5366 - mae: 19.8302 - val_loss: 40.8339 - val_mae: 40.7023\n",
            "Epoch 206/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.9803 - mae: 19.4728\n",
            "Epoch 00206: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 19.6814 - mae: 19.9734 - val_loss: 39.7622 - val_mae: 39.6467\n",
            "Epoch 207/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.8456 - mae: 19.3379\n",
            "Epoch 00207: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 19.5120 - mae: 19.8138 - val_loss: 45.6876 - val_mae: 45.5849\n",
            "Epoch 208/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.7048 - mae: 19.1972\n",
            "Epoch 00208: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 19.3717 - mae: 19.6734 - val_loss: 38.4501 - val_mae: 38.3313\n",
            "Epoch 209/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.6611 - mae: 19.1535\n",
            "Epoch 00209: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 19.3658 - mae: 19.6567 - val_loss: 42.2161 - val_mae: 42.1103\n",
            "Epoch 210/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.5556 - mae: 19.0480\n",
            "Epoch 00210: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 19.2734 - mae: 19.5605 - val_loss: 36.3167 - val_mae: 36.2201\n",
            "Epoch 211/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.4331 - mae: 18.9255\n",
            "Epoch 00211: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 19.1018 - mae: 19.4029 - val_loss: 43.1340 - val_mae: 43.0133\n",
            "Epoch 212/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.7822 - mae: 19.2750\n",
            "Epoch 00212: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 19.4709 - mae: 19.7667 - val_loss: 39.7634 - val_mae: 39.6028\n",
            "Epoch 213/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.4668 - mae: 18.9591\n",
            "Epoch 00213: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 19.1738 - mae: 19.4638 - val_loss: 41.5197 - val_mae: 41.4338\n",
            "Epoch 214/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.3493 - mae: 18.8418\n",
            "Epoch 00214: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 19.0020 - mae: 19.3078 - val_loss: 37.5178 - val_mae: 37.3887\n",
            "Epoch 215/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.2377 - mae: 18.7297\n",
            "Epoch 00215: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 18.9148 - mae: 19.2130 - val_loss: 38.8118 - val_mae: 38.7147\n",
            "Epoch 216/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.1988 - mae: 18.6909\n",
            "Epoch 00216: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 18.8933 - mae: 19.1868 - val_loss: 38.0860 - val_mae: 37.9696\n",
            "Epoch 217/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.0853 - mae: 18.5773\n",
            "Epoch 00217: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 18.7447 - mae: 19.0481 - val_loss: 41.6073 - val_mae: 41.5049\n",
            "Epoch 218/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.2014 - mae: 18.6938\n",
            "Epoch 00218: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 18.8649 - mae: 19.1675 - val_loss: 37.4052 - val_mae: 37.2880\n",
            "Epoch 219/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.8447 - mae: 18.3369\n",
            "Epoch 00219: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 18.5618 - mae: 18.8489 - val_loss: 38.0880 - val_mae: 38.0041\n",
            "Epoch 220/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 18.1458 - mae: 18.6377\n",
            "Epoch 00220: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 18.8123 - mae: 19.1136 - val_loss: 37.2945 - val_mae: 37.1652\n",
            "Epoch 221/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.7808 - mae: 18.2724\n",
            "Epoch 00221: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 18.4301 - mae: 18.7360 - val_loss: 37.8371 - val_mae: 37.7377\n",
            "Epoch 222/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.7427 - mae: 18.2344\n",
            "Epoch 00222: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 18.3861 - mae: 18.6937 - val_loss: 37.5455 - val_mae: 37.4296\n",
            "Epoch 223/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.6234 - mae: 18.1150\n",
            "Epoch 00223: val_loss did not improve from 34.55913\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 18.3114 - mae: 18.6061 - val_loss: 35.9911 - val_mae: 35.8972\n",
            "Epoch 224/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.6822 - mae: 18.1737\n",
            "Epoch 00224: val_loss improved from 34.55913 to 33.37776, saving model to cp/weights-224-33.38.hdf5\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 18.4096 - mae: 18.6931 - val_loss: 33.3778 - val_mae: 33.3012\n",
            "Epoch 225/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.6843 - mae: 18.1761\n",
            "Epoch 00225: val_loss did not improve from 33.37776\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 18.3823 - mae: 18.6744 - val_loss: 39.5071 - val_mae: 39.3917\n",
            "Epoch 226/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.7944 - mae: 18.2866\n",
            "Epoch 00226: val_loss did not improve from 33.37776\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 18.4423 - mae: 18.7492 - val_loss: 36.6196 - val_mae: 36.4767\n",
            "Epoch 227/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.6556 - mae: 18.1473\n",
            "Epoch 00227: val_loss did not improve from 33.37776\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 18.2612 - mae: 18.5797 - val_loss: 39.4211 - val_mae: 39.3186\n",
            "Epoch 228/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.6987 - mae: 18.1907\n",
            "Epoch 00228: val_loss did not improve from 33.37776\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 18.3723 - mae: 18.6716 - val_loss: 34.2951 - val_mae: 34.1638\n",
            "Epoch 229/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.4021 - mae: 17.8941\n",
            "Epoch 00229: val_loss did not improve from 33.37776\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 18.0458 - mae: 18.3536 - val_loss: 35.1340 - val_mae: 35.0466\n",
            "Epoch 230/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.4153 - mae: 17.9073\n",
            "Epoch 00230: val_loss did not improve from 33.37776\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 18.1083 - mae: 18.4021 - val_loss: 33.7001 - val_mae: 33.5573\n",
            "Epoch 231/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.2574 - mae: 17.7489\n",
            "Epoch 00231: val_loss did not improve from 33.37776\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 17.9153 - mae: 18.2186 - val_loss: 35.8727 - val_mae: 35.7490\n",
            "Epoch 232/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.2057 - mae: 17.6972\n",
            "Epoch 00232: val_loss did not improve from 33.37776\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 17.8692 - mae: 18.1710 - val_loss: 34.8521 - val_mae: 34.7258\n",
            "Epoch 233/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.1329 - mae: 17.6242\n",
            "Epoch 00233: val_loss did not improve from 33.37776\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 17.7783 - mae: 18.0850 - val_loss: 35.5335 - val_mae: 35.4413\n",
            "Epoch 234/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.1317 - mae: 17.6230\n",
            "Epoch 00234: val_loss did not improve from 33.37776\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 17.7750 - mae: 18.0823 - val_loss: 36.5107 - val_mae: 36.4069\n",
            "Epoch 235/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.1578 - mae: 17.6496\n",
            "Epoch 00235: val_loss did not improve from 33.37776\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 17.8061 - mae: 18.1125 - val_loss: 38.8952 - val_mae: 38.8173\n",
            "Epoch 236/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.1739 - mae: 17.6659\n",
            "Epoch 00236: val_loss did not improve from 33.37776\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 17.8215 - mae: 18.1282 - val_loss: 36.5321 - val_mae: 36.4260\n",
            "Epoch 237/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.0805 - mae: 17.5715\n",
            "Epoch 00237: val_loss did not improve from 33.37776\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 17.7283 - mae: 18.0341 - val_loss: 38.9977 - val_mae: 38.8905\n",
            "Epoch 238/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 17.0135 - mae: 17.5048\n",
            "Epoch 00238: val_loss did not improve from 33.37776\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 17.6192 - mae: 17.9373 - val_loss: 35.2467 - val_mae: 35.1359\n",
            "Epoch 239/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.7845 - mae: 17.2761\n",
            "Epoch 00239: val_loss improved from 33.37776 to 32.51661, saving model to cp/weights-239-32.52.hdf5\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 17.4650 - mae: 17.7620 - val_loss: 32.5166 - val_mae: 32.4339\n",
            "Epoch 240/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.7600 - mae: 17.2514\n",
            "Epoch 00240: val_loss did not improve from 32.51661\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 17.3891 - mae: 17.7006 - val_loss: 34.2216 - val_mae: 34.1305\n",
            "Epoch 241/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.6788 - mae: 17.1703\n",
            "Epoch 00241: val_loss did not improve from 32.51661\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 17.3933 - mae: 17.6804 - val_loss: 35.6621 - val_mae: 35.5686\n",
            "Epoch 242/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.7670 - mae: 17.2583\n",
            "Epoch 00242: val_loss did not improve from 32.51661\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 17.4109 - mae: 17.7180 - val_loss: 32.8756 - val_mae: 32.7885\n",
            "Epoch 243/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.6366 - mae: 17.1282\n",
            "Epoch 00243: val_loss did not improve from 32.51661\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 17.2849 - mae: 17.5911 - val_loss: 35.6293 - val_mae: 35.5308\n",
            "Epoch 244/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.7807 - mae: 17.2721\n",
            "Epoch 00244: val_loss improved from 32.51661 to 32.10580, saving model to cp/weights-244-32.11.hdf5\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 17.4491 - mae: 17.7493 - val_loss: 32.1058 - val_mae: 31.9999\n",
            "Epoch 245/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.5724 - mae: 17.0635\n",
            "Epoch 00245: val_loss did not improve from 32.10580\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 17.1969 - mae: 17.5094 - val_loss: 35.2439 - val_mae: 35.1327\n",
            "Epoch 246/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.5371 - mae: 17.0285\n",
            "Epoch 00246: val_loss did not improve from 32.10580\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 17.2059 - mae: 17.5060 - val_loss: 35.4636 - val_mae: 35.3446\n",
            "Epoch 247/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.3242 - mae: 16.8153\n",
            "Epoch 00247: val_loss did not improve from 32.10580\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 16.9959 - mae: 17.2949 - val_loss: 33.4142 - val_mae: 33.3114\n",
            "Epoch 248/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.3991 - mae: 16.8898\n",
            "Epoch 00248: val_loss did not improve from 32.10580\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 17.0365 - mae: 17.3449 - val_loss: 33.7636 - val_mae: 33.6830\n",
            "Epoch 249/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.4358 - mae: 16.9272\n",
            "Epoch 00249: val_loss did not improve from 32.10580\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 17.0898 - mae: 17.3942 - val_loss: 33.2431 - val_mae: 33.1795\n",
            "Epoch 250/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.2950 - mae: 16.7862\n",
            "Epoch 00250: val_loss did not improve from 32.10580\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 16.9496 - mae: 17.2536 - val_loss: 33.8769 - val_mae: 33.7781\n",
            "Epoch 251/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.2426 - mae: 16.7337\n",
            "Epoch 00251: val_loss did not improve from 32.10580\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 16.8758 - mae: 17.1858 - val_loss: 34.6742 - val_mae: 34.6031\n",
            "Epoch 252/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.4528 - mae: 16.9440\n",
            "Epoch 00252: val_loss did not improve from 32.10580\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 17.0986 - mae: 17.4050 - val_loss: 35.2351 - val_mae: 35.1428\n",
            "Epoch 253/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.2747 - mae: 16.7658\n",
            "Epoch 00253: val_loss did not improve from 32.10580\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 16.8961 - mae: 17.2095 - val_loss: 32.8078 - val_mae: 32.7054\n",
            "Epoch 254/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.0965 - mae: 16.5874\n",
            "Epoch 00254: val_loss improved from 32.10580 to 31.12848, saving model to cp/weights-254-31.13.hdf5\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 16.7362 - mae: 17.0442 - val_loss: 31.1285 - val_mae: 31.0243\n",
            "Epoch 255/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.9445 - mae: 16.4352\n",
            "Epoch 00255: val_loss improved from 31.12848 to 28.73964, saving model to cp/weights-255-28.74.hdf5\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 16.6171 - mae: 16.9155 - val_loss: 28.7396 - val_mae: 28.6472\n",
            "Epoch 256/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.0318 - mae: 16.5229\n",
            "Epoch 00256: val_loss did not improve from 28.73964\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 16.6467 - mae: 16.9619 - val_loss: 31.1114 - val_mae: 31.0106\n",
            "Epoch 257/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.9783 - mae: 16.4691\n",
            "Epoch 00257: val_loss did not improve from 28.73964\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 16.6218 - mae: 16.9286 - val_loss: 31.5641 - val_mae: 31.4277\n",
            "Epoch 258/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.9662 - mae: 16.4573\n",
            "Epoch 00258: val_loss improved from 28.73964 to 28.35721, saving model to cp/weights-258-28.36.hdf5\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 16.6339 - mae: 16.9340 - val_loss: 28.3572 - val_mae: 28.2495\n",
            "Epoch 259/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.9453 - mae: 16.4360\n",
            "Epoch 00259: val_loss did not improve from 28.35721\n",
            "30/30 [==============================] - 6s 186ms/step - loss: 16.5880 - mae: 16.8949 - val_loss: 29.2687 - val_mae: 29.1115\n",
            "Epoch 260/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 16.3363 - mae: 16.8279\n",
            "Epoch 00260: val_loss did not improve from 28.35721\n",
            "30/30 [==============================] - 6s 187ms/step - loss: 16.9329 - mae: 17.2539 - val_loss: 29.3890 - val_mae: 29.3081\n",
            "Epoch 261/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.9938 - mae: 16.4858\n",
            "Epoch 00261: val_loss did not improve from 28.35721\n",
            "30/30 [==============================] - 6s 186ms/step - loss: 16.6373 - mae: 16.9452 - val_loss: 30.6966 - val_mae: 30.5814\n",
            "Epoch 262/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.8604 - mae: 16.3513\n",
            "Epoch 00262: val_loss improved from 28.35721 to 27.44659, saving model to cp/weights-262-27.45.hdf5\n",
            "30/30 [==============================] - 6s 186ms/step - loss: 16.4956 - mae: 16.8049 - val_loss: 27.4466 - val_mae: 27.3097\n",
            "Epoch 263/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.8881 - mae: 16.3793\n",
            "Epoch 00263: val_loss did not improve from 27.44659\n",
            "30/30 [==============================] - 5s 182ms/step - loss: 16.5152 - mae: 16.8271 - val_loss: 28.9033 - val_mae: 28.7733\n",
            "Epoch 264/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.8519 - mae: 16.3430\n",
            "Epoch 00264: val_loss did not improve from 27.44659\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 16.4692 - mae: 16.7838 - val_loss: 28.8661 - val_mae: 28.7600\n",
            "Epoch 265/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.7516 - mae: 16.2423\n",
            "Epoch 00265: val_loss improved from 27.44659 to 27.05012, saving model to cp/weights-265-27.05.hdf5\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 16.3925 - mae: 16.6999 - val_loss: 27.0501 - val_mae: 26.9252\n",
            "Epoch 266/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.7873 - mae: 16.2784\n",
            "Epoch 00266: val_loss did not improve from 27.05012\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 16.4232 - mae: 16.7324 - val_loss: 27.9159 - val_mae: 27.8110\n",
            "Epoch 267/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.7200 - mae: 16.2114\n",
            "Epoch 00267: val_loss did not improve from 27.05012\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 16.3713 - mae: 16.6764 - val_loss: 30.0851 - val_mae: 29.9502\n",
            "Epoch 268/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.5108 - mae: 16.0015\n",
            "Epoch 00268: val_loss did not improve from 27.05012\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 16.1912 - mae: 16.4873 - val_loss: 29.7063 - val_mae: 29.5703\n",
            "Epoch 269/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.5079 - mae: 15.9984\n",
            "Epoch 00269: val_loss did not improve from 27.05012\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 16.1069 - mae: 16.4261 - val_loss: 31.3723 - val_mae: 31.2282\n",
            "Epoch 270/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.4462 - mae: 15.9363\n",
            "Epoch 00270: val_loss did not improve from 27.05012\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 16.0354 - mae: 16.3571 - val_loss: 31.1447 - val_mae: 30.9794\n",
            "Epoch 271/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.4161 - mae: 15.9069\n",
            "Epoch 00271: val_loss did not improve from 27.05012\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 16.0640 - mae: 16.3695 - val_loss: 31.2632 - val_mae: 31.1053\n",
            "Epoch 272/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.3653 - mae: 15.8557\n",
            "Epoch 00272: val_loss did not improve from 27.05012\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 16.0233 - mae: 16.3255 - val_loss: 27.5006 - val_mae: 27.3550\n",
            "Epoch 273/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.6192 - mae: 16.1106\n",
            "Epoch 00273: val_loss did not improve from 27.05012\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 16.2219 - mae: 16.5409 - val_loss: 29.7635 - val_mae: 29.6675\n",
            "Epoch 274/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.3119 - mae: 15.8025\n",
            "Epoch 00274: val_loss did not improve from 27.05012\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 15.9340 - mae: 16.2467 - val_loss: 32.1117 - val_mae: 31.9902\n",
            "Epoch 275/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.2362 - mae: 15.7264\n",
            "Epoch 00275: val_loss did not improve from 27.05012\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 15.8532 - mae: 16.1670 - val_loss: 32.7388 - val_mae: 32.6212\n",
            "Epoch 276/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.1322 - mae: 15.6223\n",
            "Epoch 00276: val_loss did not improve from 27.05012\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 15.7967 - mae: 16.0968 - val_loss: 31.5611 - val_mae: 31.4804\n",
            "Epoch 277/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.1989 - mae: 15.6889\n",
            "Epoch 00277: val_loss did not improve from 27.05012\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 15.8179 - mae: 16.1309 - val_loss: 31.6808 - val_mae: 31.5837\n",
            "Epoch 278/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.1218 - mae: 15.6121\n",
            "Epoch 00278: val_loss did not improve from 27.05012\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 15.7451 - mae: 16.0572 - val_loss: 29.9303 - val_mae: 29.8262\n",
            "Epoch 279/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.0138 - mae: 15.5038\n",
            "Epoch 00279: val_loss did not improve from 27.05012\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 15.6278 - mae: 15.9423 - val_loss: 31.6115 - val_mae: 31.5078\n",
            "Epoch 280/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.0063 - mae: 15.4965\n",
            "Epoch 00280: val_loss improved from 27.05012 to 26.72325, saving model to cp/weights-280-26.72.hdf5\n",
            "30/30 [==============================] - 5s 180ms/step - loss: 15.6462 - mae: 15.9535 - val_loss: 26.7232 - val_mae: 26.6221\n",
            "Epoch 281/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.0822 - mae: 15.5729\n",
            "Epoch 00281: val_loss did not improve from 26.72325\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 15.7528 - mae: 16.0517 - val_loss: 28.6390 - val_mae: 28.5517\n",
            "Epoch 282/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.9511 - mae: 15.4415\n",
            "Epoch 00282: val_loss did not improve from 26.72325\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 15.6027 - mae: 15.9067 - val_loss: 26.7979 - val_mae: 26.6638\n",
            "Epoch 283/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.1521 - mae: 15.6430\n",
            "Epoch 00283: val_loss improved from 26.72325 to 25.40593, saving model to cp/weights-283-25.41.hdf5\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 15.7480 - mae: 16.0685 - val_loss: 25.4059 - val_mae: 25.3154\n",
            "Epoch 284/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 15.1769 - mae: 15.6677\n",
            "Epoch 00284: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 15.8108 - mae: 16.1203 - val_loss: 28.2213 - val_mae: 28.1129\n",
            "Epoch 285/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.9744 - mae: 15.4651\n",
            "Epoch 00285: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 15.6009 - mae: 15.9124 - val_loss: 29.2804 - val_mae: 29.1476\n",
            "Epoch 286/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.9071 - mae: 15.3975\n",
            "Epoch 00286: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 15.5133 - mae: 15.8304 - val_loss: 29.0715 - val_mae: 28.9458\n",
            "Epoch 287/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.8267 - mae: 15.3171\n",
            "Epoch 00287: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 15.4199 - mae: 15.7407 - val_loss: 29.4542 - val_mae: 29.3395\n",
            "Epoch 288/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.6539 - mae: 15.1437\n",
            "Epoch 00288: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 15.2679 - mae: 15.5821 - val_loss: 29.5471 - val_mae: 29.4371\n",
            "Epoch 289/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.6080 - mae: 15.0982\n",
            "Epoch 00289: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 15.2351 - mae: 15.5459 - val_loss: 27.2093 - val_mae: 27.1063\n",
            "Epoch 290/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.7929 - mae: 15.2832\n",
            "Epoch 00290: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 15.3965 - mae: 15.7143 - val_loss: 30.3574 - val_mae: 30.2711\n",
            "Epoch 291/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.7084 - mae: 15.1980\n",
            "Epoch 00291: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 15.3381 - mae: 15.6477 - val_loss: 27.6768 - val_mae: 27.5618\n",
            "Epoch 292/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.7104 - mae: 15.2006\n",
            "Epoch 00292: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 15.3153 - mae: 15.6325 - val_loss: 31.7117 - val_mae: 31.6408\n",
            "Epoch 293/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.4750 - mae: 14.9648\n",
            "Epoch 00293: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 15.0998 - mae: 15.4110 - val_loss: 28.7443 - val_mae: 28.6564\n",
            "Epoch 294/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.5436 - mae: 15.0337\n",
            "Epoch 00294: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 15.1667 - mae: 15.4786 - val_loss: 31.4287 - val_mae: 31.3619\n",
            "Epoch 295/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.5915 - mae: 15.0813\n",
            "Epoch 00295: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 15.1870 - mae: 15.5065 - val_loss: 29.2096 - val_mae: 29.1515\n",
            "Epoch 296/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.4687 - mae: 14.9586\n",
            "Epoch 00296: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 15.0555 - mae: 15.3776 - val_loss: 30.3931 - val_mae: 30.3580\n",
            "Epoch 297/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.5935 - mae: 15.0833\n",
            "Epoch 00297: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 15.1966 - mae: 15.5141 - val_loss: 27.0677 - val_mae: 27.0274\n",
            "Epoch 298/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.4278 - mae: 14.9177\n",
            "Epoch 00298: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 15.0142 - mae: 15.3365 - val_loss: 31.1086 - val_mae: 31.0484\n",
            "Epoch 299/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.4219 - mae: 14.9118\n",
            "Epoch 00299: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 15.0342 - mae: 15.3490 - val_loss: 28.6727 - val_mae: 28.6046\n",
            "Epoch 300/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.4446 - mae: 14.9346\n",
            "Epoch 00300: val_loss did not improve from 25.40593\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 14.9828 - mae: 15.3189 - val_loss: 29.8706 - val_mae: 29.8022\n",
            "Epoch 301/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.3977 - mae: 14.8880\n",
            "Epoch 00301: val_loss improved from 25.40593 to 22.26302, saving model to cp/weights-301-22.26.hdf5\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 15.0175 - mae: 15.3305 - val_loss: 22.2630 - val_mae: 22.1804\n",
            "Epoch 302/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.7914 - mae: 15.2824\n",
            "Epoch 00302: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 15.3340 - mae: 15.6698 - val_loss: 25.5161 - val_mae: 25.4454\n",
            "Epoch 303/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.5019 - mae: 14.9927\n",
            "Epoch 00303: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 15.1507 - mae: 15.4560 - val_loss: 27.9190 - val_mae: 27.8212\n",
            "Epoch 304/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.2793 - mae: 14.7691\n",
            "Epoch 00304: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 14.8722 - mae: 15.1924 - val_loss: 26.5096 - val_mae: 26.3823\n",
            "Epoch 305/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.2667 - mae: 14.7566\n",
            "Epoch 00305: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 14.8841 - mae: 15.1975 - val_loss: 31.9941 - val_mae: 31.9208\n",
            "Epoch 306/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.3253 - mae: 14.8151\n",
            "Epoch 00306: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 14.9059 - mae: 15.2296 - val_loss: 30.1536 - val_mae: 30.0462\n",
            "Epoch 307/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.1981 - mae: 14.6877\n",
            "Epoch 00307: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 14.7821 - mae: 15.1047 - val_loss: 30.9221 - val_mae: 30.8298\n",
            "Epoch 308/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.1290 - mae: 14.6186\n",
            "Epoch 00308: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 14.7011 - mae: 15.0272 - val_loss: 27.1740 - val_mae: 27.0791\n",
            "Epoch 309/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.0382 - mae: 14.5276\n",
            "Epoch 00309: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 14.6145 - mae: 14.9391 - val_loss: 27.2631 - val_mae: 27.1841\n",
            "Epoch 310/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.9733 - mae: 14.4628\n",
            "Epoch 00310: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 14.5929 - mae: 14.9052 - val_loss: 27.9458 - val_mae: 27.8408\n",
            "Epoch 311/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.0229 - mae: 14.5124\n",
            "Epoch 00311: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 14.6504 - mae: 14.9605 - val_loss: 25.9339 - val_mae: 25.8304\n",
            "Epoch 312/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.1244 - mae: 14.6145\n",
            "Epoch 00312: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 14.7018 - mae: 15.0267 - val_loss: 23.8795 - val_mae: 23.7823\n",
            "Epoch 313/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.2198 - mae: 14.7102\n",
            "Epoch 00313: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 14.8122 - mae: 15.1332 - val_loss: 24.9216 - val_mae: 24.8266\n",
            "Epoch 314/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.2897 - mae: 14.7803\n",
            "Epoch 00314: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 14.8619 - mae: 15.1889 - val_loss: 23.8727 - val_mae: 23.7658\n",
            "Epoch 315/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.4267 - mae: 14.9175\n",
            "Epoch 00315: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 14.9900 - mae: 15.3197 - val_loss: 29.1574 - val_mae: 29.0970\n",
            "Epoch 316/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.9445 - mae: 14.4342\n",
            "Epoch 00316: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 14.5445 - mae: 14.8626 - val_loss: 26.6050 - val_mae: 26.4928\n",
            "Epoch 317/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.8726 - mae: 14.3622\n",
            "Epoch 00317: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 14.4472 - mae: 14.7725 - val_loss: 28.8166 - val_mae: 28.6990\n",
            "Epoch 318/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.8947 - mae: 14.3844\n",
            "Epoch 00318: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 14.4877 - mae: 14.8078 - val_loss: 23.9580 - val_mae: 23.8166\n",
            "Epoch 319/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.4803 - mae: 14.9708\n",
            "Epoch 00319: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 15.0880 - mae: 15.4047 - val_loss: 29.1657 - val_mae: 29.1149\n",
            "Epoch 320/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.8949 - mae: 14.3847\n",
            "Epoch 00320: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 14.4959 - mae: 14.8139 - val_loss: 27.7632 - val_mae: 27.6554\n",
            "Epoch 321/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.7784 - mae: 14.2681\n",
            "Epoch 00321: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 14.3681 - mae: 14.6893 - val_loss: 26.9506 - val_mae: 26.8366\n",
            "Epoch 322/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.7050 - mae: 14.1944\n",
            "Epoch 00322: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 14.2672 - mae: 14.5959 - val_loss: 29.4328 - val_mae: 29.3394\n",
            "Epoch 323/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.7802 - mae: 14.2696\n",
            "Epoch 00323: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 14.3724 - mae: 14.6924 - val_loss: 26.0763 - val_mae: 25.9015\n",
            "Epoch 324/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 14.2739 - mae: 14.7645\n",
            "Epoch 00324: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 14.8463 - mae: 15.1732 - val_loss: 33.1779 - val_mae: 33.1129\n",
            "Epoch 325/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.8479 - mae: 14.3377\n",
            "Epoch 00325: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 14.4325 - mae: 14.7551 - val_loss: 30.1717 - val_mae: 30.0282\n",
            "Epoch 326/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.7374 - mae: 14.2270\n",
            "Epoch 00326: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 14.3379 - mae: 14.6558 - val_loss: 29.3386 - val_mae: 29.2118\n",
            "Epoch 327/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.5359 - mae: 14.0254\n",
            "Epoch 00327: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 14.1220 - mae: 14.4438 - val_loss: 28.9844 - val_mae: 28.8842\n",
            "Epoch 328/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.5622 - mae: 14.0516\n",
            "Epoch 00328: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 14.1600 - mae: 14.4784 - val_loss: 26.8541 - val_mae: 26.7097\n",
            "Epoch 329/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.8636 - mae: 14.3534\n",
            "Epoch 00329: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 14.4283 - mae: 14.7566 - val_loss: 28.4846 - val_mae: 28.4444\n",
            "Epoch 330/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.7072 - mae: 14.1970\n",
            "Epoch 00330: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 14.2900 - mae: 14.6132 - val_loss: 25.5602 - val_mae: 25.4471\n",
            "Epoch 331/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.7691 - mae: 14.2585\n",
            "Epoch 00331: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 14.3485 - mae: 14.6723 - val_loss: 26.6894 - val_mae: 26.5658\n",
            "Epoch 332/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.6499 - mae: 14.1396\n",
            "Epoch 00332: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 14.2671 - mae: 14.5803 - val_loss: 27.6847 - val_mae: 27.6088\n",
            "Epoch 333/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.8061 - mae: 14.2956\n",
            "Epoch 00333: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 14.4508 - mae: 14.7560 - val_loss: 33.2291 - val_mae: 33.0615\n",
            "Epoch 334/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.6031 - mae: 14.0926\n",
            "Epoch 00334: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 14.1880 - mae: 14.5103 - val_loss: 26.6986 - val_mae: 26.6157\n",
            "Epoch 335/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.7274 - mae: 14.2169\n",
            "Epoch 00335: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 14.3779 - mae: 14.6815 - val_loss: 35.4574 - val_mae: 35.2620\n",
            "Epoch 336/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.6878 - mae: 14.1771\n",
            "Epoch 00336: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 14.2807 - mae: 14.6005 - val_loss: 23.1534 - val_mae: 23.0424\n",
            "Epoch 337/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.6513 - mae: 14.1409\n",
            "Epoch 00337: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 14.2449 - mae: 14.5648 - val_loss: 34.8706 - val_mae: 34.6465\n",
            "Epoch 338/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.5910 - mae: 14.0804\n",
            "Epoch 00338: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 14.1654 - mae: 14.4906 - val_loss: 24.2931 - val_mae: 24.1136\n",
            "Epoch 339/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.6726 - mae: 14.1619\n",
            "Epoch 00339: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 14.2683 - mae: 14.5873 - val_loss: 32.0484 - val_mae: 31.8583\n",
            "Epoch 340/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.4535 - mae: 13.9433\n",
            "Epoch 00340: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 14.0255 - mae: 14.3518 - val_loss: 27.9739 - val_mae: 27.7663\n",
            "Epoch 341/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.3690 - mae: 13.8582\n",
            "Epoch 00341: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 13.9638 - mae: 14.2829 - val_loss: 31.6741 - val_mae: 31.4978\n",
            "Epoch 342/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.2706 - mae: 13.7593\n",
            "Epoch 00342: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 13.8387 - mae: 14.1650 - val_loss: 29.7788 - val_mae: 29.5801\n",
            "Epoch 343/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.2303 - mae: 13.7192\n",
            "Epoch 00343: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 13.8186 - mae: 14.1392 - val_loss: 28.9581 - val_mae: 28.8037\n",
            "Epoch 344/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.0942 - mae: 13.5827\n",
            "Epoch 00344: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 13.6479 - mae: 13.9781 - val_loss: 29.4988 - val_mae: 29.3220\n",
            "Epoch 345/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.0707 - mae: 13.5593\n",
            "Epoch 00345: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 13.6553 - mae: 13.9768 - val_loss: 27.4474 - val_mae: 27.3048\n",
            "Epoch 346/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.0985 - mae: 13.5869\n",
            "Epoch 00346: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 13.6622 - mae: 13.9895 - val_loss: 26.6268 - val_mae: 26.5020\n",
            "Epoch 347/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.0529 - mae: 13.5409\n",
            "Epoch 00347: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 13.6155 - mae: 13.9427 - val_loss: 27.9529 - val_mae: 27.7986\n",
            "Epoch 348/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.0519 - mae: 13.5405\n",
            "Epoch 00348: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 13.6268 - mae: 13.9510 - val_loss: 28.6204 - val_mae: 28.4817\n",
            "Epoch 349/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.9994 - mae: 13.4875\n",
            "Epoch 00349: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 13.5737 - mae: 13.8976 - val_loss: 26.3936 - val_mae: 26.2813\n",
            "Epoch 350/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.9777 - mae: 13.4660\n",
            "Epoch 00350: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 13.5568 - mae: 13.8796 - val_loss: 26.5653 - val_mae: 26.4241\n",
            "Epoch 351/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.9640 - mae: 13.4526\n",
            "Epoch 00351: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 13.5489 - mae: 13.8703 - val_loss: 28.0897 - val_mae: 27.9769\n",
            "Epoch 352/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.9402 - mae: 13.4287\n",
            "Epoch 00352: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 13.5196 - mae: 13.8424 - val_loss: 26.1247 - val_mae: 25.9858\n",
            "Epoch 353/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.1009 - mae: 13.5898\n",
            "Epoch 00353: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 13.7150 - mae: 14.0283 - val_loss: 25.9813 - val_mae: 25.8826\n",
            "Epoch 354/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.9836 - mae: 13.4718\n",
            "Epoch 00354: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 13.5453 - mae: 13.8729 - val_loss: 24.1437 - val_mae: 24.0313\n",
            "Epoch 355/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.1680 - mae: 13.6572\n",
            "Epoch 00355: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 13.7392 - mae: 14.0651 - val_loss: 27.5489 - val_mae: 27.4539\n",
            "Epoch 356/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.8613 - mae: 13.3498\n",
            "Epoch 00356: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 13.4497 - mae: 13.7700 - val_loss: 26.3884 - val_mae: 26.2621\n",
            "Epoch 357/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.9608 - mae: 13.4495\n",
            "Epoch 00357: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 13.5260 - mae: 13.8531 - val_loss: 25.1272 - val_mae: 25.0427\n",
            "Epoch 358/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.8978 - mae: 13.3859\n",
            "Epoch 00358: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 13.4768 - mae: 13.7993 - val_loss: 27.5036 - val_mae: 27.3975\n",
            "Epoch 359/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.8459 - mae: 13.3340\n",
            "Epoch 00359: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 13.4426 - mae: 13.7601 - val_loss: 26.1163 - val_mae: 26.0017\n",
            "Epoch 360/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.0201 - mae: 13.5088\n",
            "Epoch 00360: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 13.5471 - mae: 13.8852 - val_loss: 24.8676 - val_mae: 24.7976\n",
            "Epoch 361/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.0602 - mae: 13.5488\n",
            "Epoch 00361: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 13.6485 - mae: 13.9690 - val_loss: 29.5822 - val_mae: 29.4287\n",
            "Epoch 362/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.1318 - mae: 13.6207\n",
            "Epoch 00362: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 13.7282 - mae: 14.0466 - val_loss: 28.9526 - val_mae: 28.8671\n",
            "Epoch 363/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.2781 - mae: 13.7668\n",
            "Epoch 00363: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 13.8698 - mae: 14.1894 - val_loss: 32.0818 - val_mae: 31.9337\n",
            "Epoch 364/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.2175 - mae: 13.7062\n",
            "Epoch 00364: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 13.7868 - mae: 14.1127 - val_loss: 25.4005 - val_mae: 25.3092\n",
            "Epoch 365/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 13.4922 - mae: 13.9810\n",
            "Epoch 00365: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 14.0940 - mae: 14.4108 - val_loss: 41.9150 - val_mae: 41.6674\n",
            "Epoch 366/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.9615 - mae: 13.4503\n",
            "Epoch 00366: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 13.5316 - mae: 13.8574 - val_loss: 27.1673 - val_mae: 27.0043\n",
            "Epoch 367/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.7915 - mae: 13.2799\n",
            "Epoch 00367: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 13.3198 - mae: 13.6572 - val_loss: 32.0355 - val_mae: 31.8336\n",
            "Epoch 368/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.7257 - mae: 13.2139\n",
            "Epoch 00368: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 13.2652 - mae: 13.5992 - val_loss: 26.2927 - val_mae: 26.1003\n",
            "Epoch 369/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.6499 - mae: 13.1376\n",
            "Epoch 00369: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 13.2135 - mae: 13.5401 - val_loss: 28.9422 - val_mae: 28.7676\n",
            "Epoch 370/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.6001 - mae: 13.0882\n",
            "Epoch 00370: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 13.1514 - mae: 13.4819 - val_loss: 28.2841 - val_mae: 28.1026\n",
            "Epoch 371/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.6959 - mae: 13.1837\n",
            "Epoch 00371: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 13.2414 - mae: 13.5733 - val_loss: 31.3758 - val_mae: 31.1930\n",
            "Epoch 372/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.5867 - mae: 13.0744\n",
            "Epoch 00372: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 13.1693 - mae: 13.4905 - val_loss: 28.4525 - val_mae: 28.3045\n",
            "Epoch 373/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.5908 - mae: 13.0785\n",
            "Epoch 00373: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 13.1602 - mae: 13.4852 - val_loss: 28.7209 - val_mae: 28.5839\n",
            "Epoch 374/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.5944 - mae: 13.0820\n",
            "Epoch 00374: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 13.1626 - mae: 13.4879 - val_loss: 25.6682 - val_mae: 25.5427\n",
            "Epoch 375/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.6989 - mae: 13.1871\n",
            "Epoch 00375: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 13.2823 - mae: 13.6037 - val_loss: 26.9856 - val_mae: 26.8207\n",
            "Epoch 376/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.6838 - mae: 13.1723\n",
            "Epoch 00376: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 13.2209 - mae: 13.5559 - val_loss: 26.1760 - val_mae: 26.0717\n",
            "Epoch 377/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.6944 - mae: 13.1822\n",
            "Epoch 00377: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 13.3111 - mae: 13.6227 - val_loss: 30.3583 - val_mae: 30.1968\n",
            "Epoch 378/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.7094 - mae: 13.1972\n",
            "Epoch 00378: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 13.2491 - mae: 13.5826 - val_loss: 22.7742 - val_mae: 22.6466\n",
            "Epoch 379/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.8163 - mae: 13.3047\n",
            "Epoch 00379: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 13.3849 - mae: 13.7107 - val_loss: 34.6956 - val_mae: 34.4686\n",
            "Epoch 380/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.7085 - mae: 13.1964\n",
            "Epoch 00380: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 13.2895 - mae: 13.6112 - val_loss: 22.4918 - val_mae: 22.3177\n",
            "Epoch 381/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.7297 - mae: 13.2180\n",
            "Epoch 00381: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 13.2640 - mae: 13.5996 - val_loss: 32.4418 - val_mae: 32.2156\n",
            "Epoch 382/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.6596 - mae: 13.1480\n",
            "Epoch 00382: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 13.2043 - mae: 13.5370 - val_loss: 25.7306 - val_mae: 25.5107\n",
            "Epoch 383/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.6939 - mae: 13.1822\n",
            "Epoch 00383: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 13.2314 - mae: 13.5660 - val_loss: 31.0266 - val_mae: 30.7961\n",
            "Epoch 384/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.3624 - mae: 12.8499\n",
            "Epoch 00384: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 12.9050 - mae: 13.2374 - val_loss: 28.2028 - val_mae: 27.9805\n",
            "Epoch 385/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.3223 - mae: 12.8098\n",
            "Epoch 00385: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 12.8874 - mae: 13.2134 - val_loss: 29.0963 - val_mae: 28.8847\n",
            "Epoch 386/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.3116 - mae: 12.7992\n",
            "Epoch 00386: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 12.8626 - mae: 13.1927 - val_loss: 26.9034 - val_mae: 26.7006\n",
            "Epoch 387/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.3682 - mae: 12.8560\n",
            "Epoch 00387: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 12.9126 - mae: 13.2448 - val_loss: 28.5735 - val_mae: 28.3686\n",
            "Epoch 388/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.3418 - mae: 12.8288\n",
            "Epoch 00388: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 12.8812 - mae: 13.2141 - val_loss: 26.1668 - val_mae: 25.9836\n",
            "Epoch 389/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.2438 - mae: 12.7313\n",
            "Epoch 00389: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.7987 - mae: 13.1275 - val_loss: 28.9132 - val_mae: 28.7206\n",
            "Epoch 390/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.2628 - mae: 12.7501\n",
            "Epoch 00390: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.8275 - mae: 13.1534 - val_loss: 24.4977 - val_mae: 24.3443\n",
            "Epoch 391/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.2368 - mae: 12.7241\n",
            "Epoch 00391: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.7881 - mae: 13.1179 - val_loss: 27.3972 - val_mae: 27.2208\n",
            "Epoch 392/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.2854 - mae: 12.7729\n",
            "Epoch 00392: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 12.7985 - mae: 13.1393 - val_loss: 25.0574 - val_mae: 24.9169\n",
            "Epoch 393/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.1835 - mae: 12.6702\n",
            "Epoch 00393: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 12.7216 - mae: 13.0545 - val_loss: 28.2040 - val_mae: 28.0443\n",
            "Epoch 394/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.2414 - mae: 12.7287\n",
            "Epoch 00394: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 12.8124 - mae: 13.1365 - val_loss: 27.0117 - val_mae: 26.8881\n",
            "Epoch 395/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.2450 - mae: 12.7318\n",
            "Epoch 00395: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.8171 - mae: 13.1404 - val_loss: 29.3414 - val_mae: 29.1935\n",
            "Epoch 396/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.3218 - mae: 12.8084\n",
            "Epoch 00396: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 12.8641 - mae: 13.1958 - val_loss: 24.4628 - val_mae: 24.3677\n",
            "Epoch 397/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.4625 - mae: 12.9499\n",
            "Epoch 00397: val_loss did not improve from 22.26302\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 13.0371 - mae: 13.3603 - val_loss: 33.9315 - val_mae: 33.7338\n",
            "Epoch 398/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.3563 - mae: 12.8433\n",
            "Epoch 00398: val_loss improved from 22.26302 to 22.08566, saving model to cp/weights-398-22.09.hdf5\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 12.8559 - mae: 13.2001 - val_loss: 22.0857 - val_mae: 21.9642\n",
            "Epoch 399/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.6156 - mae: 13.1041\n",
            "Epoch 00399: val_loss did not improve from 22.08566\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 13.2068 - mae: 13.5263 - val_loss: 34.4132 - val_mae: 34.2164\n",
            "Epoch 400/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.4843 - mae: 12.9719\n",
            "Epoch 00400: val_loss improved from 22.08566 to 21.06688, saving model to cp/weights-400-21.07.hdf5\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 13.0037 - mae: 13.3428 - val_loss: 21.0669 - val_mae: 20.9245\n",
            "Epoch 401/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.8804 - mae: 13.3693\n",
            "Epoch 00401: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 13.3873 - mae: 13.7313 - val_loss: 34.3241 - val_mae: 34.1230\n",
            "Epoch 402/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.7420 - mae: 13.2312\n",
            "Epoch 00402: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 13.2789 - mae: 13.6146 - val_loss: 24.9021 - val_mae: 24.6870\n",
            "Epoch 403/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.6869 - mae: 13.1760\n",
            "Epoch 00403: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 13.2542 - mae: 13.5811 - val_loss: 28.1918 - val_mae: 28.0043\n",
            "Epoch 404/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.3111 - mae: 12.7985\n",
            "Epoch 00404: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 12.8597 - mae: 13.1904 - val_loss: 30.7577 - val_mae: 30.5347\n",
            "Epoch 405/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.2200 - mae: 12.7073\n",
            "Epoch 00405: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.7581 - mae: 13.0917 - val_loss: 25.6996 - val_mae: 25.5309\n",
            "Epoch 406/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.0683 - mae: 12.5550\n",
            "Epoch 00406: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.6166 - mae: 12.9466 - val_loss: 32.8411 - val_mae: 32.6300\n",
            "Epoch 407/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.1276 - mae: 12.6147\n",
            "Epoch 00407: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 12.6407 - mae: 12.9812 - val_loss: 23.8327 - val_mae: 23.6740\n",
            "Epoch 408/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.1376 - mae: 12.6249\n",
            "Epoch 00408: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 12.7036 - mae: 13.0291 - val_loss: 31.6471 - val_mae: 31.4052\n",
            "Epoch 409/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.0747 - mae: 12.5614\n",
            "Epoch 00409: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 12.5972 - mae: 12.9346 - val_loss: 24.7575 - val_mae: 24.5553\n",
            "Epoch 410/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.1205 - mae: 12.6080\n",
            "Epoch 00410: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 12.6763 - mae: 13.0049 - val_loss: 32.0474 - val_mae: 31.8326\n",
            "Epoch 411/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.1695 - mae: 12.6569\n",
            "Epoch 00411: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.7204 - mae: 13.0503 - val_loss: 23.6922 - val_mae: 23.5045\n",
            "Epoch 412/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.1938 - mae: 12.6814\n",
            "Epoch 00412: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 12.7321 - mae: 13.0658 - val_loss: 29.8501 - val_mae: 29.6762\n",
            "Epoch 413/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.0863 - mae: 12.5736\n",
            "Epoch 00413: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 12.5958 - mae: 12.9374 - val_loss: 25.4949 - val_mae: 25.3211\n",
            "Epoch 414/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.1011 - mae: 12.5883\n",
            "Epoch 00414: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 12.6192 - mae: 12.9582 - val_loss: 29.6476 - val_mae: 29.4985\n",
            "Epoch 415/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.0112 - mae: 12.4984\n",
            "Epoch 00415: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.5344 - mae: 12.8720 - val_loss: 28.1291 - val_mae: 27.9619\n",
            "Epoch 416/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.9539 - mae: 12.4404\n",
            "Epoch 00416: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 12.4894 - mae: 12.8228 - val_loss: 24.3297 - val_mae: 24.2104\n",
            "Epoch 417/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.8757 - mae: 12.3619\n",
            "Epoch 00417: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 12.4267 - mae: 12.7554 - val_loss: 28.8488 - val_mae: 28.6977\n",
            "Epoch 418/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.9651 - mae: 12.4515\n",
            "Epoch 00418: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 12.4893 - mae: 12.8258 - val_loss: 24.7688 - val_mae: 24.6258\n",
            "Epoch 419/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.9634 - mae: 12.4505\n",
            "Epoch 00419: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 12.5178 - mae: 12.8465 - val_loss: 33.5594 - val_mae: 33.3250\n",
            "Epoch 420/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.0350 - mae: 12.5216\n",
            "Epoch 00420: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 12.5815 - mae: 12.9119 - val_loss: 22.4983 - val_mae: 22.3173\n",
            "Epoch 421/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.1645 - mae: 12.6519\n",
            "Epoch 00421: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 12.6985 - mae: 13.0332 - val_loss: 32.2703 - val_mae: 32.0400\n",
            "Epoch 422/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.0466 - mae: 12.5338\n",
            "Epoch 00422: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 12.5706 - mae: 12.9079 - val_loss: 22.8845 - val_mae: 22.6811\n",
            "Epoch 423/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.2051 - mae: 12.6927\n",
            "Epoch 00423: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 12.7133 - mae: 13.0556 - val_loss: 30.7025 - val_mae: 30.4823\n",
            "Epoch 424/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.9410 - mae: 12.4280\n",
            "Epoch 00424: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.4468 - mae: 12.7892 - val_loss: 26.9330 - val_mae: 26.7020\n",
            "Epoch 425/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.8930 - mae: 12.3803\n",
            "Epoch 00425: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.4147 - mae: 12.7529 - val_loss: 29.5918 - val_mae: 29.3871\n",
            "Epoch 426/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.9577 - mae: 12.4446\n",
            "Epoch 00426: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 12.5184 - mae: 12.8450 - val_loss: 26.5600 - val_mae: 26.3467\n",
            "Epoch 427/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.9560 - mae: 12.4432\n",
            "Epoch 00427: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 12.4822 - mae: 12.8190 - val_loss: 26.9017 - val_mae: 26.7065\n",
            "Epoch 428/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.7502 - mae: 12.2367\n",
            "Epoch 00428: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 12.2791 - mae: 12.6145 - val_loss: 29.1099 - val_mae: 28.9104\n",
            "Epoch 429/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.7056 - mae: 12.1919\n",
            "Epoch 00429: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 12.2431 - mae: 12.5758 - val_loss: 25.2839 - val_mae: 25.1115\n",
            "Epoch 430/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.7051 - mae: 12.1911\n",
            "Epoch 00430: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 12.2654 - mae: 12.5913 - val_loss: 28.6410 - val_mae: 28.4707\n",
            "Epoch 431/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.8151 - mae: 12.3013\n",
            "Epoch 00431: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 12.3529 - mae: 12.6854 - val_loss: 25.9340 - val_mae: 25.7778\n",
            "Epoch 432/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.8599 - mae: 12.3464\n",
            "Epoch 00432: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 12.4431 - mae: 12.7630 - val_loss: 32.7634 - val_mae: 32.5739\n",
            "Epoch 433/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.9201 - mae: 12.4067\n",
            "Epoch 00433: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 12.4746 - mae: 12.8028 - val_loss: 22.2771 - val_mae: 22.1273\n",
            "Epoch 434/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.2043 - mae: 12.6918\n",
            "Epoch 00434: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 12.7625 - mae: 13.0904 - val_loss: 34.9202 - val_mae: 34.7234\n",
            "Epoch 435/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.1716 - mae: 12.6598\n",
            "Epoch 00435: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 12.6572 - mae: 13.0066 - val_loss: 22.3886 - val_mae: 22.1993\n",
            "Epoch 436/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.5113 - mae: 12.9999\n",
            "Epoch 00436: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 13.0174 - mae: 13.3613 - val_loss: 29.1924 - val_mae: 29.0251\n",
            "Epoch 437/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.0816 - mae: 12.5682\n",
            "Epoch 00437: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 12.6057 - mae: 12.9426 - val_loss: 31.5290 - val_mae: 31.3148\n",
            "Epoch 438/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.8761 - mae: 12.3624\n",
            "Epoch 00438: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 12.3852 - mae: 12.7260 - val_loss: 22.5797 - val_mae: 22.4121\n",
            "Epoch 439/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.7221 - mae: 12.2086\n",
            "Epoch 00439: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 12.2558 - mae: 12.5897 - val_loss: 28.4562 - val_mae: 28.2782\n",
            "Epoch 440/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.5755 - mae: 12.0616\n",
            "Epoch 00440: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 12.1182 - mae: 12.4493 - val_loss: 25.9435 - val_mae: 25.7695\n",
            "Epoch 441/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.5745 - mae: 12.0603\n",
            "Epoch 00441: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 12.1130 - mae: 12.4449 - val_loss: 28.8202 - val_mae: 28.6573\n",
            "Epoch 442/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.5975 - mae: 12.0837\n",
            "Epoch 00442: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 12.1401 - mae: 12.4712 - val_loss: 24.4097 - val_mae: 24.2602\n",
            "Epoch 443/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.6570 - mae: 12.1431\n",
            "Epoch 00443: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.1920 - mae: 12.5253 - val_loss: 28.9879 - val_mae: 28.8341\n",
            "Epoch 444/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.6287 - mae: 12.1151\n",
            "Epoch 00444: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 12.1651 - mae: 12.4982 - val_loss: 23.3669 - val_mae: 23.2182\n",
            "Epoch 445/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.6934 - mae: 12.1798\n",
            "Epoch 00445: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 12.2124 - mae: 12.5505 - val_loss: 29.0545 - val_mae: 28.9101\n",
            "Epoch 446/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.6593 - mae: 12.1455\n",
            "Epoch 00446: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 12.1899 - mae: 12.5245 - val_loss: 22.5241 - val_mae: 22.3813\n",
            "Epoch 447/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.6118 - mae: 12.0980\n",
            "Epoch 00447: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 12.1238 - mae: 12.4638 - val_loss: 28.7318 - val_mae: 28.5739\n",
            "Epoch 448/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.8168 - mae: 12.3031\n",
            "Epoch 00448: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.3091 - mae: 12.6547 - val_loss: 24.0354 - val_mae: 23.8706\n",
            "Epoch 449/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.7106 - mae: 12.1969\n",
            "Epoch 00449: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 12.2170 - mae: 12.5587 - val_loss: 30.2139 - val_mae: 30.0247\n",
            "Epoch 450/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.8326 - mae: 12.3195\n",
            "Epoch 00450: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 12.3606 - mae: 12.6966 - val_loss: 21.4882 - val_mae: 21.3080\n",
            "Epoch 451/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.9817 - mae: 12.4691\n",
            "Epoch 00451: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.4929 - mae: 12.8342 - val_loss: 30.1920 - val_mae: 30.0085\n",
            "Epoch 452/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.7434 - mae: 12.2303\n",
            "Epoch 00452: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.2399 - mae: 12.5849 - val_loss: 25.2795 - val_mae: 25.0815\n",
            "Epoch 453/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.5254 - mae: 12.0116\n",
            "Epoch 00453: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 12.0541 - mae: 12.3892 - val_loss: 28.9627 - val_mae: 28.7793\n",
            "Epoch 454/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.5805 - mae: 12.0669\n",
            "Epoch 00454: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.0917 - mae: 12.4320 - val_loss: 25.4057 - val_mae: 25.1965\n",
            "Epoch 455/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.6806 - mae: 12.1673\n",
            "Epoch 00455: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.2046 - mae: 12.5416 - val_loss: 27.6572 - val_mae: 27.4833\n",
            "Epoch 456/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.5282 - mae: 12.0142\n",
            "Epoch 00456: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 12.0505 - mae: 12.3872 - val_loss: 27.3884 - val_mae: 27.2008\n",
            "Epoch 457/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.6743 - mae: 12.1605\n",
            "Epoch 00457: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 12.1735 - mae: 12.5170 - val_loss: 24.5047 - val_mae: 24.3724\n",
            "Epoch 458/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.5896 - mae: 12.0755\n",
            "Epoch 00458: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 12.1019 - mae: 12.4415 - val_loss: 29.7432 - val_mae: 29.5841\n",
            "Epoch 459/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.7069 - mae: 12.1922\n",
            "Epoch 00459: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.2249 - mae: 12.5622 - val_loss: 22.3491 - val_mae: 22.2005\n",
            "Epoch 460/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.9939 - mae: 12.4806\n",
            "Epoch 00460: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 12.5096 - mae: 12.8489 - val_loss: 39.0628 - val_mae: 38.7740\n",
            "Epoch 461/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.6475 - mae: 12.1343\n",
            "Epoch 00461: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 12.1514 - mae: 12.4941 - val_loss: 25.4684 - val_mae: 25.2469\n",
            "Epoch 462/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.5861 - mae: 12.0727\n",
            "Epoch 00462: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 12.1338 - mae: 12.4639 - val_loss: 24.9947 - val_mae: 24.7824\n",
            "Epoch 463/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.3538 - mae: 11.8388\n",
            "Epoch 00463: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.8863 - mae: 12.2192 - val_loss: 29.8338 - val_mae: 29.5805\n",
            "Epoch 464/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.5162 - mae: 12.0019\n",
            "Epoch 00464: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 12.0303 - mae: 12.3690 - val_loss: 23.7273 - val_mae: 23.5078\n",
            "Epoch 465/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.5814 - mae: 12.0672\n",
            "Epoch 00465: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 12.1133 - mae: 12.4471 - val_loss: 33.4722 - val_mae: 33.2224\n",
            "Epoch 466/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.5743 - mae: 12.0606\n",
            "Epoch 00466: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 12.0891 - mae: 12.4283 - val_loss: 23.5803 - val_mae: 23.3590\n",
            "Epoch 467/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.5756 - mae: 12.0626\n",
            "Epoch 00467: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 12.0503 - mae: 12.4017 - val_loss: 29.0989 - val_mae: 28.8654\n",
            "Epoch 468/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.3880 - mae: 11.8735\n",
            "Epoch 00468: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.8801 - mae: 12.2249 - val_loss: 27.1340 - val_mae: 26.8958\n",
            "Epoch 469/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2706 - mae: 11.7560\n",
            "Epoch 00469: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.8166 - mae: 12.1461 - val_loss: 27.3067 - val_mae: 27.0737\n",
            "Epoch 470/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2571 - mae: 11.7421\n",
            "Epoch 00470: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.7768 - mae: 12.1133 - val_loss: 27.5358 - val_mae: 27.2975\n",
            "Epoch 471/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.3076 - mae: 11.7933\n",
            "Epoch 00471: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.8282 - mae: 12.1651 - val_loss: 26.2360 - val_mae: 26.0165\n",
            "Epoch 472/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2694 - mae: 11.7543\n",
            "Epoch 00472: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.7930 - mae: 12.1283 - val_loss: 26.8930 - val_mae: 26.6550\n",
            "Epoch 473/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2529 - mae: 11.7377\n",
            "Epoch 00473: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.7457 - mae: 12.0898 - val_loss: 28.0243 - val_mae: 27.8029\n",
            "Epoch 474/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2622 - mae: 11.7475\n",
            "Epoch 00474: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.7805 - mae: 12.1177 - val_loss: 27.1638 - val_mae: 26.9531\n",
            "Epoch 475/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2274 - mae: 11.7127\n",
            "Epoch 00475: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.7326 - mae: 12.0736 - val_loss: 27.1636 - val_mae: 26.9535\n",
            "Epoch 476/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1298 - mae: 11.6149\n",
            "Epoch 00476: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.6346 - mae: 11.9754 - val_loss: 25.1556 - val_mae: 24.9655\n",
            "Epoch 477/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2827 - mae: 11.7675\n",
            "Epoch 00477: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.7933 - mae: 12.1322 - val_loss: 24.8136 - val_mae: 24.6282\n",
            "Epoch 478/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2336 - mae: 11.7184\n",
            "Epoch 00478: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.7302 - mae: 12.0731 - val_loss: 24.6422 - val_mae: 24.4696\n",
            "Epoch 479/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1645 - mae: 11.6494\n",
            "Epoch 00479: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.6691 - mae: 12.0098 - val_loss: 26.2619 - val_mae: 26.0948\n",
            "Epoch 480/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2899 - mae: 11.7749\n",
            "Epoch 00480: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 178ms/step - loss: 11.7906 - mae: 12.1325 - val_loss: 25.6144 - val_mae: 25.4589\n",
            "Epoch 481/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.4610 - mae: 11.9463\n",
            "Epoch 00481: val_loss did not improve from 21.06688\n",
            "30/30 [==============================] - 5s 178ms/step - loss: 11.9886 - mae: 12.3232 - val_loss: 31.3851 - val_mae: 31.1917\n",
            "Epoch 482/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.6394 - mae: 12.1241\n",
            "Epoch 00482: val_loss improved from 21.06688 to 20.90603, saving model to cp/weights-482-20.91.hdf5\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 12.1891 - mae: 12.5168 - val_loss: 20.9060 - val_mae: 20.7495\n",
            "Epoch 483/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 12.3534 - mae: 12.8402\n",
            "Epoch 00483: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 12.8567 - mae: 13.1997 - val_loss: 39.3761 - val_mae: 39.0773\n",
            "Epoch 484/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.5834 - mae: 12.0697\n",
            "Epoch 00484: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 12.0603 - mae: 12.4103 - val_loss: 28.2386 - val_mae: 28.0333\n",
            "Epoch 485/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.3684 - mae: 11.8544\n",
            "Epoch 00485: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.8723 - mae: 12.2142 - val_loss: 24.9410 - val_mae: 24.7565\n",
            "Epoch 486/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2648 - mae: 11.7498\n",
            "Epoch 00486: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.7726 - mae: 12.1125 - val_loss: 31.9297 - val_mae: 31.6961\n",
            "Epoch 487/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.3973 - mae: 11.8828\n",
            "Epoch 00487: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.8802 - mae: 12.2278 - val_loss: 22.4478 - val_mae: 22.2389\n",
            "Epoch 488/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.4758 - mae: 11.9625\n",
            "Epoch 00488: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.9518 - mae: 12.3025 - val_loss: 28.4095 - val_mae: 28.1944\n",
            "Epoch 489/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2693 - mae: 11.7548\n",
            "Epoch 00489: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.7714 - mae: 12.1134 - val_loss: 26.6609 - val_mae: 26.4308\n",
            "Epoch 490/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2577 - mae: 11.7434\n",
            "Epoch 00490: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.7373 - mae: 12.0859 - val_loss: 27.2350 - val_mae: 27.0247\n",
            "Epoch 491/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2146 - mae: 11.6994\n",
            "Epoch 00491: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.7131 - mae: 12.0555 - val_loss: 25.5737 - val_mae: 25.3574\n",
            "Epoch 492/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2950 - mae: 11.7802\n",
            "Epoch 00492: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.7826 - mae: 12.1285 - val_loss: 27.2051 - val_mae: 26.9962\n",
            "Epoch 493/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1622 - mae: 11.6473\n",
            "Epoch 00493: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.6458 - mae: 11.9927 - val_loss: 27.7035 - val_mae: 27.4929\n",
            "Epoch 494/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0944 - mae: 11.5794\n",
            "Epoch 00494: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 11.5844 - mae: 11.9294 - val_loss: 26.7419 - val_mae: 26.5458\n",
            "Epoch 495/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0589 - mae: 11.5432\n",
            "Epoch 00495: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 11.5404 - mae: 11.8871 - val_loss: 25.7073 - val_mae: 25.5087\n",
            "Epoch 496/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1076 - mae: 11.5924\n",
            "Epoch 00496: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 178ms/step - loss: 11.5852 - mae: 11.9335 - val_loss: 24.0187 - val_mae: 23.8309\n",
            "Epoch 497/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2033 - mae: 11.6880\n",
            "Epoch 00497: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.7185 - mae: 12.0561 - val_loss: 29.2277 - val_mae: 29.0230\n",
            "Epoch 498/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2190 - mae: 11.7040\n",
            "Epoch 00498: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.6958 - mae: 12.0446 - val_loss: 23.1253 - val_mae: 22.9659\n",
            "Epoch 499/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.3630 - mae: 11.8487\n",
            "Epoch 00499: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 180ms/step - loss: 11.8762 - mae: 12.2152 - val_loss: 33.6798 - val_mae: 33.4520\n",
            "Epoch 500/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.3069 - mae: 11.7918\n",
            "Epoch 00500: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 180ms/step - loss: 11.7985 - mae: 12.1430 - val_loss: 21.4201 - val_mae: 21.2366\n",
            "Epoch 501/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.8532 - mae: 12.3408\n",
            "Epoch 00501: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 12.3553 - mae: 12.6994 - val_loss: 32.6463 - val_mae: 32.4299\n",
            "Epoch 502/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.5257 - mae: 12.0127\n",
            "Epoch 00502: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 12.0131 - mae: 12.3608 - val_loss: 25.7923 - val_mae: 25.5582\n",
            "Epoch 503/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2885 - mae: 11.7741\n",
            "Epoch 00503: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.7860 - mae: 12.1295 - val_loss: 26.4356 - val_mae: 26.2197\n",
            "Epoch 504/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1251 - mae: 11.6095\n",
            "Epoch 00504: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 11.6285 - mae: 11.9691 - val_loss: 27.2607 - val_mae: 27.0488\n",
            "Epoch 505/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1624 - mae: 11.6470\n",
            "Epoch 00505: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.6398 - mae: 11.9880 - val_loss: 23.0609 - val_mae: 22.8543\n",
            "Epoch 506/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1810 - mae: 11.6664\n",
            "Epoch 00506: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.6689 - mae: 12.0149 - val_loss: 29.7014 - val_mae: 29.4657\n",
            "Epoch 507/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1028 - mae: 11.5880\n",
            "Epoch 00507: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.6085 - mae: 11.9492 - val_loss: 23.7250 - val_mae: 23.5069\n",
            "Epoch 508/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2126 - mae: 11.6980\n",
            "Epoch 00508: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.7153 - mae: 12.0571 - val_loss: 31.0387 - val_mae: 30.8087\n",
            "Epoch 509/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2559 - mae: 11.7406\n",
            "Epoch 00509: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.7186 - mae: 12.0712 - val_loss: 23.1460 - val_mae: 22.9300\n",
            "Epoch 510/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.3724 - mae: 11.8589\n",
            "Epoch 00510: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.8276 - mae: 12.1841 - val_loss: 30.7492 - val_mae: 30.5324\n",
            "Epoch 511/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2810 - mae: 11.7665\n",
            "Epoch 00511: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 11.7810 - mae: 12.1236 - val_loss: 25.0294 - val_mae: 24.8107\n",
            "Epoch 512/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2971 - mae: 11.7830\n",
            "Epoch 00512: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.8007 - mae: 12.1427 - val_loss: 26.5704 - val_mae: 26.3689\n",
            "Epoch 513/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0766 - mae: 11.5614\n",
            "Epoch 00513: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.5473 - mae: 11.8976 - val_loss: 28.3087 - val_mae: 28.1031\n",
            "Epoch 514/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1171 - mae: 11.6017\n",
            "Epoch 00514: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.6084 - mae: 11.9526 - val_loss: 23.8737 - val_mae: 23.6734\n",
            "Epoch 515/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0772 - mae: 11.5621\n",
            "Epoch 00515: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.5706 - mae: 11.9145 - val_loss: 28.6851 - val_mae: 28.4772\n",
            "Epoch 516/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0576 - mae: 11.5424\n",
            "Epoch 00516: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.5495 - mae: 11.8938 - val_loss: 22.7889 - val_mae: 22.5937\n",
            "Epoch 517/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1978 - mae: 11.6834\n",
            "Epoch 00517: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.6958 - mae: 12.0392 - val_loss: 29.9689 - val_mae: 29.7571\n",
            "Epoch 518/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1836 - mae: 11.6690\n",
            "Epoch 00518: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.6689 - mae: 12.0156 - val_loss: 23.1997 - val_mae: 22.9971\n",
            "Epoch 519/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1962 - mae: 11.6821\n",
            "Epoch 00519: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.6738 - mae: 12.0232 - val_loss: 30.3225 - val_mae: 30.1119\n",
            "Epoch 520/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1970 - mae: 11.6821\n",
            "Epoch 00520: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.6553 - mae: 12.0094 - val_loss: 24.2662 - val_mae: 24.0562\n",
            "Epoch 521/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0835 - mae: 11.5688\n",
            "Epoch 00521: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.5623 - mae: 11.9108 - val_loss: 28.2187 - val_mae: 28.0219\n",
            "Epoch 522/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1075 - mae: 11.5924\n",
            "Epoch 00522: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.5845 - mae: 11.9332 - val_loss: 24.2151 - val_mae: 24.0013\n",
            "Epoch 523/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1761 - mae: 11.6618\n",
            "Epoch 00523: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.6770 - mae: 12.0196 - val_loss: 28.5490 - val_mae: 28.3566\n",
            "Epoch 524/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1338 - mae: 11.6191\n",
            "Epoch 00524: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.6136 - mae: 11.9618 - val_loss: 24.4642 - val_mae: 24.2610\n",
            "Epoch 525/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0875 - mae: 11.5726\n",
            "Epoch 00525: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.5790 - mae: 11.9237 - val_loss: 27.9530 - val_mae: 27.7511\n",
            "Epoch 526/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0689 - mae: 11.5538\n",
            "Epoch 00526: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 178ms/step - loss: 11.5654 - mae: 11.9084 - val_loss: 26.4889 - val_mae: 26.2889\n",
            "Epoch 527/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9404 - mae: 11.4246\n",
            "Epoch 00527: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.4571 - mae: 11.7937 - val_loss: 24.4275 - val_mae: 24.2333\n",
            "Epoch 528/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8215 - mae: 11.3056\n",
            "Epoch 00528: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 11.3090 - mae: 11.6538 - val_loss: 26.1299 - val_mae: 25.9263\n",
            "Epoch 529/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0726 - mae: 11.5571\n",
            "Epoch 00529: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.5772 - mae: 11.9176 - val_loss: 23.3359 - val_mae: 23.1562\n",
            "Epoch 530/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2463 - mae: 11.7311\n",
            "Epoch 00530: val_loss did not improve from 20.90603\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.7568 - mae: 12.0958 - val_loss: 33.2412 - val_mae: 33.0146\n",
            "Epoch 531/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.3263 - mae: 11.8111\n",
            "Epoch 00531: val_loss improved from 20.90603 to 19.99956, saving model to cp/weights-531-20.00.hdf5\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.8616 - mae: 12.1935 - val_loss: 19.9996 - val_mae: 19.8177\n",
            "Epoch 532/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.9666 - mae: 12.4548\n",
            "Epoch 00532: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 12.4369 - mae: 12.7906 - val_loss: 32.1572 - val_mae: 31.9196\n",
            "Epoch 533/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2796 - mae: 11.7653\n",
            "Epoch 00533: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.7647 - mae: 12.1118 - val_loss: 27.2977 - val_mae: 27.0472\n",
            "Epoch 534/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9733 - mae: 11.4577\n",
            "Epoch 00534: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.4470 - mae: 11.7962 - val_loss: 23.9357 - val_mae: 23.7188\n",
            "Epoch 535/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8922 - mae: 11.3771\n",
            "Epoch 00535: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.3856 - mae: 11.7295 - val_loss: 28.5750 - val_mae: 28.3548\n",
            "Epoch 536/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8420 - mae: 11.3265\n",
            "Epoch 00536: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.3357 - mae: 11.6791 - val_loss: 24.1433 - val_mae: 23.9297\n",
            "Epoch 537/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9599 - mae: 11.4447\n",
            "Epoch 00537: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.4382 - mae: 11.7864 - val_loss: 26.3886 - val_mae: 26.1822\n",
            "Epoch 538/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8802 - mae: 11.3644\n",
            "Epoch 00538: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.3443 - mae: 11.6959 - val_loss: 25.3325 - val_mae: 25.1120\n",
            "Epoch 539/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8786 - mae: 11.3629\n",
            "Epoch 00539: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 11.3366 - mae: 11.6900 - val_loss: 25.9275 - val_mae: 25.7241\n",
            "Epoch 540/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8414 - mae: 11.3254\n",
            "Epoch 00540: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 11.3179 - mae: 11.6658 - val_loss: 25.4029 - val_mae: 25.1965\n",
            "Epoch 541/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7832 - mae: 11.2667\n",
            "Epoch 00541: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.2913 - mae: 11.6297 - val_loss: 26.0299 - val_mae: 25.8410\n",
            "Epoch 542/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9526 - mae: 11.4358\n",
            "Epoch 00542: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.4392 - mae: 11.7834 - val_loss: 24.1990 - val_mae: 24.0007\n",
            "Epoch 543/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0854 - mae: 11.5703\n",
            "Epoch 00543: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.5907 - mae: 11.9313 - val_loss: 32.8039 - val_mae: 32.5821\n",
            "Epoch 544/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1173 - mae: 11.6019\n",
            "Epoch 00544: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 11.6416 - mae: 11.9765 - val_loss: 21.2881 - val_mae: 21.1043\n",
            "Epoch 545/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.5414 - mae: 12.0278\n",
            "Epoch 00545: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 12.0348 - mae: 12.3802 - val_loss: 32.9895 - val_mae: 32.7720\n",
            "Epoch 546/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2498 - mae: 11.7358\n",
            "Epoch 00546: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.7417 - mae: 12.0871 - val_loss: 23.1374 - val_mae: 22.9206\n",
            "Epoch 547/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.3275 - mae: 11.8140\n",
            "Epoch 00547: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 11.7671 - mae: 12.1280 - val_loss: 25.1337 - val_mae: 24.9419\n",
            "Epoch 548/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9231 - mae: 11.4067\n",
            "Epoch 00548: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 11.4038 - mae: 11.7500 - val_loss: 29.6601 - val_mae: 29.4245\n",
            "Epoch 549/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0182 - mae: 11.5019\n",
            "Epoch 00549: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 11.5148 - mae: 11.8567 - val_loss: 21.7280 - val_mae: 21.5186\n",
            "Epoch 550/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0422 - mae: 11.5273\n",
            "Epoch 00550: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.5406 - mae: 11.8833 - val_loss: 29.2266 - val_mae: 29.0014\n",
            "Epoch 551/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8601 - mae: 11.3446\n",
            "Epoch 00551: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 11.3875 - mae: 11.7213 - val_loss: 23.3449 - val_mae: 23.1312\n",
            "Epoch 552/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9054 - mae: 11.3903\n",
            "Epoch 00552: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.3693 - mae: 11.7217 - val_loss: 27.3843 - val_mae: 27.1710\n",
            "Epoch 553/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8113 - mae: 11.2949\n",
            "Epoch 00553: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 11.2705 - mae: 11.6229 - val_loss: 25.2140 - val_mae: 24.9974\n",
            "Epoch 554/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7783 - mae: 11.2626\n",
            "Epoch 00554: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 11.2722 - mae: 11.6154 - val_loss: 28.3886 - val_mae: 28.1784\n",
            "Epoch 555/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8250 - mae: 11.3087\n",
            "Epoch 00555: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 11.2940 - mae: 11.6437 - val_loss: 23.7715 - val_mae: 23.5763\n",
            "Epoch 556/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8428 - mae: 11.3269\n",
            "Epoch 00556: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.3229 - mae: 11.6699 - val_loss: 29.8904 - val_mae: 29.6861\n",
            "Epoch 557/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9774 - mae: 11.4618\n",
            "Epoch 00557: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.4645 - mae: 11.8098 - val_loss: 21.8829 - val_mae: 21.6889\n",
            "Epoch 558/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2701 - mae: 11.7564\n",
            "Epoch 00558: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 11.7158 - mae: 12.0747 - val_loss: 30.2943 - val_mae: 30.0856\n",
            "Epoch 559/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2367 - mae: 11.7224\n",
            "Epoch 00559: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.6776 - mae: 12.0374 - val_loss: 21.7456 - val_mae: 21.5389\n",
            "Epoch 560/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2774 - mae: 11.7641\n",
            "Epoch 00560: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 11.7448 - mae: 12.0979 - val_loss: 28.4319 - val_mae: 28.2201\n",
            "Epoch 561/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8254 - mae: 11.3092\n",
            "Epoch 00561: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 11.2834 - mae: 11.6364 - val_loss: 27.7521 - val_mae: 27.5373\n",
            "Epoch 562/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7690 - mae: 11.2529\n",
            "Epoch 00562: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 6s 190ms/step - loss: 11.2216 - mae: 11.5762 - val_loss: 24.2221 - val_mae: 24.0075\n",
            "Epoch 563/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8089 - mae: 11.2928\n",
            "Epoch 00563: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 11.2680 - mae: 11.6207 - val_loss: 29.3462 - val_mae: 29.1206\n",
            "Epoch 564/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8190 - mae: 11.3031\n",
            "Epoch 00564: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.2689 - mae: 11.6245 - val_loss: 23.2632 - val_mae: 23.0598\n",
            "Epoch 565/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8712 - mae: 11.3559\n",
            "Epoch 00565: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.3418 - mae: 11.6921 - val_loss: 26.1176 - val_mae: 25.9250\n",
            "Epoch 566/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7277 - mae: 11.2113\n",
            "Epoch 00566: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.2325 - mae: 11.5719 - val_loss: 27.0540 - val_mae: 26.8496\n",
            "Epoch 567/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8238 - mae: 11.3077\n",
            "Epoch 00567: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.2973 - mae: 11.6460 - val_loss: 22.9911 - val_mae: 22.7895\n",
            "Epoch 568/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0501 - mae: 11.5344\n",
            "Epoch 00568: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 11.4891 - mae: 11.8480 - val_loss: 32.3143 - val_mae: 32.0843\n",
            "Epoch 569/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9763 - mae: 11.4620\n",
            "Epoch 00569: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.4709 - mae: 11.8152 - val_loss: 21.9621 - val_mae: 21.7628\n",
            "Epoch 570/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2917 - mae: 11.7778\n",
            "Epoch 00570: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.7565 - mae: 12.1099 - val_loss: 28.3767 - val_mae: 28.1922\n",
            "Epoch 571/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9805 - mae: 11.4648\n",
            "Epoch 00571: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.4557 - mae: 11.8042 - val_loss: 28.0834 - val_mae: 27.8732\n",
            "Epoch 572/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7502 - mae: 11.2341\n",
            "Epoch 00572: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.2399 - mae: 11.5840 - val_loss: 22.4537 - val_mae: 22.2494\n",
            "Epoch 573/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7388 - mae: 11.2229\n",
            "Epoch 00573: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.2215 - mae: 11.5678 - val_loss: 28.5110 - val_mae: 28.2921\n",
            "Epoch 574/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8121 - mae: 11.2963\n",
            "Epoch 00574: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.2640 - mae: 11.6191 - val_loss: 23.9261 - val_mae: 23.7179\n",
            "Epoch 575/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8669 - mae: 11.3517\n",
            "Epoch 00575: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 11.3012 - mae: 11.6619 - val_loss: 26.8928 - val_mae: 26.6966\n",
            "Epoch 576/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7704 - mae: 11.2542\n",
            "Epoch 00576: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.2431 - mae: 11.5919 - val_loss: 28.6204 - val_mae: 28.4186\n",
            "Epoch 577/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7589 - mae: 11.2426\n",
            "Epoch 00577: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.2340 - mae: 11.5821 - val_loss: 22.1989 - val_mae: 22.0083\n",
            "Epoch 578/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8845 - mae: 11.3691\n",
            "Epoch 00578: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.3700 - mae: 11.7159 - val_loss: 29.0239 - val_mae: 28.8201\n",
            "Epoch 579/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9300 - mae: 11.4140\n",
            "Epoch 00579: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.3852 - mae: 11.7393 - val_loss: 21.9257 - val_mae: 21.7159\n",
            "Epoch 580/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1809 - mae: 11.6669\n",
            "Epoch 00580: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 11.6242 - mae: 11.9836 - val_loss: 29.5563 - val_mae: 29.3539\n",
            "Epoch 581/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9217 - mae: 11.4065\n",
            "Epoch 00581: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.3744 - mae: 11.7298 - val_loss: 26.6548 - val_mae: 26.4190\n",
            "Epoch 582/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7956 - mae: 11.2796\n",
            "Epoch 00582: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.2615 - mae: 11.6124 - val_loss: 25.3495 - val_mae: 25.1463\n",
            "Epoch 583/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7613 - mae: 11.2439\n",
            "Epoch 00583: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.2027 - mae: 11.5592 - val_loss: 28.9221 - val_mae: 28.6935\n",
            "Epoch 584/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7429 - mae: 11.2271\n",
            "Epoch 00584: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.1895 - mae: 11.5461 - val_loss: 23.8241 - val_mae: 23.6194\n",
            "Epoch 585/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8030 - mae: 11.2871\n",
            "Epoch 00585: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.2730 - mae: 11.6229 - val_loss: 26.7176 - val_mae: 26.5154\n",
            "Epoch 586/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6146 - mae: 11.0978\n",
            "Epoch 00586: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.0937 - mae: 11.4400 - val_loss: 25.3768 - val_mae: 25.1889\n",
            "Epoch 587/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5946 - mae: 11.0778\n",
            "Epoch 00587: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.0789 - mae: 11.4237 - val_loss: 27.2657 - val_mae: 27.0835\n",
            "Epoch 588/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6831 - mae: 11.1664\n",
            "Epoch 00588: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.1710 - mae: 11.5150 - val_loss: 23.9180 - val_mae: 23.7452\n",
            "Epoch 589/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7760 - mae: 11.2599\n",
            "Epoch 00589: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.2364 - mae: 11.5888 - val_loss: 28.3181 - val_mae: 28.1335\n",
            "Epoch 590/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9231 - mae: 11.4075\n",
            "Epoch 00590: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.4095 - mae: 11.7550 - val_loss: 20.9009 - val_mae: 20.7173\n",
            "Epoch 591/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.3869 - mae: 11.8734\n",
            "Epoch 00591: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.8725 - mae: 12.2203 - val_loss: 33.4051 - val_mae: 33.1594\n",
            "Epoch 592/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1852 - mae: 11.6711\n",
            "Epoch 00592: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.6326 - mae: 11.9907 - val_loss: 25.0541 - val_mae: 24.8270\n",
            "Epoch 593/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8688 - mae: 11.3539\n",
            "Epoch 00593: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.3244 - mae: 11.6794 - val_loss: 23.9686 - val_mae: 23.7767\n",
            "Epoch 594/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6701 - mae: 11.1532\n",
            "Epoch 00594: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1581 - mae: 11.5019 - val_loss: 27.5753 - val_mae: 27.3632\n",
            "Epoch 595/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6737 - mae: 11.1568\n",
            "Epoch 00595: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1262 - mae: 11.4800 - val_loss: 24.5590 - val_mae: 24.3471\n",
            "Epoch 596/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6309 - mae: 11.1145\n",
            "Epoch 00596: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1037 - mae: 11.4523 - val_loss: 27.0523 - val_mae: 26.8392\n",
            "Epoch 597/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5651 - mae: 11.0479\n",
            "Epoch 00597: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.0461 - mae: 11.3916 - val_loss: 24.8481 - val_mae: 24.6611\n",
            "Epoch 598/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5930 - mae: 11.0758\n",
            "Epoch 00598: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.0765 - mae: 11.4212 - val_loss: 25.0737 - val_mae: 24.8889\n",
            "Epoch 599/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6418 - mae: 11.1250\n",
            "Epoch 00599: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 11.1230 - mae: 11.4687 - val_loss: 24.5513 - val_mae: 24.3690\n",
            "Epoch 600/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6111 - mae: 11.0940\n",
            "Epoch 00600: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.0914 - mae: 11.4371 - val_loss: 26.0378 - val_mae: 25.8558\n",
            "Epoch 601/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5559 - mae: 11.0385\n",
            "Epoch 00601: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.0517 - mae: 11.3928 - val_loss: 25.6636 - val_mae: 25.4899\n",
            "Epoch 602/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6235 - mae: 11.1062\n",
            "Epoch 00602: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1230 - mae: 11.4630 - val_loss: 23.2703 - val_mae: 23.0996\n",
            "Epoch 603/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7099 - mae: 11.1934\n",
            "Epoch 00603: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1862 - mae: 11.5337 - val_loss: 26.3275 - val_mae: 26.1462\n",
            "Epoch 604/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7757 - mae: 11.2590\n",
            "Epoch 00604: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 11.2572 - mae: 11.6030 - val_loss: 21.3850 - val_mae: 21.2225\n",
            "Epoch 605/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2061 - mae: 11.6912\n",
            "Epoch 00605: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.6857 - mae: 12.0338 - val_loss: 33.9839 - val_mae: 33.7518\n",
            "Epoch 606/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8640 - mae: 11.3483\n",
            "Epoch 00606: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.3339 - mae: 11.6841 - val_loss: 20.9940 - val_mae: 20.8275\n",
            "Epoch 607/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.1794 - mae: 11.6655\n",
            "Epoch 00607: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.6446 - mae: 11.9978 - val_loss: 30.4208 - val_mae: 30.2328\n",
            "Epoch 608/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9687 - mae: 11.4537\n",
            "Epoch 00608: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.4014 - mae: 11.7627 - val_loss: 24.8125 - val_mae: 24.6187\n",
            "Epoch 609/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7489 - mae: 11.2328\n",
            "Epoch 00609: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.1968 - mae: 11.5528 - val_loss: 24.0435 - val_mae: 23.8523\n",
            "Epoch 610/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6338 - mae: 11.1171\n",
            "Epoch 00610: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.1169 - mae: 11.4623 - val_loss: 28.0505 - val_mae: 27.8506\n",
            "Epoch 611/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5714 - mae: 11.0546\n",
            "Epoch 00611: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.0088 - mae: 11.3671 - val_loss: 24.0516 - val_mae: 23.8701\n",
            "Epoch 612/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6352 - mae: 11.1186\n",
            "Epoch 00612: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.1011 - mae: 11.4514 - val_loss: 25.7222 - val_mae: 25.5274\n",
            "Epoch 613/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6525 - mae: 11.1349\n",
            "Epoch 00613: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.1240 - mae: 11.4718 - val_loss: 27.1203 - val_mae: 26.9372\n",
            "Epoch 614/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7166 - mae: 11.1997\n",
            "Epoch 00614: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.1658 - mae: 11.5206 - val_loss: 21.8505 - val_mae: 21.6840\n",
            "Epoch 615/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2238 - mae: 11.7088\n",
            "Epoch 00615: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.6961 - mae: 12.0461 - val_loss: 34.1692 - val_mae: 33.9407\n",
            "Epoch 616/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9713 - mae: 11.4568\n",
            "Epoch 00616: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.4607 - mae: 11.8063 - val_loss: 24.0761 - val_mae: 23.8748\n",
            "Epoch 617/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0487 - mae: 11.5345\n",
            "Epoch 00617: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.4919 - mae: 11.8511 - val_loss: 23.6979 - val_mae: 23.5247\n",
            "Epoch 618/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6428 - mae: 11.1258\n",
            "Epoch 00618: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.0944 - mae: 11.4484 - val_loss: 29.9940 - val_mae: 29.7773\n",
            "Epoch 619/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7811 - mae: 11.2656\n",
            "Epoch 00619: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 179ms/step - loss: 11.2223 - mae: 11.5808 - val_loss: 23.1883 - val_mae: 22.9885\n",
            "Epoch 620/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0122 - mae: 11.4977\n",
            "Epoch 00620: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 178ms/step - loss: 11.4676 - mae: 11.8229 - val_loss: 26.2467 - val_mae: 26.0513\n",
            "Epoch 621/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7396 - mae: 11.2228\n",
            "Epoch 00621: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.2028 - mae: 11.5537 - val_loss: 27.7073 - val_mae: 27.4992\n",
            "Epoch 622/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7252 - mae: 11.2083\n",
            "Epoch 00622: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.1675 - mae: 11.5243 - val_loss: 22.8521 - val_mae: 22.6491\n",
            "Epoch 623/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6771 - mae: 11.1601\n",
            "Epoch 00623: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1305 - mae: 11.4840 - val_loss: 28.5916 - val_mae: 28.3717\n",
            "Epoch 624/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6780 - mae: 11.1615\n",
            "Epoch 00624: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1409 - mae: 11.4922 - val_loss: 22.8127 - val_mae: 22.6141\n",
            "Epoch 625/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7164 - mae: 11.2007\n",
            "Epoch 00625: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.1570 - mae: 11.5154 - val_loss: 28.1585 - val_mae: 27.9506\n",
            "Epoch 626/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5928 - mae: 11.0757\n",
            "Epoch 00626: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.0426 - mae: 11.3971 - val_loss: 23.6684 - val_mae: 23.4674\n",
            "Epoch 627/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8528 - mae: 11.3371\n",
            "Epoch 00627: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.2914 - mae: 11.6504 - val_loss: 27.9744 - val_mae: 27.7773\n",
            "Epoch 628/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6417 - mae: 11.1252\n",
            "Epoch 00628: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.1050 - mae: 11.4562 - val_loss: 23.8953 - val_mae: 23.7113\n",
            "Epoch 629/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6201 - mae: 11.1031\n",
            "Epoch 00629: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 11.0746 - mae: 11.4278 - val_loss: 25.4255 - val_mae: 25.2403\n",
            "Epoch 630/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5364 - mae: 11.0189\n",
            "Epoch 00630: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.9952 - mae: 11.3467 - val_loss: 27.1911 - val_mae: 26.9945\n",
            "Epoch 631/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6605 - mae: 11.1436\n",
            "Epoch 00631: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.1069 - mae: 11.4625 - val_loss: 22.0436 - val_mae: 21.8641\n",
            "Epoch 632/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6828 - mae: 11.1673\n",
            "Epoch 00632: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.1604 - mae: 11.5084 - val_loss: 28.1137 - val_mae: 27.9353\n",
            "Epoch 633/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6152 - mae: 11.0992\n",
            "Epoch 00633: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.0702 - mae: 11.4243 - val_loss: 22.6620 - val_mae: 22.5053\n",
            "Epoch 634/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7017 - mae: 11.1854\n",
            "Epoch 00634: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 11.1657 - mae: 11.5168 - val_loss: 27.1977 - val_mae: 27.0222\n",
            "Epoch 635/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5624 - mae: 11.0458\n",
            "Epoch 00635: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 178ms/step - loss: 10.9992 - mae: 11.3578 - val_loss: 24.5071 - val_mae: 24.3327\n",
            "Epoch 636/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5619 - mae: 11.0451\n",
            "Epoch 00636: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.0544 - mae: 11.3969 - val_loss: 26.4050 - val_mae: 26.2344\n",
            "Epoch 637/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5196 - mae: 11.0024\n",
            "Epoch 00637: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.9566 - mae: 11.3147 - val_loss: 25.0104 - val_mae: 24.8440\n",
            "Epoch 638/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5046 - mae: 10.9869\n",
            "Epoch 00638: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 10.9582 - mae: 11.3110 - val_loss: 25.3664 - val_mae: 25.2042\n",
            "Epoch 639/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5954 - mae: 11.0776\n",
            "Epoch 00639: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.0539 - mae: 11.4051 - val_loss: 22.1221 - val_mae: 21.9592\n",
            "Epoch 640/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8599 - mae: 11.3435\n",
            "Epoch 00640: val_loss did not improve from 19.99956\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.3187 - mae: 11.6713 - val_loss: 30.0459 - val_mae: 29.8620\n",
            "Epoch 641/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9004 - mae: 11.3842\n",
            "Epoch 00641: val_loss improved from 19.99956 to 19.00507, saving model to cp/weights-641-19.01.hdf5\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.3676 - mae: 11.7181 - val_loss: 19.0051 - val_mae: 18.8612\n",
            "Epoch 642/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2693 - mae: 11.7555\n",
            "Epoch 00642: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.7141 - mae: 12.0732 - val_loss: 30.4423 - val_mae: 30.2525\n",
            "Epoch 643/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9636 - mae: 11.4485\n",
            "Epoch 00643: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.4234 - mae: 11.7770 - val_loss: 25.2613 - val_mae: 25.0706\n",
            "Epoch 644/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5835 - mae: 11.0673\n",
            "Epoch 00644: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.0511 - mae: 11.4013 - val_loss: 23.0260 - val_mae: 22.8474\n",
            "Epoch 645/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6359 - mae: 11.1191\n",
            "Epoch 00645: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.0937 - mae: 11.4462 - val_loss: 27.4025 - val_mae: 27.2089\n",
            "Epoch 646/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5570 - mae: 11.0405\n",
            "Epoch 00646: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.0292 - mae: 11.3779 - val_loss: 23.6437 - val_mae: 23.4630\n",
            "Epoch 647/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6718 - mae: 11.1551\n",
            "Epoch 00647: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1103 - mae: 11.4683 - val_loss: 26.7861 - val_mae: 26.5857\n",
            "Epoch 648/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4707 - mae: 10.9530\n",
            "Epoch 00648: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.9180 - mae: 11.2726 - val_loss: 24.3859 - val_mae: 24.2026\n",
            "Epoch 649/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4291 - mae: 10.9117\n",
            "Epoch 00649: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.8937 - mae: 11.2436 - val_loss: 24.1793 - val_mae: 24.0072\n",
            "Epoch 650/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4444 - mae: 10.9266\n",
            "Epoch 00650: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.8917 - mae: 11.2462 - val_loss: 24.2362 - val_mae: 24.0577\n",
            "Epoch 651/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6250 - mae: 11.1079\n",
            "Epoch 00651: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.0905 - mae: 11.4405 - val_loss: 27.8967 - val_mae: 27.7156\n",
            "Epoch 652/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7723 - mae: 11.2549\n",
            "Epoch 00652: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.2334 - mae: 11.5843 - val_loss: 20.2566 - val_mae: 20.0936\n",
            "Epoch 653/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.3401 - mae: 11.8261\n",
            "Epoch 00653: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.7827 - mae: 12.1423 - val_loss: 33.9289 - val_mae: 33.6936\n",
            "Epoch 654/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8900 - mae: 11.3749\n",
            "Epoch 00654: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.3265 - mae: 11.6868 - val_loss: 25.3174 - val_mae: 25.1284\n",
            "Epoch 655/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5700 - mae: 11.0530\n",
            "Epoch 00655: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.0230 - mae: 11.3766 - val_loss: 24.1758 - val_mae: 23.9896\n",
            "Epoch 656/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5952 - mae: 11.0780\n",
            "Epoch 00656: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.0572 - mae: 11.4080 - val_loss: 27.9557 - val_mae: 27.7486\n",
            "Epoch 657/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5459 - mae: 11.0287\n",
            "Epoch 00657: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.0037 - mae: 11.3557 - val_loss: 22.4860 - val_mae: 22.2949\n",
            "Epoch 658/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7065 - mae: 11.1901\n",
            "Epoch 00658: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.1837 - mae: 11.5310 - val_loss: 27.7946 - val_mae: 27.5942\n",
            "Epoch 659/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5760 - mae: 11.0594\n",
            "Epoch 00659: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.0208 - mae: 11.3772 - val_loss: 23.4137 - val_mae: 23.2238\n",
            "Epoch 660/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5701 - mae: 11.0534\n",
            "Epoch 00660: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.0382 - mae: 11.3877 - val_loss: 27.7080 - val_mae: 27.5087\n",
            "Epoch 661/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5799 - mae: 11.0629\n",
            "Epoch 00661: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.0472 - mae: 11.3967 - val_loss: 23.2708 - val_mae: 23.0784\n",
            "Epoch 662/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6254 - mae: 11.1090\n",
            "Epoch 00662: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.1127 - mae: 11.4571 - val_loss: 27.0435 - val_mae: 26.8526\n",
            "Epoch 663/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6324 - mae: 11.1146\n",
            "Epoch 00663: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.0890 - mae: 11.4409 - val_loss: 22.6562 - val_mae: 22.4813\n",
            "Epoch 664/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6822 - mae: 11.1661\n",
            "Epoch 00664: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.1754 - mae: 11.5184 - val_loss: 29.3844 - val_mae: 29.1956\n",
            "Epoch 665/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6470 - mae: 11.1297\n",
            "Epoch 00665: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.1041 - mae: 11.4564 - val_loss: 20.6795 - val_mae: 20.5046\n",
            "Epoch 666/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9799 - mae: 11.4656\n",
            "Epoch 00666: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.3995 - mae: 11.7653 - val_loss: 29.2008 - val_mae: 29.0079\n",
            "Epoch 667/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7192 - mae: 11.2030\n",
            "Epoch 00667: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.1653 - mae: 11.5218 - val_loss: 22.6419 - val_mae: 22.4578\n",
            "Epoch 668/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7616 - mae: 11.2455\n",
            "Epoch 00668: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1943 - mae: 11.5545 - val_loss: 26.9271 - val_mae: 26.7460\n",
            "Epoch 669/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5660 - mae: 11.0487\n",
            "Epoch 00669: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.0173 - mae: 11.3711 - val_loss: 25.8823 - val_mae: 25.7036\n",
            "Epoch 670/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5127 - mae: 10.9958\n",
            "Epoch 00670: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.9326 - mae: 11.2958 - val_loss: 23.0078 - val_mae: 22.8210\n",
            "Epoch 671/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5604 - mae: 11.0443\n",
            "Epoch 00671: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.0145 - mae: 11.3686 - val_loss: 25.8868 - val_mae: 25.7048\n",
            "Epoch 672/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4431 - mae: 10.9262\n",
            "Epoch 00672: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.9013 - mae: 11.2535 - val_loss: 23.9412 - val_mae: 23.7667\n",
            "Epoch 673/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4062 - mae: 10.8889\n",
            "Epoch 00673: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.8805 - mae: 11.2277 - val_loss: 25.0075 - val_mae: 24.8203\n",
            "Epoch 674/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4506 - mae: 10.9329\n",
            "Epoch 00674: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.9258 - mae: 11.2723 - val_loss: 25.1023 - val_mae: 24.9229\n",
            "Epoch 675/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4464 - mae: 10.9285\n",
            "Epoch 00675: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.9275 - mae: 11.2722 - val_loss: 25.6979 - val_mae: 25.5446\n",
            "Epoch 676/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3334 - mae: 10.8157\n",
            "Epoch 00676: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.7866 - mae: 11.1395 - val_loss: 23.5310 - val_mae: 23.3768\n",
            "Epoch 677/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5083 - mae: 10.9908\n",
            "Epoch 00677: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.9592 - mae: 11.3129 - val_loss: 26.4229 - val_mae: 26.2599\n",
            "Epoch 678/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7356 - mae: 11.2180\n",
            "Epoch 00678: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 179ms/step - loss: 11.1840 - mae: 11.5384 - val_loss: 20.5698 - val_mae: 20.4047\n",
            "Epoch 679/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.3504 - mae: 11.8358\n",
            "Epoch 00679: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 11.8021 - mae: 12.1585 - val_loss: 33.5438 - val_mae: 33.3104\n",
            "Epoch 680/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8204 - mae: 11.3055\n",
            "Epoch 00680: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.2791 - mae: 11.6331 - val_loss: 23.8857 - val_mae: 23.7022\n",
            "Epoch 681/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7155 - mae: 11.1994\n",
            "Epoch 00681: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 11.1841 - mae: 11.5342 - val_loss: 22.6434 - val_mae: 22.4612\n",
            "Epoch 682/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6079 - mae: 11.0907\n",
            "Epoch 00682: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.0449 - mae: 11.4029 - val_loss: 28.0633 - val_mae: 27.8685\n",
            "Epoch 683/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4221 - mae: 10.9052\n",
            "Epoch 00683: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.9017 - mae: 11.2478 - val_loss: 24.0797 - val_mae: 23.9075\n",
            "Epoch 684/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5985 - mae: 11.0813\n",
            "Epoch 00684: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.0292 - mae: 11.3890 - val_loss: 24.2421 - val_mae: 24.0642\n",
            "Epoch 685/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5085 - mae: 10.9903\n",
            "Epoch 00685: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.0024 - mae: 11.3432 - val_loss: 27.4576 - val_mae: 27.2842\n",
            "Epoch 686/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6381 - mae: 11.1212\n",
            "Epoch 00686: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.0992 - mae: 11.4507 - val_loss: 20.6365 - val_mae: 20.4810\n",
            "Epoch 687/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8890 - mae: 11.3739\n",
            "Epoch 00687: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.3314 - mae: 11.6900 - val_loss: 28.5221 - val_mae: 28.3447\n",
            "Epoch 688/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6371 - mae: 11.1213\n",
            "Epoch 00688: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.0714 - mae: 11.4317 - val_loss: 22.7970 - val_mae: 22.6167\n",
            "Epoch 689/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6975 - mae: 11.1817\n",
            "Epoch 00689: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1587 - mae: 11.5112 - val_loss: 25.2512 - val_mae: 25.0845\n",
            "Epoch 690/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4055 - mae: 10.8881\n",
            "Epoch 00690: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.8785 - mae: 11.2259 - val_loss: 25.2005 - val_mae: 25.0174\n",
            "Epoch 691/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4332 - mae: 10.9154\n",
            "Epoch 00691: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.8995 - mae: 11.2485 - val_loss: 24.2986 - val_mae: 24.1192\n",
            "Epoch 692/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4055 - mae: 10.8877\n",
            "Epoch 00692: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.8412 - mae: 11.1990 - val_loss: 25.9286 - val_mae: 25.7465\n",
            "Epoch 693/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3536 - mae: 10.8352\n",
            "Epoch 00693: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.8204 - mae: 11.1687 - val_loss: 23.2832 - val_mae: 23.1149\n",
            "Epoch 694/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4671 - mae: 10.9501\n",
            "Epoch 00694: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.9323 - mae: 11.2825 - val_loss: 26.5425 - val_mae: 26.3659\n",
            "Epoch 695/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4773 - mae: 10.9593\n",
            "Epoch 00695: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.9138 - mae: 11.2712 - val_loss: 21.0449 - val_mae: 20.8935\n",
            "Epoch 696/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7569 - mae: 11.2408\n",
            "Epoch 00696: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 11.2219 - mae: 11.5730 - val_loss: 29.5808 - val_mae: 29.4054\n",
            "Epoch 697/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6771 - mae: 11.1612\n",
            "Epoch 00697: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.1322 - mae: 11.4863 - val_loss: 20.2493 - val_mae: 20.0892\n",
            "Epoch 698/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9721 - mae: 11.4574\n",
            "Epoch 00698: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 11.4329 - mae: 11.7865 - val_loss: 29.7797 - val_mae: 29.5982\n",
            "Epoch 699/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7128 - mae: 11.1967\n",
            "Epoch 00699: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.1651 - mae: 11.5198 - val_loss: 25.0994 - val_mae: 24.9196\n",
            "Epoch 700/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5223 - mae: 11.0048\n",
            "Epoch 00700: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.9675 - mae: 11.3228 - val_loss: 22.2638 - val_mae: 22.1046\n",
            "Epoch 701/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4925 - mae: 10.9748\n",
            "Epoch 00701: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.9626 - mae: 11.3107 - val_loss: 26.9261 - val_mae: 26.7438\n",
            "Epoch 702/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4801 - mae: 10.9624\n",
            "Epoch 00702: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.9085 - mae: 11.2685 - val_loss: 21.6276 - val_mae: 21.4580\n",
            "Epoch 703/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5954 - mae: 11.0792\n",
            "Epoch 00703: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.0223 - mae: 11.3842 - val_loss: 26.9409 - val_mae: 26.7596\n",
            "Epoch 704/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4233 - mae: 10.9058\n",
            "Epoch 00704: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.8569 - mae: 11.2156 - val_loss: 25.5403 - val_mae: 25.3809\n",
            "Epoch 705/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5203 - mae: 11.0020\n",
            "Epoch 00705: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.9616 - mae: 11.3174 - val_loss: 23.3174 - val_mae: 23.1683\n",
            "Epoch 706/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4707 - mae: 10.9527\n",
            "Epoch 00706: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.9521 - mae: 11.2966 - val_loss: 27.1567 - val_mae: 26.9927\n",
            "Epoch 707/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6849 - mae: 11.1680\n",
            "Epoch 00707: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1242 - mae: 11.4819 - val_loss: 20.6036 - val_mae: 20.4392\n",
            "Epoch 708/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0234 - mae: 11.5089\n",
            "Epoch 00708: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.4770 - mae: 11.8329 - val_loss: 31.8660 - val_mae: 31.6622\n",
            "Epoch 709/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8266 - mae: 11.3118\n",
            "Epoch 00709: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.2909 - mae: 11.6435 - val_loss: 22.6605 - val_mae: 22.4749\n",
            "Epoch 710/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5799 - mae: 11.0640\n",
            "Epoch 00710: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.0403 - mae: 11.3929 - val_loss: 25.0998 - val_mae: 24.9277\n",
            "Epoch 711/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5728 - mae: 11.0545\n",
            "Epoch 00711: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 11.0255 - mae: 11.3779 - val_loss: 25.4898 - val_mae: 25.3161\n",
            "Epoch 712/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4441 - mae: 10.9265\n",
            "Epoch 00712: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 10.9041 - mae: 11.2552 - val_loss: 23.8504 - val_mae: 23.6789\n",
            "Epoch 713/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5330 - mae: 11.0154\n",
            "Epoch 00713: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.9673 - mae: 11.3257 - val_loss: 25.3972 - val_mae: 25.2235\n",
            "Epoch 714/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3844 - mae: 10.8662\n",
            "Epoch 00714: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.8310 - mae: 11.1853 - val_loss: 25.0424 - val_mae: 24.8780\n",
            "Epoch 715/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3992 - mae: 10.8811\n",
            "Epoch 00715: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.8350 - mae: 11.1925 - val_loss: 23.0455 - val_mae: 22.8748\n",
            "Epoch 716/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4079 - mae: 10.8906\n",
            "Epoch 00716: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.8362 - mae: 11.1966 - val_loss: 25.6845 - val_mae: 25.4964\n",
            "Epoch 717/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3640 - mae: 10.8457\n",
            "Epoch 00717: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.8101 - mae: 11.1645 - val_loss: 23.3180 - val_mae: 23.1473\n",
            "Epoch 718/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4581 - mae: 10.9406\n",
            "Epoch 00718: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.9257 - mae: 11.2747 - val_loss: 25.8057 - val_mae: 25.6322\n",
            "Epoch 719/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5241 - mae: 11.0060\n",
            "Epoch 00719: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.9879 - mae: 11.3373 - val_loss: 20.8190 - val_mae: 20.6659\n",
            "Epoch 720/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8872 - mae: 11.3716\n",
            "Epoch 00720: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.3417 - mae: 11.6964 - val_loss: 32.1606 - val_mae: 31.9693\n",
            "Epoch 721/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8105 - mae: 11.2951\n",
            "Epoch 00721: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.2453 - mae: 11.6057 - val_loss: 20.4637 - val_mae: 20.3080\n",
            "Epoch 722/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9358 - mae: 11.4214\n",
            "Epoch 00722: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.3583 - mae: 11.7232 - val_loss: 27.3035 - val_mae: 27.1528\n",
            "Epoch 723/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6893 - mae: 11.1728\n",
            "Epoch 00723: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1472 - mae: 11.4999 - val_loss: 27.4251 - val_mae: 27.2545\n",
            "Epoch 724/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5941 - mae: 11.0770\n",
            "Epoch 00724: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.0327 - mae: 11.3904 - val_loss: 20.8761 - val_mae: 20.7224\n",
            "Epoch 725/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7190 - mae: 11.2034\n",
            "Epoch 00725: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.1737 - mae: 11.5282 - val_loss: 23.5601 - val_mae: 23.4030\n",
            "Epoch 726/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4474 - mae: 10.9288\n",
            "Epoch 00726: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.8992 - mae: 11.2517 - val_loss: 30.2018 - val_mae: 29.9971\n",
            "Epoch 727/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6216 - mae: 11.1055\n",
            "Epoch 00727: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 178ms/step - loss: 11.0577 - mae: 11.4170 - val_loss: 21.5617 - val_mae: 21.3870\n",
            "Epoch 728/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7286 - mae: 11.2136\n",
            "Epoch 00728: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.1622 - mae: 11.5233 - val_loss: 25.8068 - val_mae: 25.6238\n",
            "Epoch 729/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4814 - mae: 10.9634\n",
            "Epoch 00729: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.9259 - mae: 11.2810 - val_loss: 26.9219 - val_mae: 26.7318\n",
            "Epoch 730/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4546 - mae: 10.9374\n",
            "Epoch 00730: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.8869 - mae: 11.2462 - val_loss: 21.7689 - val_mae: 21.5924\n",
            "Epoch 731/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4800 - mae: 10.9629\n",
            "Epoch 00731: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.9168 - mae: 11.2749 - val_loss: 25.5435 - val_mae: 25.3572\n",
            "Epoch 732/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3089 - mae: 10.7905\n",
            "Epoch 00732: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.7855 - mae: 11.1310 - val_loss: 24.7010 - val_mae: 24.5196\n",
            "Epoch 733/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4167 - mae: 10.8989\n",
            "Epoch 00733: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.8713 - mae: 11.2237 - val_loss: 23.5271 - val_mae: 23.3596\n",
            "Epoch 734/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4125 - mae: 10.8941\n",
            "Epoch 00734: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.8756 - mae: 11.2250 - val_loss: 26.5352 - val_mae: 26.3564\n",
            "Epoch 735/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4857 - mae: 10.9674\n",
            "Epoch 00735: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.9366 - mae: 11.2896 - val_loss: 21.5582 - val_mae: 21.3823\n",
            "Epoch 736/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6937 - mae: 11.1781\n",
            "Epoch 00736: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1316 - mae: 11.4910 - val_loss: 28.3588 - val_mae: 28.1864\n",
            "Epoch 737/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5560 - mae: 11.0393\n",
            "Epoch 00737: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 11.0104 - mae: 11.3640 - val_loss: 22.7402 - val_mae: 22.5739\n",
            "Epoch 738/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5738 - mae: 11.0577\n",
            "Epoch 00738: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 11.0083 - mae: 11.3681 - val_loss: 26.8198 - val_mae: 26.6529\n",
            "Epoch 739/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4666 - mae: 10.9488\n",
            "Epoch 00739: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.9244 - mae: 11.2759 - val_loss: 25.3041 - val_mae: 25.1332\n",
            "Epoch 740/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4771 - mae: 10.9591\n",
            "Epoch 00740: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.9276 - mae: 11.2809 - val_loss: 21.1128 - val_mae: 20.9450\n",
            "Epoch 741/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6052 - mae: 11.0888\n",
            "Epoch 00741: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.0672 - mae: 11.4189 - val_loss: 26.9845 - val_mae: 26.8212\n",
            "Epoch 742/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4363 - mae: 10.9192\n",
            "Epoch 00742: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.8825 - mae: 11.2380 - val_loss: 22.8360 - val_mae: 22.6868\n",
            "Epoch 743/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3438 - mae: 10.8254\n",
            "Epoch 00743: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.7938 - mae: 11.1469 - val_loss: 25.4385 - val_mae: 25.2780\n",
            "Epoch 744/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4026 - mae: 10.8841\n",
            "Epoch 00744: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.8418 - mae: 11.1979 - val_loss: 22.1670 - val_mae: 22.0121\n",
            "Epoch 745/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5029 - mae: 10.9855\n",
            "Epoch 00745: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.9456 - mae: 11.3019 - val_loss: 26.4183 - val_mae: 26.2715\n",
            "Epoch 746/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7428 - mae: 11.2259\n",
            "Epoch 00746: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 11.1700 - mae: 11.5311 - val_loss: 19.3417 - val_mae: 19.1898\n",
            "Epoch 747/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0514 - mae: 11.5369\n",
            "Epoch 00747: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.5108 - mae: 11.8650 - val_loss: 28.6410 - val_mae: 28.4751\n",
            "Epoch 748/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6479 - mae: 11.1321\n",
            "Epoch 00748: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1172 - mae: 11.4674 - val_loss: 25.0718 - val_mae: 24.9131\n",
            "Epoch 749/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4397 - mae: 10.9218\n",
            "Epoch 00749: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.8793 - mae: 11.2359 - val_loss: 21.0525 - val_mae: 20.8905\n",
            "Epoch 750/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4832 - mae: 10.9657\n",
            "Epoch 00750: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.9336 - mae: 11.2875 - val_loss: 27.2598 - val_mae: 27.0844\n",
            "Epoch 751/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4002 - mae: 10.8818\n",
            "Epoch 00751: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.8412 - mae: 11.1969 - val_loss: 22.7073 - val_mae: 22.5458\n",
            "Epoch 752/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3447 - mae: 10.8271\n",
            "Epoch 00752: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.7940 - mae: 11.1481 - val_loss: 25.3829 - val_mae: 25.2095\n",
            "Epoch 753/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2699 - mae: 10.7514\n",
            "Epoch 00753: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.6900 - mae: 11.0515 - val_loss: 23.9222 - val_mae: 23.7576\n",
            "Epoch 754/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3687 - mae: 10.8507\n",
            "Epoch 00754: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.8210 - mae: 11.1738 - val_loss: 24.6549 - val_mae: 24.5005\n",
            "Epoch 755/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3891 - mae: 10.8707\n",
            "Epoch 00755: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.8611 - mae: 11.2079 - val_loss: 21.8297 - val_mae: 21.6757\n",
            "Epoch 756/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5416 - mae: 11.0245\n",
            "Epoch 00756: val_loss did not improve from 19.00507\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.0030 - mae: 11.3541 - val_loss: 28.6089 - val_mae: 28.4451\n",
            "Epoch 757/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7142 - mae: 11.1968\n",
            "Epoch 00757: val_loss improved from 19.00507 to 18.44188, saving model to cp/weights-757-18.44.hdf5\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.1463 - mae: 11.5055 - val_loss: 18.4419 - val_mae: 18.3012\n",
            "Epoch 758/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.2174 - mae: 11.7039\n",
            "Epoch 00758: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.6396 - mae: 12.0055 - val_loss: 29.1025 - val_mae: 28.9278\n",
            "Epoch 759/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7054 - mae: 11.1895\n",
            "Epoch 00759: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.1323 - mae: 11.4945 - val_loss: 24.8954 - val_mae: 24.7267\n",
            "Epoch 760/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4101 - mae: 10.8922\n",
            "Epoch 00760: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.8515 - mae: 11.2075 - val_loss: 21.3718 - val_mae: 21.2143\n",
            "Epoch 761/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5696 - mae: 11.0528\n",
            "Epoch 00761: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.0144 - mae: 11.3706 - val_loss: 25.3803 - val_mae: 25.2082\n",
            "Epoch 762/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3271 - mae: 10.8083\n",
            "Epoch 00762: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.7845 - mae: 11.1350 - val_loss: 27.6779 - val_mae: 27.5188\n",
            "Epoch 763/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4255 - mae: 10.9083\n",
            "Epoch 00763: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.8844 - mae: 11.2362 - val_loss: 21.3216 - val_mae: 21.1742\n",
            "Epoch 764/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4424 - mae: 10.9255\n",
            "Epoch 00764: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.8786 - mae: 11.2372 - val_loss: 26.9200 - val_mae: 26.7626\n",
            "Epoch 765/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4110 - mae: 10.8927\n",
            "Epoch 00765: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.8482 - mae: 11.2052 - val_loss: 22.6292 - val_mae: 22.4767\n",
            "Epoch 766/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4475 - mae: 10.9298\n",
            "Epoch 00766: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.9024 - mae: 11.2549 - val_loss: 25.5821 - val_mae: 25.4300\n",
            "Epoch 767/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3949 - mae: 10.8762\n",
            "Epoch 00767: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.8221 - mae: 11.1815 - val_loss: 19.5062 - val_mae: 19.3709\n",
            "Epoch 768/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7210 - mae: 11.2051\n",
            "Epoch 00768: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.1781 - mae: 11.5317 - val_loss: 27.0311 - val_mae: 26.8915\n",
            "Epoch 769/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5239 - mae: 11.0067\n",
            "Epoch 00769: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.9757 - mae: 11.3295 - val_loss: 20.4881 - val_mae: 20.3585\n",
            "Epoch 770/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5822 - mae: 11.0657\n",
            "Epoch 00770: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.0121 - mae: 11.3728 - val_loss: 25.6254 - val_mae: 25.5009\n",
            "Epoch 771/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4885 - mae: 10.9710\n",
            "Epoch 00771: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.9253 - mae: 11.2831 - val_loss: 22.2086 - val_mae: 22.0647\n",
            "Epoch 772/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4182 - mae: 10.9005\n",
            "Epoch 00772: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.8740 - mae: 11.2261 - val_loss: 25.1680 - val_mae: 25.0336\n",
            "Epoch 773/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3100 - mae: 10.7915\n",
            "Epoch 00773: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.7606 - mae: 11.1134 - val_loss: 21.1312 - val_mae: 21.0074\n",
            "Epoch 774/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4437 - mae: 10.9265\n",
            "Epoch 00774: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.8956 - mae: 11.2493 - val_loss: 24.9041 - val_mae: 24.7741\n",
            "Epoch 775/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3536 - mae: 10.8353\n",
            "Epoch 00775: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.8006 - mae: 11.1547 - val_loss: 21.5300 - val_mae: 21.3896\n",
            "Epoch 776/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6801 - mae: 11.1628\n",
            "Epoch 00776: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.1427 - mae: 11.4934 - val_loss: 28.7360 - val_mae: 28.5836\n",
            "Epoch 777/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7010 - mae: 11.1841\n",
            "Epoch 00777: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.1538 - mae: 11.5076 - val_loss: 18.7897 - val_mae: 18.6579\n",
            "Epoch 778/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9373 - mae: 11.4229\n",
            "Epoch 00778: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 11.3786 - mae: 11.7381 - val_loss: 27.6010 - val_mae: 27.4471\n",
            "Epoch 779/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5249 - mae: 11.0079\n",
            "Epoch 00779: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.9704 - mae: 11.3261 - val_loss: 22.9330 - val_mae: 22.7796\n",
            "Epoch 780/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3858 - mae: 10.8671\n",
            "Epoch 00780: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.8192 - mae: 11.1767 - val_loss: 22.4794 - val_mae: 22.3276\n",
            "Epoch 781/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5014 - mae: 10.9838\n",
            "Epoch 00781: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.9160 - mae: 11.2800 - val_loss: 24.3748 - val_mae: 24.2167\n",
            "Epoch 782/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2430 - mae: 10.7242\n",
            "Epoch 00782: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.6964 - mae: 11.0481 - val_loss: 23.9534 - val_mae: 23.8048\n",
            "Epoch 783/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3618 - mae: 10.8434\n",
            "Epoch 00783: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.8020 - mae: 11.1580 - val_loss: 25.1074 - val_mae: 24.9564\n",
            "Epoch 784/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2717 - mae: 10.7527\n",
            "Epoch 00784: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.7155 - mae: 11.0699 - val_loss: 23.0597 - val_mae: 22.9263\n",
            "Epoch 785/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2333 - mae: 10.7146\n",
            "Epoch 00785: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.6645 - mae: 11.0227 - val_loss: 23.5709 - val_mae: 23.4457\n",
            "Epoch 786/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2651 - mae: 10.7454\n",
            "Epoch 00786: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.7054 - mae: 11.0601 - val_loss: 22.7353 - val_mae: 22.6064\n",
            "Epoch 787/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3345 - mae: 10.8159\n",
            "Epoch 00787: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.7735 - mae: 11.1296 - val_loss: 24.7387 - val_mae: 24.6179\n",
            "Epoch 788/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4771 - mae: 10.9588\n",
            "Epoch 00788: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.9321 - mae: 11.2839 - val_loss: 20.2158 - val_mae: 20.0835\n",
            "Epoch 789/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7849 - mae: 11.2688\n",
            "Epoch 00789: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.2143 - mae: 11.5755 - val_loss: 30.5479 - val_mae: 30.3814\n",
            "Epoch 790/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7090 - mae: 11.1931\n",
            "Epoch 00790: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.1415 - mae: 11.5021 - val_loss: 20.1396 - val_mae: 20.0068\n",
            "Epoch 791/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7059 - mae: 11.1905\n",
            "Epoch 00791: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.1311 - mae: 11.4942 - val_loss: 23.4889 - val_mae: 23.3533\n",
            "Epoch 792/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4728 - mae: 10.9540\n",
            "Epoch 00792: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.9142 - mae: 11.2694 - val_loss: 27.3640 - val_mae: 27.2008\n",
            "Epoch 793/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5181 - mae: 11.0012\n",
            "Epoch 00793: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.9658 - mae: 11.3211 - val_loss: 22.5640 - val_mae: 22.4074\n",
            "Epoch 794/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5680 - mae: 11.0518\n",
            "Epoch 00794: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.9950 - mae: 11.3568 - val_loss: 24.7803 - val_mae: 24.6457\n",
            "Epoch 795/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3568 - mae: 10.8384\n",
            "Epoch 00795: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.8030 - mae: 11.1572 - val_loss: 23.2439 - val_mae: 23.0984\n",
            "Epoch 796/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3002 - mae: 10.7822\n",
            "Epoch 00796: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.7363 - mae: 11.0938 - val_loss: 22.8775 - val_mae: 22.7367\n",
            "Epoch 797/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2749 - mae: 10.7559\n",
            "Epoch 00797: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 179ms/step - loss: 10.7043 - mae: 11.0627 - val_loss: 24.0642 - val_mae: 23.9213\n",
            "Epoch 798/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2884 - mae: 10.7691\n",
            "Epoch 00798: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.7294 - mae: 11.0842 - val_loss: 21.6002 - val_mae: 21.4593\n",
            "Epoch 799/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4220 - mae: 10.9046\n",
            "Epoch 00799: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.8754 - mae: 11.2285 - val_loss: 27.9236 - val_mae: 27.7663\n",
            "Epoch 800/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5397 - mae: 11.0215\n",
            "Epoch 00800: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.9940 - mae: 11.3461 - val_loss: 19.0958 - val_mae: 18.9771\n",
            "Epoch 801/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7681 - mae: 11.2528\n",
            "Epoch 00801: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 11.2066 - mae: 11.5661 - val_loss: 27.8537 - val_mae: 27.7038\n",
            "Epoch 802/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4837 - mae: 10.9662\n",
            "Epoch 00802: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.9115 - mae: 11.2718 - val_loss: 23.4105 - val_mae: 23.2665\n",
            "Epoch 803/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3869 - mae: 10.8687\n",
            "Epoch 00803: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.8139 - mae: 11.1738 - val_loss: 21.2076 - val_mae: 21.0688\n",
            "Epoch 804/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3556 - mae: 10.8373\n",
            "Epoch 00804: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.7893 - mae: 11.1472 - val_loss: 25.6273 - val_mae: 25.4835\n",
            "Epoch 805/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2741 - mae: 10.7555\n",
            "Epoch 00805: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.7172 - mae: 11.0721 - val_loss: 22.0119 - val_mae: 21.8806\n",
            "Epoch 806/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3673 - mae: 10.8489\n",
            "Epoch 00806: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.7903 - mae: 11.1511 - val_loss: 25.0398 - val_mae: 24.8985\n",
            "Epoch 807/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2225 - mae: 10.7030\n",
            "Epoch 00807: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.6682 - mae: 11.0214 - val_loss: 23.8266 - val_mae: 23.6972\n",
            "Epoch 808/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2740 - mae: 10.7552\n",
            "Epoch 00808: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.7264 - mae: 11.0785 - val_loss: 23.7687 - val_mae: 23.6471\n",
            "Epoch 809/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4300 - mae: 10.9112\n",
            "Epoch 00809: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.8466 - mae: 11.2089 - val_loss: 20.6577 - val_mae: 20.5270\n",
            "Epoch 810/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6701 - mae: 11.1533\n",
            "Epoch 00810: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 11.1243 - mae: 11.4778 - val_loss: 31.1788 - val_mae: 30.9991\n",
            "Epoch 811/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6351 - mae: 11.1193\n",
            "Epoch 00811: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.0779 - mae: 11.4357 - val_loss: 19.4453 - val_mae: 19.3220\n",
            "Epoch 812/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8639 - mae: 11.3498\n",
            "Epoch 00812: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.2696 - mae: 11.6395 - val_loss: 25.0240 - val_mae: 24.8981\n",
            "Epoch 813/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5282 - mae: 11.0098\n",
            "Epoch 00813: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.9898 - mae: 11.3396 - val_loss: 27.6345 - val_mae: 27.4729\n",
            "Epoch 814/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6552 - mae: 11.1396\n",
            "Epoch 00814: val_loss did not improve from 18.44188\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.1235 - mae: 11.4741 - val_loss: 20.5486 - val_mae: 20.4041\n",
            "Epoch 815/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.0624 - mae: 11.5484\n",
            "Epoch 00815: val_loss improved from 18.44188 to 18.32403, saving model to cp/weights-815-18.32.hdf5\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.5114 - mae: 11.8692 - val_loss: 18.3240 - val_mae: 18.2079\n",
            "Epoch 816/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5174 - mae: 10.9992\n",
            "Epoch 00816: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.9530 - mae: 11.3105 - val_loss: 29.0700 - val_mae: 28.8679\n",
            "Epoch 817/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5665 - mae: 11.0504\n",
            "Epoch 00817: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.0117 - mae: 11.3684 - val_loss: 23.4445 - val_mae: 23.2544\n",
            "Epoch 818/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5805 - mae: 11.0640\n",
            "Epoch 00818: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.0067 - mae: 11.3685 - val_loss: 23.0478 - val_mae: 22.8820\n",
            "Epoch 819/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3811 - mae: 10.8625\n",
            "Epoch 00819: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.8329 - mae: 11.1853 - val_loss: 26.4352 - val_mae: 26.2564\n",
            "Epoch 820/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3379 - mae: 10.8200\n",
            "Epoch 00820: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.7668 - mae: 11.1265 - val_loss: 22.1872 - val_mae: 22.0308\n",
            "Epoch 821/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4966 - mae: 10.9797\n",
            "Epoch 00821: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.9598 - mae: 11.3106 - val_loss: 23.0963 - val_mae: 22.9392\n",
            "Epoch 822/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3342 - mae: 10.8150\n",
            "Epoch 00822: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.7994 - mae: 11.1474 - val_loss: 27.2219 - val_mae: 27.0464\n",
            "Epoch 823/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4202 - mae: 10.9028\n",
            "Epoch 00823: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.8574 - mae: 11.2151 - val_loss: 21.2125 - val_mae: 21.0490\n",
            "Epoch 824/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4999 - mae: 10.9832\n",
            "Epoch 00824: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.9436 - mae: 11.3002 - val_loss: 24.4367 - val_mae: 24.2778\n",
            "Epoch 825/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2674 - mae: 10.7483\n",
            "Epoch 00825: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 10.7159 - mae: 11.0688 - val_loss: 25.7061 - val_mae: 25.5237\n",
            "Epoch 826/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2302 - mae: 10.7111\n",
            "Epoch 00826: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.6636 - mae: 11.0208 - val_loss: 23.6379 - val_mae: 23.4748\n",
            "Epoch 827/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2021 - mae: 10.6827\n",
            "Epoch 00827: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.6488 - mae: 11.0020 - val_loss: 25.2192 - val_mae: 25.0553\n",
            "Epoch 828/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2753 - mae: 10.7564\n",
            "Epoch 00828: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.6987 - mae: 11.0589 - val_loss: 23.6103 - val_mae: 23.4610\n",
            "Epoch 829/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2133 - mae: 10.6938\n",
            "Epoch 00829: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.6703 - mae: 11.0203 - val_loss: 23.6694 - val_mae: 23.5210\n",
            "Epoch 830/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2581 - mae: 10.7390\n",
            "Epoch 00830: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.6746 - mae: 11.0366 - val_loss: 23.1260 - val_mae: 22.9728\n",
            "Epoch 831/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2424 - mae: 10.7236\n",
            "Epoch 00831: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.6962 - mae: 11.0478 - val_loss: 24.9367 - val_mae: 24.7703\n",
            "Epoch 832/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2645 - mae: 10.7449\n",
            "Epoch 00832: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.7204 - mae: 11.0707 - val_loss: 23.2670 - val_mae: 23.1261\n",
            "Epoch 833/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1795 - mae: 10.6605\n",
            "Epoch 00833: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.6389 - mae: 10.9888 - val_loss: 23.5293 - val_mae: 23.3835\n",
            "Epoch 834/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2492 - mae: 10.7301\n",
            "Epoch 00834: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.6979 - mae: 11.0506 - val_loss: 24.4477 - val_mae: 24.2981\n",
            "Epoch 835/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1825 - mae: 10.6629\n",
            "Epoch 00835: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.6243 - mae: 10.9786 - val_loss: 23.3233 - val_mae: 23.1803\n",
            "Epoch 836/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2766 - mae: 10.7581\n",
            "Epoch 00836: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.7000 - mae: 11.0606 - val_loss: 22.8202 - val_mae: 22.6842\n",
            "Epoch 837/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2428 - mae: 10.7237\n",
            "Epoch 00837: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.6791 - mae: 11.0355 - val_loss: 24.2828 - val_mae: 24.1328\n",
            "Epoch 838/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2192 - mae: 10.7003\n",
            "Epoch 00838: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.6594 - mae: 11.0149 - val_loss: 23.8003 - val_mae: 23.6452\n",
            "Epoch 839/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2460 - mae: 10.7273\n",
            "Epoch 00839: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.6782 - mae: 11.0362 - val_loss: 23.3101 - val_mae: 23.1683\n",
            "Epoch 840/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2279 - mae: 10.7098\n",
            "Epoch 00840: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.6639 - mae: 11.0213 - val_loss: 22.1210 - val_mae: 21.9872\n",
            "Epoch 841/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3375 - mae: 10.8197\n",
            "Epoch 00841: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.7793 - mae: 11.1354 - val_loss: 24.4479 - val_mae: 24.3242\n",
            "Epoch 842/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4178 - mae: 10.8988\n",
            "Epoch 00842: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.8670 - mae: 11.2198 - val_loss: 19.9457 - val_mae: 19.8245\n",
            "Epoch 843/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9474 - mae: 11.4321\n",
            "Epoch 00843: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.3986 - mae: 11.7545 - val_loss: 32.0893 - val_mae: 31.9342\n",
            "Epoch 844/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7542 - mae: 11.2385\n",
            "Epoch 00844: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.1572 - mae: 11.5264 - val_loss: 21.2535 - val_mae: 21.1256\n",
            "Epoch 845/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5753 - mae: 11.0587\n",
            "Epoch 00845: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.9935 - mae: 11.3575 - val_loss: 26.2045 - val_mae: 26.0823\n",
            "Epoch 846/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3479 - mae: 10.8293\n",
            "Epoch 00846: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.7863 - mae: 11.1425 - val_loss: 23.8109 - val_mae: 23.6874\n",
            "Epoch 847/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2744 - mae: 10.7555\n",
            "Epoch 00847: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.7146 - mae: 11.0700 - val_loss: 23.6924 - val_mae: 23.5715\n",
            "Epoch 848/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3054 - mae: 10.7864\n",
            "Epoch 00848: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.7371 - mae: 11.0949 - val_loss: 21.1876 - val_mae: 21.0547\n",
            "Epoch 849/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5687 - mae: 11.0516\n",
            "Epoch 00849: val_loss did not improve from 18.32403\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.9998 - mae: 11.3595 - val_loss: 27.2012 - val_mae: 27.0780\n",
            "Epoch 850/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6155 - mae: 11.0988\n",
            "Epoch 00850: val_loss improved from 18.32403 to 18.28467, saving model to cp/weights-850-18.28.hdf5\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 11.0593 - mae: 11.4158 - val_loss: 18.2847 - val_mae: 18.1754\n",
            "Epoch 851/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.9100 - mae: 11.3951\n",
            "Epoch 00851: val_loss did not improve from 18.28467\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 11.3242 - mae: 11.6910 - val_loss: 26.5529 - val_mae: 26.4277\n",
            "Epoch 852/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5626 - mae: 11.0453\n",
            "Epoch 00852: val_loss did not improve from 18.28467\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 11.0101 - mae: 11.3650 - val_loss: 24.0636 - val_mae: 23.9368\n",
            "Epoch 853/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2604 - mae: 10.7415\n",
            "Epoch 00853: val_loss did not improve from 18.28467\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.7015 - mae: 11.0566 - val_loss: 19.7105 - val_mae: 19.5963\n",
            "Epoch 854/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4494 - mae: 10.9327\n",
            "Epoch 00854: val_loss did not improve from 18.28467\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.8825 - mae: 11.2421 - val_loss: 24.0473 - val_mae: 23.9225\n",
            "Epoch 855/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3195 - mae: 10.8003\n",
            "Epoch 00855: val_loss did not improve from 18.28467\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.7840 - mae: 11.1322 - val_loss: 26.1173 - val_mae: 25.9856\n",
            "Epoch 856/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3840 - mae: 10.8665\n",
            "Epoch 00856: val_loss did not improve from 18.28467\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.8258 - mae: 11.1821 - val_loss: 19.9365 - val_mae: 19.8153\n",
            "Epoch 857/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5038 - mae: 10.9871\n",
            "Epoch 00857: val_loss did not improve from 18.28467\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.9307 - mae: 11.2921 - val_loss: 25.1126 - val_mae: 24.9988\n",
            "Epoch 858/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3550 - mae: 10.8375\n",
            "Epoch 00858: val_loss did not improve from 18.28467\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.8066 - mae: 11.1602 - val_loss: 22.6334 - val_mae: 22.5070\n",
            "Epoch 859/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3172 - mae: 10.7980\n",
            "Epoch 00859: val_loss did not improve from 18.28467\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.7673 - mae: 11.1195 - val_loss: 21.8438 - val_mae: 21.7320\n",
            "Epoch 860/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1301 - mae: 10.6106\n",
            "Epoch 00860: val_loss did not improve from 18.28467\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.5526 - mae: 10.9125 - val_loss: 21.9845 - val_mae: 21.8755\n",
            "Epoch 861/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1959 - mae: 10.6766\n",
            "Epoch 00861: val_loss did not improve from 18.28467\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.6548 - mae: 11.0045 - val_loss: 22.8964 - val_mae: 22.7905\n",
            "Epoch 862/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2417 - mae: 10.7227\n",
            "Epoch 00862: val_loss did not improve from 18.28467\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.6810 - mae: 11.0367 - val_loss: 21.4009 - val_mae: 21.2828\n",
            "Epoch 863/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3868 - mae: 10.8689\n",
            "Epoch 00863: val_loss did not improve from 18.28467\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.8249 - mae: 11.1819 - val_loss: 26.3684 - val_mae: 26.2553\n",
            "Epoch 864/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4929 - mae: 10.9754\n",
            "Epoch 00864: val_loss improved from 18.28467 to 17.62321, saving model to cp/weights-864-17.62.hdf5\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.9517 - mae: 11.3031 - val_loss: 17.6232 - val_mae: 17.5230\n",
            "Epoch 865/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6883 - mae: 11.1728\n",
            "Epoch 00865: val_loss did not improve from 17.62321\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1405 - mae: 11.4958 - val_loss: 26.9468 - val_mae: 26.8213\n",
            "Epoch 866/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4048 - mae: 10.8877\n",
            "Epoch 00866: val_loss did not improve from 17.62321\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.8621 - mae: 11.2145 - val_loss: 21.7627 - val_mae: 21.6301\n",
            "Epoch 867/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3858 - mae: 10.8684\n",
            "Epoch 00867: val_loss did not improve from 17.62321\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 10.8079 - mae: 11.1700 - val_loss: 23.3275 - val_mae: 23.1860\n",
            "Epoch 868/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2531 - mae: 10.7336\n",
            "Epoch 00868: val_loss did not improve from 17.62321\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.6832 - mae: 11.0410 - val_loss: 25.0106 - val_mae: 24.8730\n",
            "Epoch 869/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2099 - mae: 10.6912\n",
            "Epoch 00869: val_loss did not improve from 17.62321\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.6638 - mae: 11.0155 - val_loss: 20.5905 - val_mae: 20.4918\n",
            "Epoch 870/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3197 - mae: 10.8012\n",
            "Epoch 00870: val_loss did not improve from 17.62321\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.7528 - mae: 11.1106 - val_loss: 23.7112 - val_mae: 23.5786\n",
            "Epoch 871/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1413 - mae: 10.6217\n",
            "Epoch 00871: val_loss did not improve from 17.62321\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.6089 - mae: 10.9558 - val_loss: 23.3967 - val_mae: 23.2674\n",
            "Epoch 872/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1517 - mae: 10.6323\n",
            "Epoch 00872: val_loss did not improve from 17.62321\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.5933 - mae: 10.9478 - val_loss: 23.1092 - val_mae: 22.9930\n",
            "Epoch 873/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1854 - mae: 10.6660\n",
            "Epoch 00873: val_loss did not improve from 17.62321\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.6164 - mae: 10.9739 - val_loss: 22.7321 - val_mae: 22.6144\n",
            "Epoch 874/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2091 - mae: 10.6900\n",
            "Epoch 00874: val_loss did not improve from 17.62321\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.6453 - mae: 11.0016 - val_loss: 23.2707 - val_mae: 23.1595\n",
            "Epoch 875/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1220 - mae: 10.6020\n",
            "Epoch 00875: val_loss did not improve from 17.62321\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.5559 - mae: 10.9120 - val_loss: 21.8433 - val_mae: 21.7341\n",
            "Epoch 876/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2003 - mae: 10.6816\n",
            "Epoch 00876: val_loss did not improve from 17.62321\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.6405 - mae: 10.9960 - val_loss: 22.7705 - val_mae: 22.6646\n",
            "Epoch 877/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1882 - mae: 10.6688\n",
            "Epoch 00877: val_loss did not improve from 17.62321\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.6293 - mae: 10.9840 - val_loss: 21.9074 - val_mae: 21.8027\n",
            "Epoch 878/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2319 - mae: 10.7125\n",
            "Epoch 00878: val_loss did not improve from 17.62321\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.6731 - mae: 11.0278 - val_loss: 25.0456 - val_mae: 24.9429\n",
            "Epoch 879/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2368 - mae: 10.7177\n",
            "Epoch 00879: val_loss did not improve from 17.62321\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.6749 - mae: 11.0307 - val_loss: 20.9117 - val_mae: 20.8211\n",
            "Epoch 880/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4469 - mae: 10.9294\n",
            "Epoch 00880: val_loss did not improve from 17.62321\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.9013 - mae: 11.2541 - val_loss: 26.8899 - val_mae: 26.7864\n",
            "Epoch 881/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6481 - mae: 11.1300\n",
            "Epoch 00881: val_loss improved from 17.62321 to 17.25950, saving model to cp/weights-881-17.26.hdf5\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.1175 - mae: 11.4654 - val_loss: 17.2595 - val_mae: 17.1765\n",
            "Epoch 882/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 11.3301 - mae: 11.8158\n",
            "Epoch 00882: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.7201 - mae: 12.0944 - val_loss: 31.2738 - val_mae: 31.0894\n",
            "Epoch 883/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.7638 - mae: 11.2482\n",
            "Epoch 00883: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1974 - mae: 11.5579 - val_loss: 24.6154 - val_mae: 24.4868\n",
            "Epoch 884/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3272 - mae: 10.8088\n",
            "Epoch 00884: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.7605 - mae: 11.1183 - val_loss: 20.5116 - val_mae: 20.4082\n",
            "Epoch 885/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2472 - mae: 10.7291\n",
            "Epoch 00885: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.6808 - mae: 11.0389 - val_loss: 24.8228 - val_mae: 24.6896\n",
            "Epoch 886/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1609 - mae: 10.6412\n",
            "Epoch 00886: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.6103 - mae: 10.9624 - val_loss: 23.7340 - val_mae: 23.6291\n",
            "Epoch 887/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1498 - mae: 10.6308\n",
            "Epoch 00887: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 10.6084 - mae: 10.9584 - val_loss: 22.2183 - val_mae: 22.1106\n",
            "Epoch 888/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2105 - mae: 10.6917\n",
            "Epoch 00888: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.6002 - mae: 10.9702 - val_loss: 24.7462 - val_mae: 24.6320\n",
            "Epoch 889/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3231 - mae: 10.8043\n",
            "Epoch 00889: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.7654 - mae: 11.1203 - val_loss: 19.9904 - val_mae: 19.8840\n",
            "Epoch 890/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3936 - mae: 10.8763\n",
            "Epoch 00890: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.8154 - mae: 11.1777 - val_loss: 26.2761 - val_mae: 26.1616\n",
            "Epoch 891/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4507 - mae: 10.9325\n",
            "Epoch 00891: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.8831 - mae: 11.2414 - val_loss: 19.0300 - val_mae: 18.9214\n",
            "Epoch 892/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5791 - mae: 11.0629\n",
            "Epoch 00892: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.9888 - mae: 11.3556 - val_loss: 26.4281 - val_mae: 26.3248\n",
            "Epoch 893/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3556 - mae: 10.8383\n",
            "Epoch 00893: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.7995 - mae: 11.1554 - val_loss: 20.9005 - val_mae: 20.8098\n",
            "Epoch 894/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1717 - mae: 10.6533\n",
            "Epoch 00894: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 10.5941 - mae: 10.9551 - val_loss: 22.6036 - val_mae: 22.4931\n",
            "Epoch 895/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2244 - mae: 10.7049\n",
            "Epoch 00895: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.6374 - mae: 11.0001 - val_loss: 22.3925 - val_mae: 22.2821\n",
            "Epoch 896/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1922 - mae: 10.6729\n",
            "Epoch 00896: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.6401 - mae: 10.9930 - val_loss: 23.4766 - val_mae: 23.3906\n",
            "Epoch 897/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2779 - mae: 10.7582\n",
            "Epoch 00897: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.7186 - mae: 11.0730 - val_loss: 19.8637 - val_mae: 19.7641\n",
            "Epoch 898/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4229 - mae: 10.9057\n",
            "Epoch 00898: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.8653 - mae: 11.2218 - val_loss: 25.4089 - val_mae: 25.3055\n",
            "Epoch 899/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4135 - mae: 10.8953\n",
            "Epoch 00899: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.8694 - mae: 11.2210 - val_loss: 18.1180 - val_mae: 18.0387\n",
            "Epoch 900/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6790 - mae: 11.1632\n",
            "Epoch 00900: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 11.1181 - mae: 11.4769 - val_loss: 28.0583 - val_mae: 27.9183\n",
            "Epoch 901/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4398 - mae: 10.9231\n",
            "Epoch 00901: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.8602 - mae: 11.2235 - val_loss: 21.5457 - val_mae: 21.4367\n",
            "Epoch 902/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3065 - mae: 10.7883\n",
            "Epoch 00902: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.7467 - mae: 11.1028 - val_loss: 21.3378 - val_mae: 21.2361\n",
            "Epoch 903/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2449 - mae: 10.7258\n",
            "Epoch 00903: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.6996 - mae: 11.0507 - val_loss: 24.9761 - val_mae: 24.8552\n",
            "Epoch 904/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2285 - mae: 10.7094\n",
            "Epoch 00904: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.6577 - mae: 11.0161 - val_loss: 20.8960 - val_mae: 20.8045\n",
            "Epoch 905/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2233 - mae: 10.7046\n",
            "Epoch 00905: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.6554 - mae: 11.0133 - val_loss: 21.6247 - val_mae: 21.5231\n",
            "Epoch 906/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1049 - mae: 10.5852\n",
            "Epoch 00906: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 10.5444 - mae: 10.8993 - val_loss: 21.6011 - val_mae: 21.4870\n",
            "Epoch 907/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1463 - mae: 10.6266\n",
            "Epoch 00907: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.5903 - mae: 10.9439 - val_loss: 22.0690 - val_mae: 21.9573\n",
            "Epoch 908/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1189 - mae: 10.5993\n",
            "Epoch 00908: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.5431 - mae: 10.9024 - val_loss: 22.3619 - val_mae: 22.2491\n",
            "Epoch 909/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1722 - mae: 10.6526\n",
            "Epoch 00909: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.5871 - mae: 10.9491 - val_loss: 22.0210 - val_mae: 21.9229\n",
            "Epoch 910/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1752 - mae: 10.6558\n",
            "Epoch 00910: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.6118 - mae: 10.9677 - val_loss: 23.0797 - val_mae: 22.9694\n",
            "Epoch 911/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0960 - mae: 10.5761\n",
            "Epoch 00911: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.5424 - mae: 10.8952 - val_loss: 24.0228 - val_mae: 23.9159\n",
            "Epoch 912/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1150 - mae: 10.5949\n",
            "Epoch 00912: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.5551 - mae: 10.9094 - val_loss: 21.0026 - val_mae: 20.8981\n",
            "Epoch 913/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2408 - mae: 10.7222\n",
            "Epoch 00913: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.6777 - mae: 11.0344 - val_loss: 24.2902 - val_mae: 24.1967\n",
            "Epoch 914/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3113 - mae: 10.7920\n",
            "Epoch 00914: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.7675 - mae: 11.1179 - val_loss: 18.7195 - val_mae: 18.6411\n",
            "Epoch 915/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6199 - mae: 11.1034\n",
            "Epoch 00915: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.0345 - mae: 11.3997 - val_loss: 27.9958 - val_mae: 27.9060\n",
            "Epoch 916/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5678 - mae: 11.0501\n",
            "Epoch 00916: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 11.0090 - mae: 11.3654 - val_loss: 17.3919 - val_mae: 17.3248\n",
            "Epoch 917/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6727 - mae: 11.1570\n",
            "Epoch 00917: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 11.1001 - mae: 11.4624 - val_loss: 25.2423 - val_mae: 25.1600\n",
            "Epoch 918/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4090 - mae: 10.8916\n",
            "Epoch 00918: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.8134 - mae: 11.1805 - val_loss: 21.5102 - val_mae: 21.4098\n",
            "Epoch 919/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3329 - mae: 10.8144\n",
            "Epoch 00919: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.7638 - mae: 11.1224 - val_loss: 24.9161 - val_mae: 24.8222\n",
            "Epoch 920/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3864 - mae: 10.8675\n",
            "Epoch 00920: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.8124 - mae: 11.1719 - val_loss: 17.8485 - val_mae: 17.7708\n",
            "Epoch 921/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6986 - mae: 11.1828\n",
            "Epoch 00921: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 11.1139 - mae: 11.4795 - val_loss: 26.7158 - val_mae: 26.5857\n",
            "Epoch 922/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4156 - mae: 10.8984\n",
            "Epoch 00922: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.8222 - mae: 11.1889 - val_loss: 22.0152 - val_mae: 21.9149\n",
            "Epoch 923/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2187 - mae: 10.6994\n",
            "Epoch 00923: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.6517 - mae: 11.0087 - val_loss: 22.1022 - val_mae: 21.9964\n",
            "Epoch 924/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0973 - mae: 10.5774\n",
            "Epoch 00924: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.5834 - mae: 10.9248 - val_loss: 22.9258 - val_mae: 22.8113\n",
            "Epoch 925/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1074 - mae: 10.5875\n",
            "Epoch 00925: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.5376 - mae: 10.8948 - val_loss: 22.4519 - val_mae: 22.3567\n",
            "Epoch 926/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1133 - mae: 10.5931\n",
            "Epoch 00926: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.5426 - mae: 10.8998 - val_loss: 21.4788 - val_mae: 21.3770\n",
            "Epoch 927/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1496 - mae: 10.6302\n",
            "Epoch 00927: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.6080 - mae: 10.9578 - val_loss: 24.2620 - val_mae: 24.1447\n",
            "Epoch 928/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0483 - mae: 10.5283\n",
            "Epoch 00928: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.4743 - mae: 10.8328 - val_loss: 21.8995 - val_mae: 21.7903\n",
            "Epoch 929/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1436 - mae: 10.6250\n",
            "Epoch 00929: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.5929 - mae: 10.9460 - val_loss: 23.5428 - val_mae: 23.4357\n",
            "Epoch 930/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1093 - mae: 10.5894\n",
            "Epoch 00930: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.5340 - mae: 10.8930 - val_loss: 20.0201 - val_mae: 19.9224\n",
            "Epoch 931/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4010 - mae: 10.8838\n",
            "Epoch 00931: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.8488 - mae: 11.2037 - val_loss: 25.1009 - val_mae: 24.9914\n",
            "Epoch 932/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3048 - mae: 10.7856\n",
            "Epoch 00932: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.7468 - mae: 11.1014 - val_loss: 18.9012 - val_mae: 18.8379\n",
            "Epoch 933/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4764 - mae: 10.9586\n",
            "Epoch 00933: val_loss did not improve from 17.25950\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.9139 - mae: 11.2712 - val_loss: 28.0230 - val_mae: 27.9186\n",
            "Epoch 934/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4891 - mae: 10.9719\n",
            "Epoch 00934: val_loss improved from 17.25950 to 16.78607, saving model to cp/weights-934-16.79.hdf5\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.9165 - mae: 11.2772 - val_loss: 16.7861 - val_mae: 16.7273\n",
            "Epoch 935/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6527 - mae: 11.1370\n",
            "Epoch 00935: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 11.0737 - mae: 11.4378 - val_loss: 24.9854 - val_mae: 24.8738\n",
            "Epoch 936/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3174 - mae: 10.7980\n",
            "Epoch 00936: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.7745 - mae: 11.1247 - val_loss: 26.0829 - val_mae: 25.9642\n",
            "Epoch 937/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3849 - mae: 10.8674\n",
            "Epoch 00937: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.8148 - mae: 11.1745 - val_loss: 19.6342 - val_mae: 19.5265\n",
            "Epoch 938/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4226 - mae: 10.9058\n",
            "Epoch 00938: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.8355 - mae: 11.2008 - val_loss: 24.6762 - val_mae: 24.5545\n",
            "Epoch 939/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2944 - mae: 10.7753\n",
            "Epoch 00939: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.7504 - mae: 11.1010 - val_loss: 23.8393 - val_mae: 23.7308\n",
            "Epoch 940/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2995 - mae: 10.7815\n",
            "Epoch 00940: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.7302 - mae: 11.0892 - val_loss: 19.1571 - val_mae: 19.0507\n",
            "Epoch 941/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5005 - mae: 10.9840\n",
            "Epoch 00941: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.9446 - mae: 11.3013 - val_loss: 24.8055 - val_mae: 24.6936\n",
            "Epoch 942/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2101 - mae: 10.6906\n",
            "Epoch 00942: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.6632 - mae: 11.0143 - val_loss: 22.8313 - val_mae: 22.7416\n",
            "Epoch 943/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1338 - mae: 10.6137\n",
            "Epoch 00943: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.5625 - mae: 10.9201 - val_loss: 20.2028 - val_mae: 20.1067\n",
            "Epoch 944/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2534 - mae: 10.7345\n",
            "Epoch 00944: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.6964 - mae: 11.0510 - val_loss: 26.0910 - val_mae: 25.9613\n",
            "Epoch 945/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1622 - mae: 10.6432\n",
            "Epoch 00945: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 178ms/step - loss: 10.6121 - mae: 10.9647 - val_loss: 21.8564 - val_mae: 21.7644\n",
            "Epoch 946/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1153 - mae: 10.5957\n",
            "Epoch 00946: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.5738 - mae: 10.9233 - val_loss: 22.2343 - val_mae: 22.1299\n",
            "Epoch 947/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1503 - mae: 10.6302\n",
            "Epoch 00947: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.6130 - mae: 10.9608 - val_loss: 19.9196 - val_mae: 19.8287\n",
            "Epoch 948/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2136 - mae: 10.6944\n",
            "Epoch 00948: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.6612 - mae: 11.0143 - val_loss: 24.8823 - val_mae: 24.7826\n",
            "Epoch 949/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3251 - mae: 10.8060\n",
            "Epoch 00949: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.7692 - mae: 11.1234 - val_loss: 17.8944 - val_mae: 17.8046\n",
            "Epoch 950/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4603 - mae: 10.9434\n",
            "Epoch 00950: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.8790 - mae: 11.2427 - val_loss: 26.4538 - val_mae: 26.3480\n",
            "Epoch 951/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3430 - mae: 10.8259\n",
            "Epoch 00951: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.7937 - mae: 11.1478 - val_loss: 18.4933 - val_mae: 18.4118\n",
            "Epoch 952/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3622 - mae: 10.8450\n",
            "Epoch 00952: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.7896 - mae: 11.1504 - val_loss: 23.6068 - val_mae: 23.5016\n",
            "Epoch 953/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1089 - mae: 10.5884\n",
            "Epoch 00953: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.5782 - mae: 10.9238 - val_loss: 23.1718 - val_mae: 23.0867\n",
            "Epoch 954/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1850 - mae: 10.6656\n",
            "Epoch 00954: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.6468 - mae: 10.9956 - val_loss: 18.8603 - val_mae: 18.7794\n",
            "Epoch 955/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2904 - mae: 10.7718\n",
            "Epoch 00955: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.7283 - mae: 11.0847 - val_loss: 22.9967 - val_mae: 22.8865\n",
            "Epoch 956/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0958 - mae: 10.5751\n",
            "Epoch 00956: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.5472 - mae: 10.8977 - val_loss: 21.8257 - val_mae: 21.7310\n",
            "Epoch 957/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0363 - mae: 10.5163\n",
            "Epoch 00957: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.4621 - mae: 10.8206 - val_loss: 19.0779 - val_mae: 18.9862\n",
            "Epoch 958/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2747 - mae: 10.7565\n",
            "Epoch 00958: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.7116 - mae: 11.0686 - val_loss: 24.0529 - val_mae: 23.9450\n",
            "Epoch 959/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0766 - mae: 10.5561\n",
            "Epoch 00959: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.5280 - mae: 10.8787 - val_loss: 22.2571 - val_mae: 22.1603\n",
            "Epoch 960/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1226 - mae: 10.6028\n",
            "Epoch 00960: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.5602 - mae: 10.9155 - val_loss: 22.9652 - val_mae: 22.8934\n",
            "Epoch 961/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1206 - mae: 10.6001\n",
            "Epoch 00961: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.5676 - mae: 10.9195 - val_loss: 18.6554 - val_mae: 18.5930\n",
            "Epoch 962/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2815 - mae: 10.7634\n",
            "Epoch 00962: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.7453 - mae: 11.0949 - val_loss: 24.6521 - val_mae: 24.5726\n",
            "Epoch 963/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3675 - mae: 10.8481\n",
            "Epoch 00963: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.8173 - mae: 11.1695 - val_loss: 16.8517 - val_mae: 16.7983\n",
            "Epoch 964/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.6641 - mae: 11.1481\n",
            "Epoch 00964: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 11.1023 - mae: 11.4611 - val_loss: 27.8178 - val_mae: 27.7067\n",
            "Epoch 965/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4360 - mae: 10.9189\n",
            "Epoch 00965: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.8720 - mae: 11.2303 - val_loss: 20.6345 - val_mae: 20.5522\n",
            "Epoch 966/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2436 - mae: 10.7251\n",
            "Epoch 00966: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.6714 - mae: 11.0307 - val_loss: 23.6118 - val_mae: 23.5303\n",
            "Epoch 967/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1555 - mae: 10.6352\n",
            "Epoch 00967: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.5874 - mae: 10.9438 - val_loss: 19.9463 - val_mae: 19.8565\n",
            "Epoch 968/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2763 - mae: 10.7577\n",
            "Epoch 00968: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 179ms/step - loss: 10.7298 - mae: 11.0818 - val_loss: 24.6325 - val_mae: 24.5472\n",
            "Epoch 969/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1299 - mae: 10.6106\n",
            "Epoch 00969: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 10.5625 - mae: 10.9197 - val_loss: 20.1265 - val_mae: 20.0555\n",
            "Epoch 970/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2025 - mae: 10.6833\n",
            "Epoch 00970: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 178ms/step - loss: 10.6601 - mae: 11.0103 - val_loss: 24.7775 - val_mae: 24.6905\n",
            "Epoch 971/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1579 - mae: 10.6385\n",
            "Epoch 00971: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.5776 - mae: 10.9384 - val_loss: 18.9284 - val_mae: 18.8644\n",
            "Epoch 972/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3522 - mae: 10.8337\n",
            "Epoch 00972: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.7959 - mae: 11.1508 - val_loss: 25.2698 - val_mae: 25.2027\n",
            "Epoch 973/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3945 - mae: 10.8766\n",
            "Epoch 00973: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 179ms/step - loss: 10.8236 - mae: 11.1832 - val_loss: 17.3517 - val_mae: 17.3011\n",
            "Epoch 974/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.5187 - mae: 11.0019\n",
            "Epoch 00974: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 180ms/step - loss: 10.9388 - mae: 11.3021 - val_loss: 26.6782 - val_mae: 26.5888\n",
            "Epoch 975/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3513 - mae: 10.8341\n",
            "Epoch 00975: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 181ms/step - loss: 10.7838 - mae: 11.1431 - val_loss: 20.6785 - val_mae: 20.5888\n",
            "Epoch 976/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1696 - mae: 10.6507\n",
            "Epoch 00976: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.5945 - mae: 10.9543 - val_loss: 22.4557 - val_mae: 22.3659\n",
            "Epoch 977/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1026 - mae: 10.5822\n",
            "Epoch 00977: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 178ms/step - loss: 10.5339 - mae: 10.8903 - val_loss: 22.4249 - val_mae: 22.3233\n",
            "Epoch 978/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0809 - mae: 10.5607\n",
            "Epoch 00978: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 178ms/step - loss: 10.5134 - mae: 10.8698 - val_loss: 23.0563 - val_mae: 22.9654\n",
            "Epoch 979/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0922 - mae: 10.5721\n",
            "Epoch 00979: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.5316 - mae: 10.8860 - val_loss: 21.2235 - val_mae: 21.1534\n",
            "Epoch 980/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1456 - mae: 10.6253\n",
            "Epoch 00980: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.5780 - mae: 10.9343 - val_loss: 24.8523 - val_mae: 24.7682\n",
            "Epoch 981/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2611 - mae: 10.7416\n",
            "Epoch 00981: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.7161 - mae: 11.0667 - val_loss: 17.1775 - val_mae: 17.1251\n",
            "Epoch 982/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3970 - mae: 10.8795\n",
            "Epoch 00982: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.8348 - mae: 11.1924 - val_loss: 25.7049 - val_mae: 25.6155\n",
            "Epoch 983/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2778 - mae: 10.7597\n",
            "Epoch 00983: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.7316 - mae: 11.0840 - val_loss: 19.0799 - val_mae: 19.0262\n",
            "Epoch 984/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2075 - mae: 10.6887\n",
            "Epoch 00984: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.6512 - mae: 11.0057 - val_loss: 22.4104 - val_mae: 22.3385\n",
            "Epoch 985/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0564 - mae: 10.5359\n",
            "Epoch 00985: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.5048 - mae: 10.8563 - val_loss: 20.0032 - val_mae: 19.9284\n",
            "Epoch 986/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1030 - mae: 10.5826\n",
            "Epoch 00986: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.5199 - mae: 10.8805 - val_loss: 22.1324 - val_mae: 22.0587\n",
            "Epoch 987/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9838 - mae: 10.4635\n",
            "Epoch 00987: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.4025 - mae: 10.7627 - val_loss: 21.3645 - val_mae: 21.2836\n",
            "Epoch 988/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1307 - mae: 10.6106\n",
            "Epoch 00988: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.5641 - mae: 10.9203 - val_loss: 22.7354 - val_mae: 22.6542\n",
            "Epoch 989/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0845 - mae: 10.5637\n",
            "Epoch 00989: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.5344 - mae: 10.8852 - val_loss: 20.3808 - val_mae: 20.3029\n",
            "Epoch 990/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1804 - mae: 10.6602\n",
            "Epoch 00990: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 179ms/step - loss: 10.6434 - mae: 10.9910 - val_loss: 23.7423 - val_mae: 23.6672\n",
            "Epoch 991/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2897 - mae: 10.7697\n",
            "Epoch 00991: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 10.7335 - mae: 11.0869 - val_loss: 17.2377 - val_mae: 17.1544\n",
            "Epoch 992/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.8544 - mae: 11.3393\n",
            "Epoch 00992: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 11.2808 - mae: 11.6440 - val_loss: 27.9462 - val_mae: 27.8252\n",
            "Epoch 993/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.4522 - mae: 10.9356\n",
            "Epoch 00993: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.8755 - mae: 11.2380 - val_loss: 22.3701 - val_mae: 22.2736\n",
            "Epoch 994/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1684 - mae: 10.6488\n",
            "Epoch 00994: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.6148 - mae: 10.9678 - val_loss: 21.1863 - val_mae: 21.0899\n",
            "Epoch 995/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1509 - mae: 10.6320\n",
            "Epoch 00995: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.5910 - mae: 10.9465 - val_loss: 22.8495 - val_mae: 22.7519\n",
            "Epoch 996/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0932 - mae: 10.5722\n",
            "Epoch 00996: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.5345 - mae: 10.8876 - val_loss: 23.6249 - val_mae: 23.5463\n",
            "Epoch 997/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1895 - mae: 10.6703\n",
            "Epoch 00997: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.6075 - mae: 10.9690 - val_loss: 18.0663 - val_mae: 17.9988\n",
            "Epoch 998/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.3418 - mae: 10.8237\n",
            "Epoch 00998: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.7739 - mae: 11.1324 - val_loss: 24.3153 - val_mae: 24.2174\n",
            "Epoch 999/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1429 - mae: 10.6242\n",
            "Epoch 00999: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.5830 - mae: 10.9387 - val_loss: 18.9247 - val_mae: 18.8407\n",
            "Epoch 1000/1000\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2313 - mae: 10.7129\n",
            "Epoch 01000: val_loss did not improve from 16.78607\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.6697 - mae: 11.0260 - val_loss: 24.3118 - val_mae: 24.2282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM0aLVPncZE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc8ce095-f6d5-4a11-b099-4f7b10461e0a"
      },
      "source": [
        "#total epoch=2000\n",
        "history = model.fit(train_set,epochs=400,callbacks=[checkpoint], validation_data=test_set)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "     30/Unknown - 5s 166ms/step - loss: 10.2053 - mae: 10.5608\n",
            "Epoch 00001: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.2053 - mae: 10.5608 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
            "Epoch 2/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7394 - mae: 10.2145\n",
            "Epoch 00002: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.1394 - mae: 10.5004 - val_loss: 19.3462 - val_mae: 19.3599\n",
            "Epoch 3/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7478 - mae: 10.2221\n",
            "Epoch 00003: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.1808 - mae: 10.5316 - val_loss: 21.0664 - val_mae: 21.0734\n",
            "Epoch 4/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7038 - mae: 10.1772\n",
            "Epoch 00004: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1159 - mae: 10.4718 - val_loss: 18.4250 - val_mae: 18.4419\n",
            "Epoch 5/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7003 - mae: 10.1753\n",
            "Epoch 00005: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1219 - mae: 10.4767 - val_loss: 19.3174 - val_mae: 19.3390\n",
            "Epoch 6/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8025 - mae: 10.2784\n",
            "Epoch 00006: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.2068 - mae: 10.5674 - val_loss: 18.8644 - val_mae: 18.8770\n",
            "Epoch 7/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8690 - mae: 10.3476\n",
            "Epoch 00007: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.2853 - mae: 10.6451 - val_loss: 20.0394 - val_mae: 20.0649\n",
            "Epoch 8/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7400 - mae: 10.2149\n",
            "Epoch 00008: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.1790 - mae: 10.5288 - val_loss: 20.6790 - val_mae: 20.7129\n",
            "Epoch 9/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7469 - mae: 10.2207\n",
            "Epoch 00009: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1639 - mae: 10.5188 - val_loss: 18.2882 - val_mae: 18.3276\n",
            "Epoch 10/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7891 - mae: 10.2652\n",
            "Epoch 00010: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2229 - mae: 10.5752 - val_loss: 20.1568 - val_mae: 20.2183\n",
            "Epoch 11/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7643 - mae: 10.2387\n",
            "Epoch 00011: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1906 - mae: 10.5434 - val_loss: 15.8896 - val_mae: 15.9558\n",
            "Epoch 12/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9378 - mae: 10.4167\n",
            "Epoch 00012: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.3481 - mae: 10.7100 - val_loss: 22.5979 - val_mae: 22.6307\n",
            "Epoch 13/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0038 - mae: 10.4818\n",
            "Epoch 00013: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.4158 - mae: 10.7762 - val_loss: 13.1673 - val_mae: 13.2810\n",
            "Epoch 14/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0483 - mae: 10.5273\n",
            "Epoch 00014: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.4600 - mae: 10.8215 - val_loss: 20.7947 - val_mae: 20.8515\n",
            "Epoch 15/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9248 - mae: 10.4028\n",
            "Epoch 00015: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.3559 - mae: 10.7109 - val_loss: 17.6136 - val_mae: 17.6851\n",
            "Epoch 16/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8636 - mae: 10.3393\n",
            "Epoch 00016: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.2766 - mae: 10.6345 - val_loss: 21.0265 - val_mae: 21.0670\n",
            "Epoch 17/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8040 - mae: 10.2801\n",
            "Epoch 00017: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2356 - mae: 10.5886 - val_loss: 16.5962 - val_mae: 16.6654\n",
            "Epoch 18/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8101 - mae: 10.2843\n",
            "Epoch 00018: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.2271 - mae: 10.5824 - val_loss: 21.7492 - val_mae: 21.7917\n",
            "Epoch 19/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8115 - mae: 10.2878\n",
            "Epoch 00019: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.2454 - mae: 10.5979 - val_loss: 14.3496 - val_mae: 14.4581\n",
            "Epoch 20/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7596 - mae: 10.2354\n",
            "Epoch 00020: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1546 - mae: 10.5178 - val_loss: 21.9351 - val_mae: 21.9841\n",
            "Epoch 21/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8406 - mae: 10.3170\n",
            "Epoch 00021: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.2408 - mae: 10.6030 - val_loss: 17.6306 - val_mae: 17.6861\n",
            "Epoch 22/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7612 - mae: 10.2353\n",
            "Epoch 00022: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1975 - mae: 10.5473 - val_loss: 21.6605 - val_mae: 21.6855\n",
            "Epoch 23/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8156 - mae: 10.2916\n",
            "Epoch 00023: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.2538 - mae: 10.6048 - val_loss: 14.1644 - val_mae: 14.2441\n",
            "Epoch 24/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9147 - mae: 10.3931\n",
            "Epoch 00024: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.3452 - mae: 10.7008 - val_loss: 21.8710 - val_mae: 21.8814\n",
            "Epoch 25/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7493 - mae: 10.2248\n",
            "Epoch 00025: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1838 - mae: 10.5353 - val_loss: 18.4037 - val_mae: 18.4295\n",
            "Epoch 26/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7356 - mae: 10.2085\n",
            "Epoch 00026: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1658 - mae: 10.5161 - val_loss: 21.0096 - val_mae: 21.0285\n",
            "Epoch 27/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6929 - mae: 10.1680\n",
            "Epoch 00027: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1340 - mae: 10.4833 - val_loss: 16.7236 - val_mae: 16.7762\n",
            "Epoch 28/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6970 - mae: 10.1717\n",
            "Epoch 00028: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.1088 - mae: 10.4661 - val_loss: 21.5004 - val_mae: 21.5263\n",
            "Epoch 29/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7560 - mae: 10.2306\n",
            "Epoch 00029: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 180ms/step - loss: 10.1554 - mae: 10.5161 - val_loss: 15.0359 - val_mae: 15.1185\n",
            "Epoch 30/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8486 - mae: 10.3259\n",
            "Epoch 00030: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 179ms/step - loss: 10.2876 - mae: 10.6397 - val_loss: 21.9273 - val_mae: 21.9557\n",
            "Epoch 31/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7768 - mae: 10.2523\n",
            "Epoch 00031: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 178ms/step - loss: 10.2074 - mae: 10.5601 - val_loss: 16.8246 - val_mae: 16.8898\n",
            "Epoch 32/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7560 - mae: 10.2312\n",
            "Epoch 00032: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.1714 - mae: 10.5281 - val_loss: 20.2105 - val_mae: 20.2516\n",
            "Epoch 33/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7545 - mae: 10.2289\n",
            "Epoch 00033: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.1657 - mae: 10.5228 - val_loss: 17.7800 - val_mae: 17.8324\n",
            "Epoch 34/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7083 - mae: 10.1833\n",
            "Epoch 00034: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.1423 - mae: 10.4936 - val_loss: 21.4102 - val_mae: 21.4449\n",
            "Epoch 35/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8438 - mae: 10.3191\n",
            "Epoch 00035: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.2922 - mae: 10.6395 - val_loss: 14.3048 - val_mae: 14.3967\n",
            "Epoch 36/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9240 - mae: 10.4022\n",
            "Epoch 00036: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 10.3336 - mae: 10.6949 - val_loss: 22.2533 - val_mae: 22.2809\n",
            "Epoch 37/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7295 - mae: 10.2068\n",
            "Epoch 00037: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.1580 - mae: 10.5130 - val_loss: 16.5350 - val_mae: 16.6033\n",
            "Epoch 38/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7460 - mae: 10.2196\n",
            "Epoch 00038: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1598 - mae: 10.5155 - val_loss: 21.0057 - val_mae: 21.0311\n",
            "Epoch 39/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7267 - mae: 10.2017\n",
            "Epoch 00039: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1508 - mae: 10.5049 - val_loss: 15.1856 - val_mae: 15.2571\n",
            "Epoch 40/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7775 - mae: 10.2538\n",
            "Epoch 00040: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1905 - mae: 10.5491 - val_loss: 21.3996 - val_mae: 21.4321\n",
            "Epoch 41/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7908 - mae: 10.2659\n",
            "Epoch 00041: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2089 - mae: 10.5647 - val_loss: 15.7120 - val_mae: 15.7821\n",
            "Epoch 42/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8275 - mae: 10.3045\n",
            "Epoch 00042: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2721 - mae: 10.6222 - val_loss: 18.8417 - val_mae: 18.9043\n",
            "Epoch 43/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6849 - mae: 10.1591\n",
            "Epoch 00043: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1108 - mae: 10.4636 - val_loss: 16.1861 - val_mae: 16.2627\n",
            "Epoch 44/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8669 - mae: 10.3442\n",
            "Epoch 00044: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2834 - mae: 10.6419 - val_loss: 20.8885 - val_mae: 20.9408\n",
            "Epoch 45/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8435 - mae: 10.3186\n",
            "Epoch 00045: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.2742 - mae: 10.6265 - val_loss: 14.7002 - val_mae: 14.7808\n",
            "Epoch 46/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0046 - mae: 10.4826\n",
            "Epoch 00046: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.4376 - mae: 10.7922 - val_loss: 20.5574 - val_mae: 20.6020\n",
            "Epoch 47/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8189 - mae: 10.2955\n",
            "Epoch 00047: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2326 - mae: 10.5912 - val_loss: 16.6710 - val_mae: 16.7315\n",
            "Epoch 48/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7792 - mae: 10.2528\n",
            "Epoch 00048: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.2130 - mae: 10.5630 - val_loss: 20.0993 - val_mae: 20.1509\n",
            "Epoch 49/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7854 - mae: 10.2614\n",
            "Epoch 00049: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1910 - mae: 10.5513 - val_loss: 16.7565 - val_mae: 16.8186\n",
            "Epoch 50/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8444 - mae: 10.3209\n",
            "Epoch 00050: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2692 - mae: 10.6246 - val_loss: 20.4921 - val_mae: 20.5434\n",
            "Epoch 51/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9138 - mae: 10.3906\n",
            "Epoch 00051: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.3342 - mae: 10.6911 - val_loss: 13.9092 - val_mae: 13.9987\n",
            "Epoch 52/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0275 - mae: 10.5065\n",
            "Epoch 00052: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.4421 - mae: 10.8028 - val_loss: 20.2519 - val_mae: 20.3036\n",
            "Epoch 53/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8684 - mae: 10.3447\n",
            "Epoch 00053: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.3011 - mae: 10.6540 - val_loss: 18.5471 - val_mae: 18.6081\n",
            "Epoch 54/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7937 - mae: 10.2698\n",
            "Epoch 00054: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.2234 - mae: 10.5770 - val_loss: 19.4646 - val_mae: 19.5223\n",
            "Epoch 55/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7921 - mae: 10.2687\n",
            "Epoch 00055: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.2286 - mae: 10.5807 - val_loss: 17.1304 - val_mae: 17.1923\n",
            "Epoch 56/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6941 - mae: 10.1679\n",
            "Epoch 00056: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1104 - mae: 10.4656 - val_loss: 20.5951 - val_mae: 20.6347\n",
            "Epoch 57/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8220 - mae: 10.2980\n",
            "Epoch 00057: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.2691 - mae: 10.6176 - val_loss: 15.2859 - val_mae: 15.3597\n",
            "Epoch 58/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8287 - mae: 10.3046\n",
            "Epoch 00058: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.2633 - mae: 10.6153 - val_loss: 22.1801 - val_mae: 22.1872\n",
            "Epoch 59/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7624 - mae: 10.2367\n",
            "Epoch 00059: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1895 - mae: 10.5421 - val_loss: 16.3648 - val_mae: 16.4128\n",
            "Epoch 60/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7664 - mae: 10.2426\n",
            "Epoch 00060: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1893 - mae: 10.5449 - val_loss: 21.4542 - val_mae: 21.4524\n",
            "Epoch 61/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7090 - mae: 10.1833\n",
            "Epoch 00061: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1275 - mae: 10.4825 - val_loss: 17.0183 - val_mae: 17.0570\n",
            "Epoch 62/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8160 - mae: 10.2919\n",
            "Epoch 00062: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.2140 - mae: 10.5764 - val_loss: 21.5836 - val_mae: 21.5873\n",
            "Epoch 63/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7522 - mae: 10.2265\n",
            "Epoch 00063: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1662 - mae: 10.5224 - val_loss: 15.8697 - val_mae: 15.9297\n",
            "Epoch 64/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9068 - mae: 10.3857\n",
            "Epoch 00064: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.3491 - mae: 10.7018 - val_loss: 21.6451 - val_mae: 21.6651\n",
            "Epoch 65/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7578 - mae: 10.2340\n",
            "Epoch 00065: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1895 - mae: 10.5426 - val_loss: 16.2280 - val_mae: 16.3064\n",
            "Epoch 66/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7494 - mae: 10.2232\n",
            "Epoch 00066: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1731 - mae: 10.5262 - val_loss: 21.1542 - val_mae: 21.1941\n",
            "Epoch 67/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8028 - mae: 10.2794\n",
            "Epoch 00067: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.2076 - mae: 10.5687 - val_loss: 16.0267 - val_mae: 16.0943\n",
            "Epoch 68/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8633 - mae: 10.3384\n",
            "Epoch 00068: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.2842 - mae: 10.6394 - val_loss: 22.8910 - val_mae: 22.9145\n",
            "Epoch 69/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9701 - mae: 10.4475\n",
            "Epoch 00069: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.4029 - mae: 10.7567 - val_loss: 13.6126 - val_mae: 13.7046\n",
            "Epoch 70/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9429 - mae: 10.4217\n",
            "Epoch 00070: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.3350 - mae: 10.7019 - val_loss: 22.6397 - val_mae: 22.6543\n",
            "Epoch 71/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9204 - mae: 10.3970\n",
            "Epoch 00071: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.3535 - mae: 10.7066 - val_loss: 20.3602 - val_mae: 20.3903\n",
            "Epoch 72/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8231 - mae: 10.3005\n",
            "Epoch 00072: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.2442 - mae: 10.6014 - val_loss: 16.9511 - val_mae: 17.0144\n",
            "Epoch 73/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6647 - mae: 10.1384\n",
            "Epoch 00073: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.0815 - mae: 10.4364 - val_loss: 18.9119 - val_mae: 18.9265\n",
            "Epoch 74/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7059 - mae: 10.1820\n",
            "Epoch 00074: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1289 - mae: 10.4843 - val_loss: 18.7421 - val_mae: 18.7514\n",
            "Epoch 75/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7873 - mae: 10.2645\n",
            "Epoch 00075: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1960 - mae: 10.5565 - val_loss: 19.0146 - val_mae: 19.0333\n",
            "Epoch 76/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8398 - mae: 10.3162\n",
            "Epoch 00076: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.2736 - mae: 10.6262 - val_loss: 21.0070 - val_mae: 21.0216\n",
            "Epoch 77/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7390 - mae: 10.2134\n",
            "Epoch 00077: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1304 - mae: 10.4933 - val_loss: 17.0016 - val_mae: 17.0544\n",
            "Epoch 78/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7547 - mae: 10.2302\n",
            "Epoch 00078: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1863 - mae: 10.5387 - val_loss: 20.3384 - val_mae: 20.3551\n",
            "Epoch 79/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7132 - mae: 10.1872\n",
            "Epoch 00079: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1459 - mae: 10.4965 - val_loss: 17.6460 - val_mae: 17.6984\n",
            "Epoch 80/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6999 - mae: 10.1772\n",
            "Epoch 00080: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.1112 - mae: 10.4712 - val_loss: 19.4479 - val_mae: 19.4828\n",
            "Epoch 81/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7132 - mae: 10.1878\n",
            "Epoch 00081: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.1615 - mae: 10.5083 - val_loss: 19.0142 - val_mae: 19.0758\n",
            "Epoch 82/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7111 - mae: 10.1856\n",
            "Epoch 00082: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1300 - mae: 10.4850 - val_loss: 15.4476 - val_mae: 15.5273\n",
            "Epoch 83/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9676 - mae: 10.4472\n",
            "Epoch 00083: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.3814 - mae: 10.7429 - val_loss: 19.7651 - val_mae: 19.8187\n",
            "Epoch 84/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7394 - mae: 10.2129\n",
            "Epoch 00084: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1692 - mae: 10.5201 - val_loss: 19.7901 - val_mae: 19.8452\n",
            "Epoch 85/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6883 - mae: 10.1622\n",
            "Epoch 00085: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1051 - mae: 10.4602 - val_loss: 17.8322 - val_mae: 17.9068\n",
            "Epoch 86/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6968 - mae: 10.1697\n",
            "Epoch 00086: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1458 - mae: 10.4907 - val_loss: 19.6309 - val_mae: 19.6909\n",
            "Epoch 87/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7757 - mae: 10.2504\n",
            "Epoch 00087: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1949 - mae: 10.5501 - val_loss: 15.0789 - val_mae: 15.1636\n",
            "Epoch 88/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7336 - mae: 10.2101\n",
            "Epoch 00088: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1553 - mae: 10.5115 - val_loss: 21.4481 - val_mae: 21.5067\n",
            "Epoch 89/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1038 - mae: 10.5803\n",
            "Epoch 00089: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.5174 - mae: 10.8760 - val_loss: 13.2657 - val_mae: 13.3552\n",
            "Epoch 90/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.2179 - mae: 10.6988\n",
            "Epoch 00090: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.6467 - mae: 11.0052 - val_loss: 20.6324 - val_mae: 20.6784\n",
            "Epoch 91/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9707 - mae: 10.4483\n",
            "Epoch 00091: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.3859 - mae: 10.7450 - val_loss: 20.8124 - val_mae: 20.8210\n",
            "Epoch 92/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9275 - mae: 10.4075\n",
            "Epoch 00092: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.3420 - mae: 10.7037 - val_loss: 18.1496 - val_mae: 18.1839\n",
            "Epoch 93/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8310 - mae: 10.3088\n",
            "Epoch 00093: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.2461 - mae: 10.6056 - val_loss: 18.1307 - val_mae: 18.1546\n",
            "Epoch 94/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7473 - mae: 10.2236\n",
            "Epoch 00094: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.1666 - mae: 10.5234 - val_loss: 20.0131 - val_mae: 20.0534\n",
            "Epoch 95/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7489 - mae: 10.2227\n",
            "Epoch 00095: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 10.1478 - mae: 10.5078 - val_loss: 15.8850 - val_mae: 15.9613\n",
            "Epoch 96/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7230 - mae: 10.1973\n",
            "Epoch 00096: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1439 - mae: 10.4982 - val_loss: 21.3497 - val_mae: 21.3785\n",
            "Epoch 97/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6857 - mae: 10.1596\n",
            "Epoch 00097: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.1140 - mae: 10.4658 - val_loss: 16.7244 - val_mae: 16.7685\n",
            "Epoch 98/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6770 - mae: 10.1521\n",
            "Epoch 00098: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1031 - mae: 10.4567 - val_loss: 20.9257 - val_mae: 20.9644\n",
            "Epoch 99/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6406 - mae: 10.1155\n",
            "Epoch 00099: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.0710 - mae: 10.4231 - val_loss: 16.3703 - val_mae: 16.4423\n",
            "Epoch 100/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7103 - mae: 10.1843\n",
            "Epoch 00100: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1447 - mae: 10.4949 - val_loss: 21.3469 - val_mae: 21.4053\n",
            "Epoch 101/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9289 - mae: 10.4049\n",
            "Epoch 00101: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.3685 - mae: 10.7191 - val_loss: 14.2623 - val_mae: 14.3481\n",
            "Epoch 102/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0599 - mae: 10.5395\n",
            "Epoch 00102: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.4625 - mae: 10.8272 - val_loss: 20.2696 - val_mae: 20.3249\n",
            "Epoch 103/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8495 - mae: 10.3255\n",
            "Epoch 00103: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.2839 - mae: 10.6360 - val_loss: 17.8983 - val_mae: 17.9715\n",
            "Epoch 104/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7382 - mae: 10.2156\n",
            "Epoch 00104: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1549 - mae: 10.5133 - val_loss: 17.1947 - val_mae: 17.2591\n",
            "Epoch 105/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6412 - mae: 10.1152\n",
            "Epoch 00105: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.0479 - mae: 10.4059 - val_loss: 20.5728 - val_mae: 20.5899\n",
            "Epoch 106/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7151 - mae: 10.1889\n",
            "Epoch 00106: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1524 - mae: 10.5015 - val_loss: 17.7608 - val_mae: 17.8096\n",
            "Epoch 107/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7200 - mae: 10.1955\n",
            "Epoch 00107: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 10.1584 - mae: 10.5089 - val_loss: 19.4177 - val_mae: 19.4587\n",
            "Epoch 108/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6540 - mae: 10.1270\n",
            "Epoch 00108: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.0689 - mae: 10.4237 - val_loss: 18.2324 - val_mae: 18.2796\n",
            "Epoch 109/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7354 - mae: 10.2098\n",
            "Epoch 00109: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1773 - mae: 10.5257 - val_loss: 19.7293 - val_mae: 19.7955\n",
            "Epoch 110/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7504 - mae: 10.2240\n",
            "Epoch 00110: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1935 - mae: 10.5407 - val_loss: 14.5698 - val_mae: 14.6754\n",
            "Epoch 111/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8673 - mae: 10.3456\n",
            "Epoch 00111: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.2957 - mae: 10.6518 - val_loss: 21.0752 - val_mae: 21.1238\n",
            "Epoch 112/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7185 - mae: 10.1918\n",
            "Epoch 00112: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1259 - mae: 10.4832 - val_loss: 18.5064 - val_mae: 18.6006\n",
            "Epoch 113/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7076 - mae: 10.1832\n",
            "Epoch 00113: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.1358 - mae: 10.4893 - val_loss: 15.8191 - val_mae: 15.9130\n",
            "Epoch 114/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6955 - mae: 10.1696\n",
            "Epoch 00114: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1232 - mae: 10.4754 - val_loss: 20.4273 - val_mae: 20.4758\n",
            "Epoch 115/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8471 - mae: 10.3215\n",
            "Epoch 00115: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.2662 - mae: 10.6211 - val_loss: 14.0273 - val_mae: 14.1146\n",
            "Epoch 116/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.1127 - mae: 10.5921\n",
            "Epoch 00116: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.5010 - mae: 10.8696 - val_loss: 22.0207 - val_mae: 22.0697\n",
            "Epoch 117/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9313 - mae: 10.4089\n",
            "Epoch 00117: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.3387 - mae: 10.7001 - val_loss: 18.5291 - val_mae: 18.5964\n",
            "Epoch 118/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9088 - mae: 10.3877\n",
            "Epoch 00118: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.3242 - mae: 10.6845 - val_loss: 17.3698 - val_mae: 17.4245\n",
            "Epoch 119/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6715 - mae: 10.1462\n",
            "Epoch 00119: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.0941 - mae: 10.4484 - val_loss: 18.5579 - val_mae: 18.6042\n",
            "Epoch 120/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7377 - mae: 10.2113\n",
            "Epoch 00120: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1391 - mae: 10.4983 - val_loss: 18.3095 - val_mae: 18.3736\n",
            "Epoch 121/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6084 - mae: 10.0816\n",
            "Epoch 00121: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.0278 - mae: 10.3814 - val_loss: 17.2950 - val_mae: 17.3721\n",
            "Epoch 122/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7319 - mae: 10.2064\n",
            "Epoch 00122: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.1304 - mae: 10.4913 - val_loss: 17.7817 - val_mae: 17.8408\n",
            "Epoch 123/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7423 - mae: 10.2194\n",
            "Epoch 00123: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1618 - mae: 10.5193 - val_loss: 19.7412 - val_mae: 19.7909\n",
            "Epoch 124/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7172 - mae: 10.1919\n",
            "Epoch 00124: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1406 - mae: 10.4946 - val_loss: 17.3555 - val_mae: 17.4050\n",
            "Epoch 125/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9036 - mae: 10.3826\n",
            "Epoch 00125: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.3008 - mae: 10.6664 - val_loss: 19.6473 - val_mae: 19.7285\n",
            "Epoch 126/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8083 - mae: 10.2827\n",
            "Epoch 00126: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.2245 - mae: 10.5802 - val_loss: 16.1088 - val_mae: 16.2129\n",
            "Epoch 127/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6948 - mae: 10.1683\n",
            "Epoch 00127: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1229 - mae: 10.4743 - val_loss: 20.0787 - val_mae: 20.1505\n",
            "Epoch 128/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9400 - mae: 10.4172\n",
            "Epoch 00128: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.3867 - mae: 10.7365 - val_loss: 12.7213 - val_mae: 12.8422\n",
            "Epoch 129/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0360 - mae: 10.5150\n",
            "Epoch 00129: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.4223 - mae: 10.7912 - val_loss: 22.8200 - val_mae: 22.8474\n",
            "Epoch 130/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0175 - mae: 10.4967\n",
            "Epoch 00130: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.4252 - mae: 10.7881 - val_loss: 16.9542 - val_mae: 17.0299\n",
            "Epoch 131/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7026 - mae: 10.1764\n",
            "Epoch 00131: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1312 - mae: 10.4828 - val_loss: 20.3896 - val_mae: 20.4441\n",
            "Epoch 132/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6550 - mae: 10.1282\n",
            "Epoch 00132: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.0850 - mae: 10.4356 - val_loss: 16.9601 - val_mae: 17.0222\n",
            "Epoch 133/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6499 - mae: 10.1232\n",
            "Epoch 00133: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.0673 - mae: 10.4215 - val_loss: 20.0951 - val_mae: 20.1390\n",
            "Epoch 134/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6129 - mae: 10.0857\n",
            "Epoch 00134: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.0308 - mae: 10.3846 - val_loss: 16.6725 - val_mae: 16.7334\n",
            "Epoch 135/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7251 - mae: 10.2000\n",
            "Epoch 00135: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1500 - mae: 10.5038 - val_loss: 21.1772 - val_mae: 21.2325\n",
            "Epoch 136/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7641 - mae: 10.2394\n",
            "Epoch 00136: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1906 - mae: 10.5443 - val_loss: 15.0509 - val_mae: 15.1307\n",
            "Epoch 137/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8411 - mae: 10.3174\n",
            "Epoch 00137: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.2597 - mae: 10.6167 - val_loss: 23.7323 - val_mae: 23.7563\n",
            "Epoch 138/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8680 - mae: 10.3458\n",
            "Epoch 00138: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2909 - mae: 10.6481 - val_loss: 14.1236 - val_mae: 14.2277\n",
            "Epoch 139/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7386 - mae: 10.2146\n",
            "Epoch 00139: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1531 - mae: 10.5110 - val_loss: 20.0499 - val_mae: 20.1146\n",
            "Epoch 140/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7897 - mae: 10.2646\n",
            "Epoch 00140: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2161 - mae: 10.5695 - val_loss: 17.0553 - val_mae: 17.1261\n",
            "Epoch 141/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7716 - mae: 10.2452\n",
            "Epoch 00141: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.2159 - mae: 10.5629 - val_loss: 19.7437 - val_mae: 19.8084\n",
            "Epoch 142/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8244 - mae: 10.3023\n",
            "Epoch 00142: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.2495 - mae: 10.6061 - val_loss: 13.6308 - val_mae: 13.7262\n",
            "Epoch 143/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8144 - mae: 10.2908\n",
            "Epoch 00143: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.2125 - mae: 10.5754 - val_loss: 20.5588 - val_mae: 20.5956\n",
            "Epoch 144/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7545 - mae: 10.2280\n",
            "Epoch 00144: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1757 - mae: 10.5291 - val_loss: 16.9311 - val_mae: 16.9873\n",
            "Epoch 145/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7297 - mae: 10.2039\n",
            "Epoch 00145: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1308 - mae: 10.4907 - val_loss: 18.7909 - val_mae: 18.8200\n",
            "Epoch 146/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7235 - mae: 10.1979\n",
            "Epoch 00146: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1537 - mae: 10.5054 - val_loss: 17.6417 - val_mae: 17.6836\n",
            "Epoch 147/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8721 - mae: 10.3504\n",
            "Epoch 00147: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 10.3164 - mae: 10.6679 - val_loss: 18.3254 - val_mae: 18.3859\n",
            "Epoch 148/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6940 - mae: 10.1664\n",
            "Epoch 00148: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 10.1216 - mae: 10.4722 - val_loss: 19.3605 - val_mae: 19.4355\n",
            "Epoch 149/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7589 - mae: 10.2332\n",
            "Epoch 00149: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 10.2043 - mae: 10.5516 - val_loss: 15.2085 - val_mae: 15.3127\n",
            "Epoch 150/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8171 - mae: 10.2928\n",
            "Epoch 00150: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.2464 - mae: 10.5997 - val_loss: 22.2242 - val_mae: 22.2602\n",
            "Epoch 151/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8896 - mae: 10.3654\n",
            "Epoch 00151: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.3107 - mae: 10.6664 - val_loss: 14.0888 - val_mae: 14.1885\n",
            "Epoch 152/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9198 - mae: 10.3978\n",
            "Epoch 00152: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.3463 - mae: 10.7027 - val_loss: 20.3685 - val_mae: 20.4137\n",
            "Epoch 153/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8215 - mae: 10.2969\n",
            "Epoch 00153: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.2581 - mae: 10.6089 - val_loss: 17.1084 - val_mae: 17.1649\n",
            "Epoch 154/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7034 - mae: 10.1772\n",
            "Epoch 00154: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1242 - mae: 10.4780 - val_loss: 21.3087 - val_mae: 21.3188\n",
            "Epoch 155/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6222 - mae: 10.0952\n",
            "Epoch 00155: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0169 - mae: 10.3774 - val_loss: 17.9740 - val_mae: 18.0116\n",
            "Epoch 156/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6393 - mae: 10.1121\n",
            "Epoch 00156: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0700 - mae: 10.4201 - val_loss: 19.4791 - val_mae: 19.4967\n",
            "Epoch 157/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7065 - mae: 10.1793\n",
            "Epoch 00157: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1308 - mae: 10.4827 - val_loss: 19.0908 - val_mae: 19.1183\n",
            "Epoch 158/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6830 - mae: 10.1579\n",
            "Epoch 00158: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0767 - mae: 10.4393 - val_loss: 20.1662 - val_mae: 20.1963\n",
            "Epoch 159/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6512 - mae: 10.1242\n",
            "Epoch 00159: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0822 - mae: 10.4324 - val_loss: 17.6630 - val_mae: 17.7247\n",
            "Epoch 160/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7318 - mae: 10.2083\n",
            "Epoch 00160: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.1650 - mae: 10.5180 - val_loss: 18.9146 - val_mae: 18.9667\n",
            "Epoch 161/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8111 - mae: 10.2862\n",
            "Epoch 00161: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.2266 - mae: 10.5832 - val_loss: 18.2016 - val_mae: 18.2216\n",
            "Epoch 162/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9467 - mae: 10.4257\n",
            "Epoch 00162: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.3765 - mae: 10.7328 - val_loss: 19.2370 - val_mae: 19.2830\n",
            "Epoch 163/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.5700 - mae: 10.0424\n",
            "Epoch 00163: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.0256 - mae: 10.3682 - val_loss: 18.1449 - val_mae: 18.1815\n",
            "Epoch 164/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6644 - mae: 10.1390\n",
            "Epoch 00164: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 10.0983 - mae: 10.4492 - val_loss: 18.4088 - val_mae: 18.4516\n",
            "Epoch 165/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7467 - mae: 10.2230\n",
            "Epoch 00165: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1659 - mae: 10.5226 - val_loss: 19.1820 - val_mae: 19.2324\n",
            "Epoch 166/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7193 - mae: 10.1939\n",
            "Epoch 00166: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1293 - mae: 10.4870 - val_loss: 17.9824 - val_mae: 18.0125\n",
            "Epoch 167/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8517 - mae: 10.3299\n",
            "Epoch 00167: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2653 - mae: 10.6255 - val_loss: 18.5550 - val_mae: 18.6461\n",
            "Epoch 168/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7941 - mae: 10.2684\n",
            "Epoch 00168: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.2317 - mae: 10.5813 - val_loss: 14.0091 - val_mae: 14.1412\n",
            "Epoch 169/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9078 - mae: 10.3843\n",
            "Epoch 00169: val_loss did not improve from 12.36601\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.3444 - mae: 10.6963 - val_loss: 20.4281 - val_mae: 20.5232\n",
            "Epoch 170/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9698 - mae: 10.4483\n",
            "Epoch 00170: val_loss improved from 12.36601 to 12.15187, saving model to cp/weights-170-12.15.hdf5\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.4174 - mae: 10.7682 - val_loss: 12.1519 - val_mae: 12.3081\n",
            "Epoch 171/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9919 - mae: 10.4695\n",
            "Epoch 00171: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.3818 - mae: 10.7481 - val_loss: 19.1577 - val_mae: 19.2731\n",
            "Epoch 172/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8354 - mae: 10.3116\n",
            "Epoch 00172: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.2576 - mae: 10.6133 - val_loss: 17.2496 - val_mae: 17.3557\n",
            "Epoch 173/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7692 - mae: 10.2458\n",
            "Epoch 00173: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1973 - mae: 10.5518 - val_loss: 18.0295 - val_mae: 18.1029\n",
            "Epoch 174/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6411 - mae: 10.1135\n",
            "Epoch 00174: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.0739 - mae: 10.4230 - val_loss: 17.1521 - val_mae: 17.2173\n",
            "Epoch 175/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6185 - mae: 10.0919\n",
            "Epoch 00175: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.0447 - mae: 10.3966 - val_loss: 19.0422 - val_mae: 19.0884\n",
            "Epoch 176/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6833 - mae: 10.1580\n",
            "Epoch 00176: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0945 - mae: 10.4520 - val_loss: 17.8688 - val_mae: 17.9332\n",
            "Epoch 177/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7672 - mae: 10.2445\n",
            "Epoch 00177: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1774 - mae: 10.5376 - val_loss: 18.8626 - val_mae: 18.9230\n",
            "Epoch 178/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6518 - mae: 10.1259\n",
            "Epoch 00178: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.0717 - mae: 10.4261 - val_loss: 18.8192 - val_mae: 18.8673\n",
            "Epoch 179/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7278 - mae: 10.2021\n",
            "Epoch 00179: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.1504 - mae: 10.5041 - val_loss: 16.6136 - val_mae: 16.6972\n",
            "Epoch 180/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7797 - mae: 10.2574\n",
            "Epoch 00180: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.2167 - mae: 10.5697 - val_loss: 18.3749 - val_mae: 18.4688\n",
            "Epoch 181/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6715 - mae: 10.1439\n",
            "Epoch 00181: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.0886 - mae: 10.4421 - val_loss: 16.9139 - val_mae: 17.0126\n",
            "Epoch 182/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6845 - mae: 10.1584\n",
            "Epoch 00182: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.1162 - mae: 10.4670 - val_loss: 18.7997 - val_mae: 18.8832\n",
            "Epoch 183/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6212 - mae: 10.0944\n",
            "Epoch 00183: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.0591 - mae: 10.4074 - val_loss: 17.2291 - val_mae: 17.3069\n",
            "Epoch 184/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7584 - mae: 10.2352\n",
            "Epoch 00184: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1833 - mae: 10.5389 - val_loss: 18.8865 - val_mae: 19.0123\n",
            "Epoch 185/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7653 - mae: 10.2391\n",
            "Epoch 00185: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1976 - mae: 10.5481 - val_loss: 14.8546 - val_mae: 14.9747\n",
            "Epoch 186/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9495 - mae: 10.4273\n",
            "Epoch 00186: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.3561 - mae: 10.7180 - val_loss: 21.2017 - val_mae: 21.3085\n",
            "Epoch 187/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0444 - mae: 10.5224\n",
            "Epoch 00187: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.4461 - mae: 10.8095 - val_loss: 12.3764 - val_mae: 12.5320\n",
            "Epoch 188/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0174 - mae: 10.4938\n",
            "Epoch 00188: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.4635 - mae: 10.8126 - val_loss: 21.1850 - val_mae: 21.2667\n",
            "Epoch 189/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9928 - mae: 10.4717\n",
            "Epoch 00189: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.4312 - mae: 10.7850 - val_loss: 17.5059 - val_mae: 17.5930\n",
            "Epoch 190/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8221 - mae: 10.2969\n",
            "Epoch 00190: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.2416 - mae: 10.5969 - val_loss: 19.5904 - val_mae: 19.6831\n",
            "Epoch 191/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8899 - mae: 10.3680\n",
            "Epoch 00191: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.2972 - mae: 10.6591 - val_loss: 13.8785 - val_mae: 13.9746\n",
            "Epoch 192/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8239 - mae: 10.3010\n",
            "Epoch 00192: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.2448 - mae: 10.6019 - val_loss: 20.8299 - val_mae: 20.8767\n",
            "Epoch 193/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7335 - mae: 10.2082\n",
            "Epoch 00193: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1575 - mae: 10.5113 - val_loss: 17.8088 - val_mae: 17.8694\n",
            "Epoch 194/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6337 - mae: 10.1062\n",
            "Epoch 00194: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.0632 - mae: 10.4133 - val_loss: 19.2512 - val_mae: 19.3231\n",
            "Epoch 195/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6316 - mae: 10.1046\n",
            "Epoch 00195: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0474 - mae: 10.4019 - val_loss: 18.7627 - val_mae: 18.8221\n",
            "Epoch 196/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.5909 - mae: 10.0639\n",
            "Epoch 00196: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.0133 - mae: 10.3659 - val_loss: 18.3644 - val_mae: 18.4327\n",
            "Epoch 197/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6584 - mae: 10.1312\n",
            "Epoch 00197: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.0746 - mae: 10.4288 - val_loss: 18.8912 - val_mae: 18.9800\n",
            "Epoch 198/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7786 - mae: 10.2547\n",
            "Epoch 00198: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1938 - mae: 10.5516 - val_loss: 15.7720 - val_mae: 15.8721\n",
            "Epoch 199/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7241 - mae: 10.1971\n",
            "Epoch 00199: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1545 - mae: 10.5049 - val_loss: 20.2867 - val_mae: 20.3488\n",
            "Epoch 200/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9057 - mae: 10.3805\n",
            "Epoch 00200: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.3238 - mae: 10.6794 - val_loss: 13.4715 - val_mae: 13.5712\n",
            "Epoch 201/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0334 - mae: 10.5123\n",
            "Epoch 00201: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.4394 - mae: 10.8024 - val_loss: 21.5260 - val_mae: 21.5724\n",
            "Epoch 202/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9770 - mae: 10.4548\n",
            "Epoch 00202: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.3807 - mae: 10.7432 - val_loss: 16.4324 - val_mae: 16.5047\n",
            "Epoch 203/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6722 - mae: 10.1461\n",
            "Epoch 00203: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.0999 - mae: 10.4519 - val_loss: 19.8522 - val_mae: 19.9056\n",
            "Epoch 204/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6716 - mae: 10.1450\n",
            "Epoch 00204: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.0844 - mae: 10.4401 - val_loss: 15.4905 - val_mae: 15.5721\n",
            "Epoch 205/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6838 - mae: 10.1584\n",
            "Epoch 00205: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.0909 - mae: 10.4494 - val_loss: 20.5933 - val_mae: 20.6348\n",
            "Epoch 206/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7428 - mae: 10.2167\n",
            "Epoch 00206: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1239 - mae: 10.4891 - val_loss: 15.4769 - val_mae: 15.5594\n",
            "Epoch 207/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7083 - mae: 10.1836\n",
            "Epoch 00207: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.1384 - mae: 10.4910 - val_loss: 20.0732 - val_mae: 20.1100\n",
            "Epoch 208/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6735 - mae: 10.1466\n",
            "Epoch 00208: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 10.1039 - mae: 10.4543 - val_loss: 17.3361 - val_mae: 17.3786\n",
            "Epoch 209/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7832 - mae: 10.2601\n",
            "Epoch 00209: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2064 - mae: 10.5626 - val_loss: 20.9046 - val_mae: 20.9410\n",
            "Epoch 210/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6380 - mae: 10.1106\n",
            "Epoch 00210: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.0517 - mae: 10.4065 - val_loss: 16.2053 - val_mae: 16.2768\n",
            "Epoch 211/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6445 - mae: 10.1181\n",
            "Epoch 00211: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.0640 - mae: 10.4180 - val_loss: 19.5219 - val_mae: 19.5718\n",
            "Epoch 212/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6153 - mae: 10.0878\n",
            "Epoch 00212: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.0319 - mae: 10.3857 - val_loss: 17.4425 - val_mae: 17.4861\n",
            "Epoch 213/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7718 - mae: 10.2487\n",
            "Epoch 00213: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 10.1902 - mae: 10.5477 - val_loss: 21.0772 - val_mae: 21.1104\n",
            "Epoch 214/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7274 - mae: 10.2005\n",
            "Epoch 00214: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.1379 - mae: 10.4940 - val_loss: 15.8456 - val_mae: 15.9100\n",
            "Epoch 215/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8700 - mae: 10.3482\n",
            "Epoch 00215: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.2777 - mae: 10.6395 - val_loss: 20.8402 - val_mae: 20.8958\n",
            "Epoch 216/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6929 - mae: 10.1666\n",
            "Epoch 00216: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.1206 - mae: 10.4723 - val_loss: 17.3431 - val_mae: 17.4445\n",
            "Epoch 217/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7612 - mae: 10.2354\n",
            "Epoch 00217: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1805 - mae: 10.5352 - val_loss: 19.9037 - val_mae: 19.9916\n",
            "Epoch 218/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7909 - mae: 10.2685\n",
            "Epoch 00218: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 10.1739 - mae: 10.5422 - val_loss: 16.7419 - val_mae: 16.8206\n",
            "Epoch 219/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7125 - mae: 10.1850\n",
            "Epoch 00219: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 10.1574 - mae: 10.5031 - val_loss: 21.2253 - val_mae: 21.2778\n",
            "Epoch 220/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8805 - mae: 10.3581\n",
            "Epoch 00220: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 10.3190 - mae: 10.6715 - val_loss: 14.6749 - val_mae: 14.7686\n",
            "Epoch 221/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8561 - mae: 10.3321\n",
            "Epoch 00221: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.2889 - mae: 10.6415 - val_loss: 19.6583 - val_mae: 19.7357\n",
            "Epoch 222/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8411 - mae: 10.3167\n",
            "Epoch 00222: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.2746 - mae: 10.6265 - val_loss: 15.5257 - val_mae: 15.6146\n",
            "Epoch 223/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6849 - mae: 10.1598\n",
            "Epoch 00223: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1109 - mae: 10.4644 - val_loss: 21.9222 - val_mae: 21.9832\n",
            "Epoch 224/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8989 - mae: 10.3758\n",
            "Epoch 00224: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.2905 - mae: 10.6557 - val_loss: 13.9124 - val_mae: 14.0278\n",
            "Epoch 225/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8225 - mae: 10.2991\n",
            "Epoch 00225: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.2378 - mae: 10.5960 - val_loss: 20.8758 - val_mae: 20.9288\n",
            "Epoch 226/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7985 - mae: 10.2730\n",
            "Epoch 00226: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.2160 - mae: 10.5715 - val_loss: 15.1375 - val_mae: 15.2395\n",
            "Epoch 227/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6907 - mae: 10.1639\n",
            "Epoch 00227: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1167 - mae: 10.4685 - val_loss: 20.1050 - val_mae: 20.1527\n",
            "Epoch 228/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6434 - mae: 10.1167\n",
            "Epoch 00228: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.0431 - mae: 10.4024 - val_loss: 15.9075 - val_mae: 15.9924\n",
            "Epoch 229/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6744 - mae: 10.1482\n",
            "Epoch 00229: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.0977 - mae: 10.4509 - val_loss: 20.3088 - val_mae: 20.3532\n",
            "Epoch 230/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6633 - mae: 10.1369\n",
            "Epoch 00230: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1043 - mae: 10.4522 - val_loss: 15.8423 - val_mae: 15.9016\n",
            "Epoch 231/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7832 - mae: 10.2599\n",
            "Epoch 00231: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.2072 - mae: 10.5629 - val_loss: 21.0982 - val_mae: 21.1438\n",
            "Epoch 232/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7861 - mae: 10.2601\n",
            "Epoch 00232: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.2147 - mae: 10.5665 - val_loss: 14.5281 - val_mae: 14.6163\n",
            "Epoch 233/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7000 - mae: 10.1757\n",
            "Epoch 00233: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1044 - mae: 10.4647 - val_loss: 20.8577 - val_mae: 20.9022\n",
            "Epoch 234/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7500 - mae: 10.2240\n",
            "Epoch 00234: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1668 - mae: 10.5221 - val_loss: 16.5507 - val_mae: 16.6247\n",
            "Epoch 235/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6884 - mae: 10.1625\n",
            "Epoch 00235: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 10.1077 - mae: 10.4623 - val_loss: 21.2068 - val_mae: 21.2450\n",
            "Epoch 236/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7195 - mae: 10.1934\n",
            "Epoch 00236: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.1200 - mae: 10.4798 - val_loss: 15.2019 - val_mae: 15.2960\n",
            "Epoch 237/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8053 - mae: 10.2798\n",
            "Epoch 00237: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.2217 - mae: 10.5775 - val_loss: 21.2322 - val_mae: 21.2783\n",
            "Epoch 238/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8046 - mae: 10.2788\n",
            "Epoch 00238: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.2349 - mae: 10.5864 - val_loss: 13.7476 - val_mae: 13.8579\n",
            "Epoch 239/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8427 - mae: 10.3216\n",
            "Epoch 00239: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.2535 - mae: 10.6152 - val_loss: 21.4874 - val_mae: 21.5272\n",
            "Epoch 240/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7327 - mae: 10.2083\n",
            "Epoch 00240: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1544 - mae: 10.5097 - val_loss: 17.3507 - val_mae: 17.3962\n",
            "Epoch 241/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7243 - mae: 10.1974\n",
            "Epoch 00241: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.1432 - mae: 10.4969 - val_loss: 21.6684 - val_mae: 21.7018\n",
            "Epoch 242/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7180 - mae: 10.1930\n",
            "Epoch 00242: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 10.1348 - mae: 10.4909 - val_loss: 15.4917 - val_mae: 15.5876\n",
            "Epoch 243/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7736 - mae: 10.2476\n",
            "Epoch 00243: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1940 - mae: 10.5481 - val_loss: 20.9621 - val_mae: 21.0198\n",
            "Epoch 244/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8263 - mae: 10.3026\n",
            "Epoch 00244: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.2510 - mae: 10.6060 - val_loss: 13.9827 - val_mae: 14.0856\n",
            "Epoch 245/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8898 - mae: 10.3668\n",
            "Epoch 00245: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.2948 - mae: 10.6563 - val_loss: 21.6453 - val_mae: 21.6785\n",
            "Epoch 246/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7874 - mae: 10.2646\n",
            "Epoch 00246: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.2023 - mae: 10.5611 - val_loss: 15.9479 - val_mae: 16.0104\n",
            "Epoch 247/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6602 - mae: 10.1335\n",
            "Epoch 00247: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 167ms/step - loss: 10.0751 - mae: 10.4302 - val_loss: 19.6740 - val_mae: 19.7015\n",
            "Epoch 248/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6527 - mae: 10.1255\n",
            "Epoch 00248: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.0966 - mae: 10.4429 - val_loss: 16.5228 - val_mae: 16.5887\n",
            "Epoch 249/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6696 - mae: 10.1445\n",
            "Epoch 00249: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.0873 - mae: 10.4431 - val_loss: 19.6428 - val_mae: 19.6957\n",
            "Epoch 250/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7280 - mae: 10.2010\n",
            "Epoch 00250: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1469 - mae: 10.5005 - val_loss: 17.0461 - val_mae: 17.1127\n",
            "Epoch 251/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6789 - mae: 10.1542\n",
            "Epoch 00251: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1063 - mae: 10.4597 - val_loss: 19.6018 - val_mae: 19.6414\n",
            "Epoch 252/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7416 - mae: 10.2160\n",
            "Epoch 00252: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1527 - mae: 10.5099 - val_loss: 17.6173 - val_mae: 17.6681\n",
            "Epoch 253/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7430 - mae: 10.2194\n",
            "Epoch 00253: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.1677 - mae: 10.5229 - val_loss: 20.3704 - val_mae: 20.4048\n",
            "Epoch 254/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6061 - mae: 10.0785\n",
            "Epoch 00254: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0219 - mae: 10.3757 - val_loss: 17.1882 - val_mae: 17.2544\n",
            "Epoch 255/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6725 - mae: 10.1472\n",
            "Epoch 00255: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.0929 - mae: 10.4477 - val_loss: 18.6730 - val_mae: 18.7463\n",
            "Epoch 256/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6172 - mae: 10.0896\n",
            "Epoch 00256: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.0388 - mae: 10.3911 - val_loss: 18.2623 - val_mae: 18.3137\n",
            "Epoch 257/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6762 - mae: 10.1499\n",
            "Epoch 00257: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.0961 - mae: 10.4501 - val_loss: 19.7027 - val_mae: 19.7573\n",
            "Epoch 258/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6838 - mae: 10.1570\n",
            "Epoch 00258: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1165 - mae: 10.4664 - val_loss: 15.4780 - val_mae: 15.5578\n",
            "Epoch 259/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0005 - mae: 10.4795\n",
            "Epoch 00259: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.3868 - mae: 10.7556 - val_loss: 19.7334 - val_mae: 19.8179\n",
            "Epoch 260/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7857 - mae: 10.2599\n",
            "Epoch 00260: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.2003 - mae: 10.5563 - val_loss: 20.0765 - val_mae: 20.1600\n",
            "Epoch 261/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8787 - mae: 10.3581\n",
            "Epoch 00261: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.2957 - mae: 10.6561 - val_loss: 14.7848 - val_mae: 14.9232\n",
            "Epoch 262/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.5871 - mae: 10.0592\n",
            "Epoch 00262: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.0144 - mae: 10.3647 - val_loss: 17.8786 - val_mae: 17.9696\n",
            "Epoch 263/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6353 - mae: 10.1082\n",
            "Epoch 00263: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0577 - mae: 10.4102 - val_loss: 15.1008 - val_mae: 15.2009\n",
            "Epoch 264/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7547 - mae: 10.2324\n",
            "Epoch 00264: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1729 - mae: 10.5313 - val_loss: 19.5098 - val_mae: 19.5889\n",
            "Epoch 265/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7132 - mae: 10.1862\n",
            "Epoch 00265: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1362 - mae: 10.4886 - val_loss: 15.1840 - val_mae: 15.2783\n",
            "Epoch 266/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8998 - mae: 10.3776\n",
            "Epoch 00266: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.2805 - mae: 10.6498 - val_loss: 19.8099 - val_mae: 19.8838\n",
            "Epoch 267/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6949 - mae: 10.1696\n",
            "Epoch 00267: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1520 - mae: 10.4962 - val_loss: 15.8893 - val_mae: 15.9744\n",
            "Epoch 268/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7504 - mae: 10.2247\n",
            "Epoch 00268: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.1553 - mae: 10.5142 - val_loss: 20.9839 - val_mae: 21.0493\n",
            "Epoch 269/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8442 - mae: 10.3190\n",
            "Epoch 00269: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.2747 - mae: 10.6267 - val_loss: 13.5509 - val_mae: 13.6599\n",
            "Epoch 270/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9275 - mae: 10.4058\n",
            "Epoch 00270: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.3381 - mae: 10.6993 - val_loss: 21.1549 - val_mae: 21.2005\n",
            "Epoch 271/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7962 - mae: 10.2730\n",
            "Epoch 00271: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.2269 - mae: 10.5809 - val_loss: 15.7213 - val_mae: 15.8078\n",
            "Epoch 272/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6883 - mae: 10.1620\n",
            "Epoch 00272: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1136 - mae: 10.4660 - val_loss: 19.6688 - val_mae: 19.7169\n",
            "Epoch 273/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6679 - mae: 10.1408\n",
            "Epoch 00273: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.0961 - mae: 10.4469 - val_loss: 16.5463 - val_mae: 16.5962\n",
            "Epoch 274/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7042 - mae: 10.1788\n",
            "Epoch 00274: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1333 - mae: 10.4856 - val_loss: 21.0998 - val_mae: 21.1128\n",
            "Epoch 275/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7045 - mae: 10.1777\n",
            "Epoch 00275: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1292 - mae: 10.4813 - val_loss: 15.2886 - val_mae: 15.3524\n",
            "Epoch 276/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8536 - mae: 10.3318\n",
            "Epoch 00276: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.2641 - mae: 10.6252 - val_loss: 20.5333 - val_mae: 20.5766\n",
            "Epoch 277/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7516 - mae: 10.2271\n",
            "Epoch 00277: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1743 - mae: 10.5292 - val_loss: 16.4855 - val_mae: 16.5548\n",
            "Epoch 278/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7456 - mae: 10.2185\n",
            "Epoch 00278: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1816 - mae: 10.5302 - val_loss: 20.1030 - val_mae: 20.1587\n",
            "Epoch 279/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7497 - mae: 10.2255\n",
            "Epoch 00279: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1943 - mae: 10.5433 - val_loss: 14.8992 - val_mae: 14.9876\n",
            "Epoch 280/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6879 - mae: 10.1619\n",
            "Epoch 00280: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1032 - mae: 10.4588 - val_loss: 20.3141 - val_mae: 20.3579\n",
            "Epoch 281/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7064 - mae: 10.1808\n",
            "Epoch 00281: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1231 - mae: 10.4786 - val_loss: 14.6449 - val_mae: 14.7329\n",
            "Epoch 282/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7594 - mae: 10.2352\n",
            "Epoch 00282: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1914 - mae: 10.5441 - val_loss: 19.9822 - val_mae: 20.0344\n",
            "Epoch 283/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7361 - mae: 10.2099\n",
            "Epoch 00283: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1422 - mae: 10.5003 - val_loss: 16.3167 - val_mae: 16.3772\n",
            "Epoch 284/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7297 - mae: 10.2053\n",
            "Epoch 00284: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1306 - mae: 10.4919 - val_loss: 21.2084 - val_mae: 21.2527\n",
            "Epoch 285/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7277 - mae: 10.2027\n",
            "Epoch 00285: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1352 - mae: 10.4940 - val_loss: 16.8943 - val_mae: 16.9586\n",
            "Epoch 286/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6637 - mae: 10.1368\n",
            "Epoch 00286: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1100 - mae: 10.4559 - val_loss: 20.9040 - val_mae: 20.9410\n",
            "Epoch 287/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7842 - mae: 10.2591\n",
            "Epoch 00287: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.2271 - mae: 10.5756 - val_loss: 15.2291 - val_mae: 15.3120\n",
            "Epoch 288/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7202 - mae: 10.1950\n",
            "Epoch 00288: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 176ms/step - loss: 10.1171 - mae: 10.4787 - val_loss: 21.5025 - val_mae: 21.5335\n",
            "Epoch 289/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6633 - mae: 10.1382\n",
            "Epoch 00289: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.0791 - mae: 10.4355 - val_loss: 16.1962 - val_mae: 16.2609\n",
            "Epoch 290/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8413 - mae: 10.3155\n",
            "Epoch 00290: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2619 - mae: 10.6162 - val_loss: 22.0332 - val_mae: 22.0511\n",
            "Epoch 291/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8751 - mae: 10.3510\n",
            "Epoch 00291: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.2908 - mae: 10.6482 - val_loss: 14.4869 - val_mae: 14.5591\n",
            "Epoch 292/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8710 - mae: 10.3489\n",
            "Epoch 00292: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2607 - mae: 10.6274 - val_loss: 19.3321 - val_mae: 19.3771\n",
            "Epoch 293/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7201 - mae: 10.1932\n",
            "Epoch 00293: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1247 - mae: 10.4825 - val_loss: 20.2650 - val_mae: 20.2941\n",
            "Epoch 294/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6213 - mae: 10.0951\n",
            "Epoch 00294: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.0368 - mae: 10.3921 - val_loss: 16.3923 - val_mae: 16.4545\n",
            "Epoch 295/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.5522 - mae: 10.0237\n",
            "Epoch 00295: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 9.9846 - mae: 10.3329 - val_loss: 20.6513 - val_mae: 20.6694\n",
            "Epoch 296/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.5678 - mae: 10.0390\n",
            "Epoch 00296: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 9.9741 - mae: 10.3295 - val_loss: 18.4326 - val_mae: 18.4755\n",
            "Epoch 297/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.5800 - mae: 10.0516\n",
            "Epoch 00297: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 9.9908 - mae: 10.3454 - val_loss: 20.3333 - val_mae: 20.3799\n",
            "Epoch 298/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6112 - mae: 10.0840\n",
            "Epoch 00298: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.0217 - mae: 10.3775 - val_loss: 15.5100 - val_mae: 15.5927\n",
            "Epoch 299/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7053 - mae: 10.1794\n",
            "Epoch 00299: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1357 - mae: 10.4871 - val_loss: 22.4410 - val_mae: 22.4422\n",
            "Epoch 300/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7016 - mae: 10.1752\n",
            "Epoch 00300: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1220 - mae: 10.4757 - val_loss: 16.1384 - val_mae: 16.1900\n",
            "Epoch 301/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7350 - mae: 10.2118\n",
            "Epoch 00301: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1540 - mae: 10.5114 - val_loss: 19.9200 - val_mae: 19.9603\n",
            "Epoch 302/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7853 - mae: 10.2582\n",
            "Epoch 00302: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 178ms/step - loss: 10.1884 - mae: 10.5465 - val_loss: 17.5125 - val_mae: 17.5607\n",
            "Epoch 303/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7319 - mae: 10.2085\n",
            "Epoch 00303: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 180ms/step - loss: 10.1680 - mae: 10.5202 - val_loss: 22.1264 - val_mae: 22.1295\n",
            "Epoch 304/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7112 - mae: 10.1843\n",
            "Epoch 00304: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1318 - mae: 10.4850 - val_loss: 15.8226 - val_mae: 15.9006\n",
            "Epoch 305/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6999 - mae: 10.1758\n",
            "Epoch 00305: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1270 - mae: 10.4811 - val_loss: 22.0397 - val_mae: 22.0832\n",
            "Epoch 306/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7730 - mae: 10.2475\n",
            "Epoch 00306: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1923 - mae: 10.5473 - val_loss: 13.6806 - val_mae: 13.8134\n",
            "Epoch 307/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7453 - mae: 10.2204\n",
            "Epoch 00307: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1729 - mae: 10.5261 - val_loss: 20.7955 - val_mae: 20.8479\n",
            "Epoch 308/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7274 - mae: 10.2010\n",
            "Epoch 00308: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1355 - mae: 10.4928 - val_loss: 15.2620 - val_mae: 15.3651\n",
            "Epoch 309/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7502 - mae: 10.2237\n",
            "Epoch 00309: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1990 - mae: 10.5445 - val_loss: 20.0981 - val_mae: 20.1687\n",
            "Epoch 310/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7618 - mae: 10.2376\n",
            "Epoch 00310: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1996 - mae: 10.5506 - val_loss: 13.1198 - val_mae: 13.2683\n",
            "Epoch 311/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6873 - mae: 10.1625\n",
            "Epoch 00311: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1255 - mae: 10.4757 - val_loss: 21.3319 - val_mae: 21.3798\n",
            "Epoch 312/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8014 - mae: 10.2769\n",
            "Epoch 00312: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2210 - mae: 10.5768 - val_loss: 14.6751 - val_mae: 14.7828\n",
            "Epoch 313/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7339 - mae: 10.2079\n",
            "Epoch 00313: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1532 - mae: 10.5077 - val_loss: 21.7026 - val_mae: 21.7196\n",
            "Epoch 314/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6796 - mae: 10.1528\n",
            "Epoch 00314: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.0870 - mae: 10.4440 - val_loss: 16.3549 - val_mae: 16.4050\n",
            "Epoch 315/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7784 - mae: 10.2538\n",
            "Epoch 00315: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.2100 - mae: 10.5623 - val_loss: 20.7486 - val_mae: 20.7814\n",
            "Epoch 316/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6701 - mae: 10.1438\n",
            "Epoch 00316: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0801 - mae: 10.4369 - val_loss: 16.3446 - val_mae: 16.4145\n",
            "Epoch 317/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6456 - mae: 10.1187\n",
            "Epoch 00317: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.0563 - mae: 10.4124 - val_loss: 21.2166 - val_mae: 21.2203\n",
            "Epoch 318/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6906 - mae: 10.1637\n",
            "Epoch 00318: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.0892 - mae: 10.4487 - val_loss: 16.4150 - val_mae: 16.4506\n",
            "Epoch 319/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8948 - mae: 10.3742\n",
            "Epoch 00319: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.2961 - mae: 10.6610 - val_loss: 20.2693 - val_mae: 20.3088\n",
            "Epoch 320/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7494 - mae: 10.2237\n",
            "Epoch 00320: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1621 - mae: 10.5188 - val_loss: 17.9291 - val_mae: 17.9957\n",
            "Epoch 321/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7364 - mae: 10.2124\n",
            "Epoch 00321: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1525 - mae: 10.5098 - val_loss: 16.8866 - val_mae: 16.9680\n",
            "Epoch 322/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.5271 - mae: 9.9978\n",
            "Epoch 00322: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 9.9509 - mae: 10.3009 - val_loss: 18.1992 - val_mae: 18.2593\n",
            "Epoch 323/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.4660 - mae: 9.9376\n",
            "Epoch 00323: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 9.8731 - mae: 10.2287 - val_loss: 18.5786 - val_mae: 18.6409\n",
            "Epoch 324/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6192 - mae: 10.0902\n",
            "Epoch 00324: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.0468 - mae: 10.3959 - val_loss: 18.8275 - val_mae: 18.8995\n",
            "Epoch 325/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.5946 - mae: 10.0669\n",
            "Epoch 00325: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0160 - mae: 10.3682 - val_loss: 16.0396 - val_mae: 16.1424\n",
            "Epoch 326/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6515 - mae: 10.1247\n",
            "Epoch 00326: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.0796 - mae: 10.4308 - val_loss: 21.4719 - val_mae: 21.5138\n",
            "Epoch 327/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8078 - mae: 10.2809\n",
            "Epoch 00327: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.2258 - mae: 10.5798 - val_loss: 13.8687 - val_mae: 13.9517\n",
            "Epoch 328/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0341 - mae: 10.5141\n",
            "Epoch 00328: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.4357 - mae: 10.8011 - val_loss: 20.1990 - val_mae: 20.2758\n",
            "Epoch 329/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8995 - mae: 10.3759\n",
            "Epoch 00329: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2949 - mae: 10.6585 - val_loss: 15.8643 - val_mae: 15.9555\n",
            "Epoch 330/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7912 - mae: 10.2669\n",
            "Epoch 00330: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.2021 - mae: 10.5605 - val_loss: 17.0492 - val_mae: 17.1220\n",
            "Epoch 331/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6609 - mae: 10.1341\n",
            "Epoch 00331: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.0758 - mae: 10.4307 - val_loss: 21.0758 - val_mae: 21.0992\n",
            "Epoch 332/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6934 - mae: 10.1659\n",
            "Epoch 00332: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.0705 - mae: 10.4356 - val_loss: 15.8791 - val_mae: 15.9484\n",
            "Epoch 333/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7142 - mae: 10.1896\n",
            "Epoch 00333: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1443 - mae: 10.4971 - val_loss: 21.5870 - val_mae: 21.6034\n",
            "Epoch 334/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6430 - mae: 10.1156\n",
            "Epoch 00334: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.0667 - mae: 10.4186 - val_loss: 16.0136 - val_mae: 16.0795\n",
            "Epoch 335/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6923 - mae: 10.1683\n",
            "Epoch 00335: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1252 - mae: 10.4777 - val_loss: 18.6777 - val_mae: 18.7342\n",
            "Epoch 336/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6271 - mae: 10.0994\n",
            "Epoch 00336: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0440 - mae: 10.3975 - val_loss: 16.2815 - val_mae: 16.3543\n",
            "Epoch 337/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7229 - mae: 10.1985\n",
            "Epoch 00337: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1179 - mae: 10.4809 - val_loss: 19.0316 - val_mae: 19.0899\n",
            "Epoch 338/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6394 - mae: 10.1120\n",
            "Epoch 00338: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0689 - mae: 10.4191 - val_loss: 16.7515 - val_mae: 16.8158\n",
            "Epoch 339/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7817 - mae: 10.2592\n",
            "Epoch 00339: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.1829 - mae: 10.5460 - val_loss: 19.1988 - val_mae: 19.2743\n",
            "Epoch 340/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.5886 - mae: 10.0605\n",
            "Epoch 00340: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.0329 - mae: 10.3781 - val_loss: 15.9360 - val_mae: 16.0339\n",
            "Epoch 341/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.5943 - mae: 10.0666\n",
            "Epoch 00341: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.0312 - mae: 10.3790 - val_loss: 19.1500 - val_mae: 19.2252\n",
            "Epoch 342/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.5292 - mae: 10.0018\n",
            "Epoch 00342: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 9.9557 - mae: 10.3067 - val_loss: 14.4296 - val_mae: 14.5238\n",
            "Epoch 343/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8290 - mae: 10.3071\n",
            "Epoch 00343: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.2458 - mae: 10.6050 - val_loss: 19.5258 - val_mae: 19.5841\n",
            "Epoch 344/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6654 - mae: 10.1382\n",
            "Epoch 00344: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.0864 - mae: 10.4392 - val_loss: 16.4840 - val_mae: 16.5544\n",
            "Epoch 345/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7349 - mae: 10.2084\n",
            "Epoch 00345: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1757 - mae: 10.5235 - val_loss: 21.6260 - val_mae: 21.6652\n",
            "Epoch 346/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9281 - mae: 10.4018\n",
            "Epoch 00346: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.3566 - mae: 10.7081 - val_loss: 13.8670 - val_mae: 13.9525\n",
            "Epoch 347/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 10.0420 - mae: 10.5224\n",
            "Epoch 00347: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.4460 - mae: 10.8111 - val_loss: 20.0182 - val_mae: 20.0889\n",
            "Epoch 348/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8898 - mae: 10.3668\n",
            "Epoch 00348: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 10.3173 - mae: 10.6723 - val_loss: 17.8719 - val_mae: 17.9383\n",
            "Epoch 349/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7625 - mae: 10.2400\n",
            "Epoch 00349: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1640 - mae: 10.5269 - val_loss: 17.6572 - val_mae: 17.7143\n",
            "Epoch 350/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6387 - mae: 10.1109\n",
            "Epoch 00350: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.0572 - mae: 10.4102 - val_loss: 18.5647 - val_mae: 18.6001\n",
            "Epoch 351/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.5738 - mae: 10.0463\n",
            "Epoch 00351: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 9.9785 - mae: 10.3357 - val_loss: 17.8461 - val_mae: 17.8892\n",
            "Epoch 352/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6538 - mae: 10.1278\n",
            "Epoch 00352: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.0968 - mae: 10.4445 - val_loss: 19.4666 - val_mae: 19.4899\n",
            "Epoch 353/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8089 - mae: 10.2847\n",
            "Epoch 00353: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.2126 - mae: 10.5732 - val_loss: 17.7567 - val_mae: 17.7788\n",
            "Epoch 354/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9368 - mae: 10.4163\n",
            "Epoch 00354: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 10.3459 - mae: 10.7086 - val_loss: 18.3046 - val_mae: 18.3480\n",
            "Epoch 355/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6319 - mae: 10.1048\n",
            "Epoch 00355: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.0422 - mae: 10.3982 - val_loss: 21.8388 - val_mae: 21.8804\n",
            "Epoch 356/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7614 - mae: 10.2382\n",
            "Epoch 00356: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1721 - mae: 10.5318 - val_loss: 14.0650 - val_mae: 14.1860\n",
            "Epoch 357/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7223 - mae: 10.1973\n",
            "Epoch 00357: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 10.1611 - mae: 10.5110 - val_loss: 20.6925 - val_mae: 20.7330\n",
            "Epoch 358/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.5930 - mae: 10.0661\n",
            "Epoch 00358: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0249 - mae: 10.3748 - val_loss: 15.8732 - val_mae: 15.9533\n",
            "Epoch 359/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6980 - mae: 10.1721\n",
            "Epoch 00359: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.0988 - mae: 10.4587 - val_loss: 20.2459 - val_mae: 20.2969\n",
            "Epoch 360/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6824 - mae: 10.1550\n",
            "Epoch 00360: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1059 - mae: 10.4578 - val_loss: 16.0269 - val_mae: 16.0938\n",
            "Epoch 361/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6972 - mae: 10.1715\n",
            "Epoch 00361: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1285 - mae: 10.4798 - val_loss: 19.8853 - val_mae: 19.9322\n",
            "Epoch 362/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6129 - mae: 10.0848\n",
            "Epoch 00362: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 10.0343 - mae: 10.3860 - val_loss: 17.4087 - val_mae: 17.4820\n",
            "Epoch 363/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.5825 - mae: 10.0545\n",
            "Epoch 00363: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 9.9932 - mae: 10.3481 - val_loss: 19.0266 - val_mae: 19.0845\n",
            "Epoch 364/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6285 - mae: 10.1003\n",
            "Epoch 00364: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0353 - mae: 10.3912 - val_loss: 16.3586 - val_mae: 16.4091\n",
            "Epoch 365/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7410 - mae: 10.2181\n",
            "Epoch 00365: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.1482 - mae: 10.5092 - val_loss: 20.4406 - val_mae: 20.4764\n",
            "Epoch 366/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6920 - mae: 10.1650\n",
            "Epoch 00366: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.0796 - mae: 10.4421 - val_loss: 18.2845 - val_mae: 18.3207\n",
            "Epoch 367/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.5883 - mae: 10.0630\n",
            "Epoch 00367: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 10.0291 - mae: 10.3782 - val_loss: 20.8376 - val_mae: 20.8679\n",
            "Epoch 368/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6862 - mae: 10.1583\n",
            "Epoch 00368: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.0803 - mae: 10.4401 - val_loss: 15.2244 - val_mae: 15.3001\n",
            "Epoch 369/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8687 - mae: 10.3460\n",
            "Epoch 00369: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.2575 - mae: 10.6238 - val_loss: 21.2550 - val_mae: 21.3070\n",
            "Epoch 370/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6642 - mae: 10.1379\n",
            "Epoch 00370: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0860 - mae: 10.4394 - val_loss: 15.4222 - val_mae: 15.5377\n",
            "Epoch 371/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6947 - mae: 10.1668\n",
            "Epoch 00371: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 170ms/step - loss: 10.1214 - mae: 10.4719 - val_loss: 19.0411 - val_mae: 19.1436\n",
            "Epoch 372/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7458 - mae: 10.2206\n",
            "Epoch 00372: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1786 - mae: 10.5299 - val_loss: 14.7215 - val_mae: 14.8336\n",
            "Epoch 373/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6547 - mae: 10.1273\n",
            "Epoch 00373: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1119 - mae: 10.4541 - val_loss: 21.4685 - val_mae: 21.5219\n",
            "Epoch 374/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7920 - mae: 10.2669\n",
            "Epoch 00374: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2245 - mae: 10.5761 - val_loss: 12.8202 - val_mae: 12.9610\n",
            "Epoch 375/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8403 - mae: 10.3170\n",
            "Epoch 00375: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.2495 - mae: 10.6095 - val_loss: 22.6460 - val_mae: 22.6961\n",
            "Epoch 376/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8857 - mae: 10.3644\n",
            "Epoch 00376: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2826 - mae: 10.6480 - val_loss: 14.7465 - val_mae: 14.8672\n",
            "Epoch 377/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7156 - mae: 10.1892\n",
            "Epoch 00377: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1338 - mae: 10.4882 - val_loss: 19.3367 - val_mae: 19.3949\n",
            "Epoch 378/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6560 - mae: 10.1288\n",
            "Epoch 00378: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1007 - mae: 10.4467 - val_loss: 17.1773 - val_mae: 17.2198\n",
            "Epoch 379/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6141 - mae: 10.0870\n",
            "Epoch 00379: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.0386 - mae: 10.3905 - val_loss: 19.4945 - val_mae: 19.5324\n",
            "Epoch 380/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6070 - mae: 10.0793\n",
            "Epoch 00380: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.0269 - mae: 10.3795 - val_loss: 17.5421 - val_mae: 17.5932\n",
            "Epoch 381/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7221 - mae: 10.1975\n",
            "Epoch 00381: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 177ms/step - loss: 10.1355 - mae: 10.4930 - val_loss: 19.1495 - val_mae: 19.1975\n",
            "Epoch 382/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6163 - mae: 10.0888\n",
            "Epoch 00382: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 174ms/step - loss: 10.0559 - mae: 10.4031 - val_loss: 16.2736 - val_mae: 16.3364\n",
            "Epoch 383/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8468 - mae: 10.3251\n",
            "Epoch 00383: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 175ms/step - loss: 10.2624 - mae: 10.6222 - val_loss: 19.2198 - val_mae: 19.2784\n",
            "Epoch 384/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6656 - mae: 10.1383\n",
            "Epoch 00384: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.0859 - mae: 10.4388 - val_loss: 17.2723 - val_mae: 17.3393\n",
            "Epoch 385/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6213 - mae: 10.0954\n",
            "Epoch 00385: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0522 - mae: 10.4035 - val_loss: 20.2993 - val_mae: 20.3646\n",
            "Epoch 386/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6610 - mae: 10.1346\n",
            "Epoch 00386: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.0841 - mae: 10.4370 - val_loss: 13.4835 - val_mae: 13.6033\n",
            "Epoch 387/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7684 - mae: 10.2446\n",
            "Epoch 00387: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.1750 - mae: 10.5353 - val_loss: 20.2937 - val_mae: 20.3636\n",
            "Epoch 388/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7344 - mae: 10.2081\n",
            "Epoch 00388: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1618 - mae: 10.5137 - val_loss: 13.7748 - val_mae: 13.8795\n",
            "Epoch 389/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.9540 - mae: 10.4314\n",
            "Epoch 00389: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.3565 - mae: 10.7192 - val_loss: 21.6535 - val_mae: 21.6955\n",
            "Epoch 390/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7819 - mae: 10.2574\n",
            "Epoch 00390: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1910 - mae: 10.5499 - val_loss: 16.3912 - val_mae: 16.4793\n",
            "Epoch 391/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6465 - mae: 10.1195\n",
            "Epoch 00391: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.0625 - mae: 10.4169 - val_loss: 20.3281 - val_mae: 20.3749\n",
            "Epoch 392/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6357 - mae: 10.1094\n",
            "Epoch 00392: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.0790 - mae: 10.4262 - val_loss: 15.8823 - val_mae: 15.9608\n",
            "Epoch 393/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6795 - mae: 10.1512\n",
            "Epoch 00393: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1045 - mae: 10.4551 - val_loss: 20.6449 - val_mae: 20.6952\n",
            "Epoch 394/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6645 - mae: 10.1373\n",
            "Epoch 00394: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.0725 - mae: 10.4290 - val_loss: 16.8306 - val_mae: 16.8993\n",
            "Epoch 395/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7066 - mae: 10.1798\n",
            "Epoch 00395: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1453 - mae: 10.4934 - val_loss: 21.4951 - val_mae: 21.5205\n",
            "Epoch 396/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.8398 - mae: 10.3150\n",
            "Epoch 00396: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 172ms/step - loss: 10.2672 - mae: 10.6205 - val_loss: 13.8287 - val_mae: 13.9379\n",
            "Epoch 397/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7260 - mae: 10.2014\n",
            "Epoch 00397: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 173ms/step - loss: 10.1455 - mae: 10.5012 - val_loss: 21.3421 - val_mae: 21.3751\n",
            "Epoch 398/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.7444 - mae: 10.2181\n",
            "Epoch 00398: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 10.1669 - mae: 10.5202 - val_loss: 14.6481 - val_mae: 14.7459\n",
            "Epoch 399/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6430 - mae: 10.1168\n",
            "Epoch 00399: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 169ms/step - loss: 10.0666 - mae: 10.4197 - val_loss: 19.0017 - val_mae: 19.0613\n",
            "Epoch 400/400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 9.6523 - mae: 10.1242\n",
            "Epoch 00400: val_loss did not improve from 12.15187\n",
            "30/30 [==============================] - 5s 168ms/step - loss: 10.0715 - mae: 10.4239 - val_loss: 17.9949 - val_mae: 18.0446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkOgKI-NbGVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"cp/weights-170-12.15.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-oj653tbKos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_forecast = model_forecast(model, series[..., np.newaxis], window_size)\n",
        "rnn_forecast = rnn_forecast[split_time - window_size:-1, -1, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvWsTUHKYKPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI8a_DLibNZm",
        "colab_type": "code",
        "outputId": "715b460b-b590-4a2a-8f3c-4e1dbee26dee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(time_valid, x_valid,label='actual')\n",
        "plt.plot(time_valid, rnn_forecast,label='forcast')\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.title('ICICI BANK')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "# plot_series(time_valid, x_valid)\n",
        "# plot_series(time_valid, rnn_forecast)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAGDCAYAAACfhOyVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW7v4LJibPu0",
        "colab_type": "code",
        "outputId": "724734aa-9850-407e-dc33-2b9d95b1a4bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11.07319"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEuQy4VbqkMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu2Va0U1R_ZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}